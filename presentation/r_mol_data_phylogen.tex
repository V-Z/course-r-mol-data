\documentclass[compress, ucs, xelatex, 11pt, xcolor=svgnames, aspectratio=169,
	hyperref={
		bookmarks=true,
		unicode=true,
		colorlinks=true,
		pdftitle={Molecular data in R},
		plainpages=false,
		pdfauthor={Vojtech Zeisek},
		pdfsubject={Course about phylogeny and evolution in R},
		pdfcreator={XeLaTeX},
		pdfkeywords={R, evolution, phylogeny, molecular data},
		linkcolor=Crimson, % Navigation menu links on pages and in navigation menus
		anchorcolor=Magenta, % Not in use?
		citecolor=Magenta, % Not in use?
		filecolor=Magenta, % Not in use?
		menucolor=Magenta, % Not in use?
		urlcolor=DodgerBlue, % Links with \href and \url
		pdftex},
	url={hyphens, lowtilde} % Allow line breaks within URLs
	]{beamer}

% Theme settings
\usetheme[secheader]{Boadilla}
\usecolortheme{whale}
\setbeamertemplate{headline} {
	\begin{beamercolorbox}{section in head/foot}
		\insertsectionnavigationhorizontal{\paperwidth}{\hskip0pt plus1fill}{\hskip0pt plus1fill}
	\end{beamercolorbox}
	\begin{beamercolorbox}[ht=2ex, dp=1.125ex]{subsection in head/foot}
		\insertsubsectionnavigationhorizontal{\paperwidth}{}{\hfill\hfill}
	\end{beamercolorbox}
	}
\useinnertheme{circles}

% Fonts Linux Libertine
\usepackage{libertine}

% Other packages
\usepackage{multicol}

% Add background for \texttt{}
\renewcommand{\texttt}[1]{\colorbox{Beige}{{\ttfamily #1}}}

% TeX logos
\usepackage{dtk-logos}

% Syntax higlight
\usepackage{minted}
\usemintedstyle{vim} % Styles are listed by pygmentize -L styles; languages are listed by pygmentize -L lexers
\newminted{splus}{linenos, fontsize=\footnotesize, bgcolor=DimGray, fontfamily=tt, gobble=4, numbersep=-3pt}
% Change line number style
\renewcommand{\theFancyVerbLine}{
	\sffamily
	\textcolor{BlueViolet}{
		\tiny
		\oldstylenums{
			\arabic{FancyVerbLine}
			}
		}
	}

% Fixing space before and after block of code higlight
\BeforeBeginEnvironment{spluscode}{\vspace{-0.5em}}
\AfterEndEnvironment{spluscode}{\par\vspace{-0.5em}}

% Fixing space before and after multicols region
\BeforeBeginEnvironment{multicols}{\vspace{-1.5em}}
\AfterEndEnvironment{multicols}{\par\vspace{-1.5em}}

% Fixing space before and after itemize region
\BeforeBeginEnvironment{itemize}{\vspace{-0.25em}}
\AfterEndEnvironment{itemize}{\vspace{-0.25em}}

% Default language
\usepackage[main=american]{babel}

% Quotes
\usepackage[autostyle=true, english=american]{csquotes}

% Title page
\author{Vojtěch Zeisek}
\institute[\url{https://trapa.cz/}]{Department of Botany, Faculty of Science, Charles University, Prague\\Institute of Botany, Czech Academy of Sciences, Průhonice\\\url{https://trapa.cz/}, \href{mailto:zeisek@natur.cuni.cz}{zeisek@natur.cuni.cz}}
\title{Molecular data in R}
\subtitle{Phylogeny, evolution \& R}
\titlegraphic{\includegraphics[width=1.5cm]{rlogo.jpg}}
\date{March 16 to 20, 2020}

\begin{document}

\begin{frame}
	\titlepage
\end{frame}

\begin{frame}[allowframebreaks]{Outline}
	\tableofcontents
\end{frame}

\section{Introduction}

\begin{frame}{The course information}
	\begin{itemize}
		\item The course page: \url{https://trapa.cz/en/course-molecular-data-r-2020-cb}
% 		\begin{itemize}
% 			\item Česky: \url{https://trapa.cz/cs/kurz-molekularni-data-r-2020}
% 		\end{itemize}
% 		\item Subject in SIS: \url{https://is.cuni.cz/studium/eng/predmety/index.php?do=predmet&kod=MB120C16}
		\item In \href{https://wstag.jcu.cz/portal/studium/prohlizeni.html?pc_lang=en}{IS STAG} as KBO/148 \enquote{Courses of work with molecular data in R}
		\begin{itemize}
% 			\item Česky: \url{https://is.cuni.cz/studium/predmety/index.php?do=predmet&kod=MB120C16}
			\item For students having subscribed the subject, requirements are on next slide
		\end{itemize}
		\item Working version is available at \url{https://github.com/V-Z/course-r-mol-data} --- feel free to contribute, request new parts or report bugs
	\end{itemize}
\end{frame}

\begin{frame}{Requirements to exam (\enquote{zápočet})}
	\begin{enumerate}
		\item Be present whole course.
		\item Be active --- ask and answer questions.
		\item Process some data. This will be very variable and individual. Everyone should be able take some data (according to her/his interest) and do several simple analysis (according to her/his interest). Students can of course use manual, internet, discuss with anyone. The aim is to repeat part the most interesting/important for the student and edit introduced commands to fit her/his needs. Students can thus bring their data (if they are not too large), download any data from the internet or I~can give them some toy data.
		\item Write at least one page (can be split into multiple articles) on Wikipedia about any method or related topic discussed during the course. Again, this is very open, students can write about any topic they like. I~prefer native language of the student (typically to make larger non-English Wikipedia).
	\end{enumerate}
\end{frame}

\begin{frame}{Materials to help you\ldots}
	\begin{itemize}
		\item Download the presentation from \url{https://soubory.trapa.cz/rcourse/r_mol_data_phylogen.pdf}
		\item Download the script from \url{https://soubory.trapa.cz/rcourse/course_commands.r}, use it and write your comments and notes to it during the course
		\begin{itemize}
			\item \alert{Note:} Open the R script in some \alert{good} \href{http://texteditors.org/cgi-bin/wiki.pl?PickingATextEditor}{text editor} (next slide) --- showing syntax highlight, line numbers, etc. (\alert{NO} Windows Notepad); the file is in UTF-8 encoding and with UNIX end of lines (so that too silly programs like Windows Notepad won't be able to open it correctly)
			\item The best is to open the script (or copy-paste the text) in e.g. RStudio or any other R GUI (slide~\ref{gui}) and directly work with it
			\item \alert{Downloaded file must have suffix \texttt{*.r}, not \texttt{*.txt}}
			\item \alert{Never ever} open R script in software like MS~Word --- it destroys quotation marks and other things making script unusable
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Importance of good text editor}{Can your text editor\ldots ?}
	\label{editors}
	\begin{multicols}{2}
		\begin{itemize}
			\item Show syntax highlight
			\item Show line numbers
			\item Show space between brackets
			\item Open any encoding and EOL
			\item Fold source code
			\item Show line breaks
			\item Mark lines
			\item Open multiple files
			\item Advanced search and replace
			\item Use regular expressions
			\item Make projects, add notes
			\item Use command line
			\item Check spelling
			\item Debug source code
		\end{itemize}
	\end{multicols}
	\vfill
	\vfill
	\begin{multicols}{4}
		\begin{itemize}
			\item \href{https://kate-editor.org/}{Kate}
			\item \href{https://kde.org/applications/utilities/org.kde.kwrite}{KWrite}
			\item \href{https://www.vim.org/}{Vim}
			\item \href{https://en.wikipedia.org/wiki/Emacs}{GNU Emacs}
			\item \href{https://www.geany.org/}{Geany}
			\item \href{https://bluefish.openoffice.nl/}{Bluefish}
			\item \href{https://wiki.gnome.org/Apps/Gedit}{Gedit}
			\item \href{https://notepad-plus-plus.org/}{Notepad++}
			\item \href{https://www.sublimetext.com/}{Sublime}
			\item \href{https://atom.io/}{Atom}
			\item \href{https://www.nano-editor.org/}{Nano}
			\item And \href{https://en.wikipedia.org/wiki/List_of_text_editors}{more}\ldots
		\end{itemize}
	\end{multicols}
	\vfil
	\begin{itemize}
		\item The best option is to use text editor of selected R GUI (slide~\ref{gui})\ldots
	\end{itemize}
\end{frame}

\begin{frame}{Think before you type (and hit Enter)\ldots}
	\begin{itemize}
		\item Commands from file \texttt{course\_commands.r} can be mostly directly launched without editing them, but before you do so\ldots
		\begin{enumerate}
			\item \textbf{Read} the command and all comments around, do not blindly launch it
			\item Ensure you understand, what is \textbf{aim} of the command (what it is supposed to do)
			\item Ensure you understand all \textbf{limitations} of the method (when you can use it and when not)
			\item Ensure you understand \textbf{syntax} of the command (its grammatical structure and what and how it technically does)
		\end{enumerate}
		\item Some \alert{commands} from \texttt{course\_commands.r} \alert{\textit{do \textbf{require}} to be edited} according to particular user's computer --- it is described in the comments around the command
		\item Learning R is effective only if you learn R syntax (language grammar), otherwise you only memorize commands without understanding them or blindly repeat someone's code --- in such case, you wouldn't be able to solve any issue with your workflow
	\end{itemize}
\end{frame}

\begin{frame}{What we will and what we will not do\ldots}
	\begin{multicols}{2}
		\textbf{We will go through\ldots}
		\begin{itemize}
			\item Basic introduction into R
			\item Analyzing phylogeny and evolution and basic theory
			\begin{itemize}
				\item DNA sequences, SNP, SSRs, AFLP, VCF,~\ldots
				\item NJ, UPGMA, PCoA, DAPC, Bayesian clustering, ML, maximum parsimony,~\ldots
				\item Character evolution, ancestral state reconstructions,~\ldots
				\item Alignments
				\item Manipulations with trees
			\end{itemize}
			\item Plotting
		\columnbreak
			\item Maps, spatial analysis,~\ldots
			\item Basic creation of scripts
			\item And more\ldots
		\end{itemize}
		\textbf{We will not dig deep into\ldots}
		\begin{itemize}
			\item Detailed theory behind used methods
			\item Programming in~R
			\item Other software related to the methods used (with exceptions of applications called from R)
			\item Other areas of R usage (ecology, biomedicine,~\ldots)
		\end{itemize}
	\end{multicols}
\end{frame}

\section{R}

\begin{frame}{The R}{Basic introduction to work with R, installation of all required software}
	\tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
\end{frame}

\begin{frame}{About R}
	\begin{itemize}
		\item Project for Statistical Computing
		\item Open-source --- freely available with source code --- anyone can use and modify it and contribute its development
		\item Development is organized by non-governmental non-profit organization from Vienna
		\item Thousands of packages extending its functionality are available --- all fields of computations in any scientific discipline
		\item Provides only command line interface --- full control over the analysis, easy to rerun and/or modify analysis in the future, easy creation of scripts for batch analysis etc.
		\item Several projects provide convenient graphical user interfaces (GUI)
		\item More details: \url{https://www.r-project.org/}
	\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Graphical user interfaces (GUI)}
	\label{gui}
	\begin{itemize}
		\item Provide more comfortable interface for work with scripts (source code highlight,~\ldots), overview of loaded packages and variables, easier work with figures,~\ldots
		\item RStudio \url{https://rstudio.com/products/rstudio/} --- probably the most common, multi-platform, very powerful
		\item RKWard \url{https://rkward.kde.org/} --- feature very rich, developed mainly for Linux, available also for another operating systems
		\begin{itemize}
			\item RKWard must be compiled for the same version as you use
			\item If downloading for Windows or macOS, check your version of R and download respective version of RKWard
			\item On Linux, do not mix package repositories, ensure RKWard is compiled for your R version (typically install both from same resource)
		\end{itemize}
		\item R commander (Rcmdr) \url{https://www.rcommander.com/} --- multi-platform, not so rich as previous
		\item Java GUI for R \url{https://rforge.net/JGR/} --- Java (multi-platform, but with all Java issues like memory consumption)
		\item Tinn-R (Windows only) \url{https://sourceforge.net/projects/tinn-r/} and \url{http://nbcgib.uesc.br/lec/software/editores/tinn-r/en}
		\item Pick one you like (from above list or any else) and install it\ldots
	\end{itemize}
\end{frame}

\begin{frame}{RKWard}
	\begin{center}
		\includegraphics[width=\textwidth-3.5cm]{rkward.jpg}
	\end{center}
\end{frame}

\begin{frame}{When using RKWard, consider change of settings of text editor for more comfortable work}
	\begin{center}
		\includegraphics[width=\textwidth-4cm]{rkward_settings.png}
	\end{center}
\end{frame}

\begin{frame}{RStudio}
	\begin{center}
		\includegraphics[width=\textwidth-3.5cm]{rstudio.jpg}
	\end{center}
\end{frame}

\begin{frame}{When using RStudio, turn on soft line wrap, select Czech mirror to download packages and consider change of appearance for more comfortable work}
	\begin{center}
		\includegraphics[width=\textwidth-5.25cm]{rstudio_settings.png}
	\end{center}
\end{frame}

\subsection{Installation}

\begin{frame}{MS Windows \& Apple macOS}
	\begin{itemize}
		\item Got to \url{https://CRAN.R-project.org/}
		\item Download appropriate version and install as usual
		\item Download and install selected GUI (not required, but highly recommended)
		\item Most of packages are available as pre-compiled and can be immediately installed from R --- it is convenient, but usually not tuned for particular computer architecture (type of CPU)
		\item Usually there are some problems every time new version of OS is released --- it takes time to modify and recompile packages for new version of OS
		\item You have to check for new version of R manually
		\item RStudio is available from its \href{https://rstudio.com/products/rstudio/download/\#download}{download page}
		\item RKWard is also available for \href{https://rkward.kde.org/RKWard_on_Windows.html}{Windows} and \href{https://rkward.kde.org/RKWard_on_Mac.html}{macOS}, but it requires some work to install it
	\end{itemize}
\end{frame}

\begin{frame}{Linux --- general}
	\begin{itemize}
		\item R, and usually also GUI, is available in repositories --- use standard package management according to distribution
		\item Linux repositories provide automatic updates
		\item Packages are also partially available in repositories and can be installed and updated as usual application or from R
		\item Packages commonly have to be compiled --- R will do it automatically, but install basic Linux packages for building of C, C++, FORTRAN,~\ldots
		\item Compilation takes longer time and there are sometimes issues with missing dependencies (tools required by particular packages), but it can then provide higher performance\ldots
	\end{itemize}
\end{frame}

\begin{frame}{Linux --- Debian/Ubuntu and derivatives like Linux Mint or Kali Linux}
	\begin{itemize}
		\item Install package \texttt{build-essential} (general tools to compile software, including R packages)
		\item Debian (and derivatives): follow instructions at \url{https://CRAN.R-project.org/bin/linux/debian/}
		\item Ubuntu (and derivatives): follow instructions at \url{https://CRAN.R-project.org/bin/linux/ubuntu/}
		\item As \texttt{<my.favorite.cran.mirror>} select \alert{\texttt{https://mirrors.nic.cz/R/}}, see \alert{CRAN Mirrors} at \url{https://CRAN.R-project.org/mirrors.html}
		\item Install packages \texttt{R-base} (the R), \texttt{R-base-dev} (required to compile additional R packages --- only some are available in repositories) and optionally \texttt{rkward} and/or \texttt{rstudio}
		\item RStudio is also available from its \href{https://rstudio.com/products/rstudio/download/\#download}{download page}
	\end{itemize}
\end{frame}

\begin{frame}{Linux --- openSUSE and SUSE Linux Enterprise}
	\begin{itemize}
		\item See instructions at \url{https://CRAN.R-project.org/bin/linux/suse/}
		\item Add repository/ies for appropriate version of your distribution
		\begin{itemize}
			\begin{footnotesize}
				\item \url{https://download.opensuse.org/repositories/devel:/languages:/R:/patched/} (daily updated) or/and
				\item \url{https://download.opensuse.org/repositories/devel:/languages:/R:/released/} (updated with new R release)
			\end{footnotesize}
		\end{itemize}
		\item Install packages \texttt{R-base} (the R), \texttt{R-base-devel} (required to compile additional R packages --- only some are available in repositories) and optionally \texttt{rstudio} and/or \texttt{rkward}
		\item Install packages \texttt{patterns-openSUSE-devel\_basis} and \texttt{gcc-fortran} for compilation of R packages when installing them from R (only some R packages are available in openSUSE repositories)
		\item RStudio is also available from its \href{https://rstudio.com/products/rstudio/download/\#download}{download page}
	\end{itemize}
\end{frame}

\begin{frame}{Linux --- RedHat, Fedora and derivatives like CENTOS, Scientific Linux, etc.}
	\begin{itemize}
		\item See instructions at \url{https://CRAN.R-project.org/bin/linux/redhat/README}
		\item Install packages \texttt{R-core} (the R), \texttt{R-core-devel} (required to compile additional R packages --- only some are available in repositories) and optionally \texttt{rkward}
		\item RStudio is available from its \href{https://rstudio.com/products/rstudio/download/\#download}{download page}
	\end{itemize}
\end{frame}

\begin{frame}{Important note about names of directories}
	\begin{itemize}
		\item \alert{There must not be any spaces or accented characters in the path to R working directory or local R library}, otherwise some R functions can fail (and there is no other solution)
		\item If the user has e.g. on Windows path like \texttt{C:/Documents and Settings/Šíleně úpějící kůoň/kurzíček}, change it to something like \texttt{C:/Users/username/rcourse}, otherwise user can experience a~lot of problems\ldots
		\item It might be required to make a~new user on the computer\ldots
		\item Similarly on macOS and Linux, avoid directory names with spaces and accented characters
	\end{itemize}
\end{frame}

\begin{frame}{Sources of R packages}
	\label{sources}
	\begin{itemize}
		\item R CRAN \url{https://CRAN.R-project.org/} --- main and largest source of R packages (over 15,000 packages + many orphaned and archived --- abandoned by developers, might be working)
		\item Bioconductor \url{https://bioconductor.org/} --- mainly bioinformatics packages, genomic data (over 1,800 packages)
		\item R-Forge \url{https://r-forge.r-project.org/} (over 2,000 packages)
		\item RForge \url{https://www.rforge.net/} (much smaller)
		\item And more (\href{https://github.com/}{GitHub}), custom webs,~\ldots
		\item Some packages are available from more resources
		\item Same name for function can be used in different packages (there is no central index) --- to distinguish them call functions like this: \texttt{muscle::read.fasta()} vs. \texttt{seqinr::read.fasta()} --- call function \texttt{read.fasta()} from package \texttt{muscle} \alert{or} \texttt{seqinr} (and their parameters can be different\ldots) --- see further
	\end{itemize}
\end{frame}

\begin{frame}{CRAN keeps growing\ldots}
	\begin{center}
		\includegraphics[height=6.5cm]{cran.png}
	\end{center}
\end{frame}

\subsection{Let's start with R}

\begin{frame}{First steps in R}{Recommended is usage of GUI (RKWard or RStudio)}
	\begin{multicols}{2}
		\begin{itemize}
			\item Linux (UNIX): open any terminal, type \texttt{R} and hit Enter
			\item Windows and Mac: find it as normal application in menu
			\item Type commands to work\ldots
			\item \alert{Ever wished to be Harry Potter? Secret spells make magic operations~:-)}
			\item Use arrows up and down to navigate in history
			\item \texttt{Ctrl+R} works as reverse search --- searches text in history
		\end{itemize}
		\columnbreak
		\begin{center}
			\includegraphics[width=4.5cm]{rkonsole.png}
		\end{center}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{How it works}
	\begin{itemize}
		\item General look of R commands:
	\end{itemize}
	\begin{spluscode}
    function(argument1="SomeName", argument2=SomeVariable, argument3=8)
    ModifiedObject <- SomeFunction(argument1=MyData, argument2=TRUE)
	\end{spluscode}
	\begin{itemize}
		\item New/modified object (with data,~\ldots) is on the left: \enquote{\texttt{<-}} says to insert result of the function \texttt{SomeFunction} on the right into the object \texttt{ModifiedObject} on the left
		\item Functions have various parameters/arguments (in brackets, separated by comas): \texttt{argument=ItsValue}
		\item Arguments are named --- if you keep order, no need to name them:
	\end{itemize}
	\begin{spluscode}
    SomeFunction(MyData, TRUE, 123, "SomeName")
	\end{spluscode}
	\begin{itemize}
		\item When only some of the arguments are in use, use the names (order doesn't matter any more)
	\end{itemize}
	\begin{spluscode}
    SomeFunction(argument2=TRUE, argument3=123, argument1=MyData)
	\end{spluscode}
	\begin{itemize}
		\item Some arguments are required, some optional
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Get help in R}
	\begin{spluscode}
    # "#" marks comments - notes within code which are not executed
    help(function) # Help for particular function (package must be loaded)
    ?function # Help for particular function (package must be loaded)
    ??SearchedTerm # Search for the term within all installed packages
    help.search("searched phrase") # Search for the phrase within all
      # installed packages - return list of hits sorted according to
      # type and package (i.e. package::function)
    require(sos) # More comprehensive search from packages
    findFn("function") # Search for function name
	\end{spluscode}
	\vfill
	\alert{\texttt{?}} shows help for questioned function (in console type \texttt{q} to close it):
	\vfill
	\begin{multicols}{2}
		\begin{itemize}
			\item Name of the package (top left)
			\item Function name (headline)
			\item Description
			\item Usage
			\item Comments on arguments
			\item Details
			\item About author(s)
			\item References to cite
			\item Example code
		\end{itemize}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Where we are?}
	\begin{itemize}
		\item In Linux/UNIX, R starts in current directory (use \texttt{cd} to change it before launching R)
		\item \alert{Set and check working directory} in R:
	\end{itemize}
	\begin{spluscode}
    setwd("/some/path/") # Or "~/...". In Windows "C:/..."
    getwd() # Verifies where we are
    dir() # Lists files and folders on the disk
    ls() # Lists currently available R objects
	\end{spluscode}
	\begin{itemize}
		\item In Windows (\textbf{File | working directory}) or in RStudio (\textbf{Session | Set working directory}) set it in menu or by above command
		\item R saves history of commands into file \texttt{.Rhistory} file within working directory (by default hidden in Linux/macOS)
		\item When closing R by \texttt{q()} you can save all R data in \texttt{.RData} (and command history in \texttt{.Rhistory}) file(s) and it/they can be loaded next time
		\item RStudio and RKWard help with this very much
	\end{itemize}
\end{frame}

\begin{frame}{Importance of working directory}
	\begin{itemize}
		\item Default place to load/save, import/export data/results
		\begin{itemize}
			\item It changes paths --- one of the most common mistakes --- something is not found because of wrong path
			\item Private folder for particular R project (task) prevents unwanted inferences with another tools/projects
		\end{itemize}
		\item Without saving and loading the R data next time, it is not possible to do any longer work or to check the work in the future
		\item \alert{Get used that R \textbf{always} work in some directory and by default saves/loads files there}
		\item RStudio and RKWard also save session information (list of opened files,~\ldots) --- very convenient
		\item Regularly save your work to prevent looses in case of crash or any other accident
	\end{itemize}
\end{frame}

\subsection{Basic operations in R}

\begin{frame}{Types of objects}
	\begin{itemize}
		\item \textbf{Vectors} --- numbers or characters
		\item \textbf{Matrices} --- columns are of same type (numeric, character, etc.) and the same length
		\item \textbf{Arrays} --- like matrices, but with possibly more dimensions
		\item \textbf{Data frames} --- more general --- columns can be of different type
		\item \textbf{Lists} --- ordered collections of objects (vectors, matrices,~\ldots) --- not necessarily of the same type
		\item \textbf{Factors} --- a~vector of levels, e.g. populations, colors, etc.
		\item More \enquote{advanced} objects to store plots, genetic data,~\ldots
		\begin{itemize}
			\item Commonly called \enquote{\textbf{S3}} and \enquote{\textbf{S4}} objects in R terminology
			\item Technically commonly just lists putting together various information
			\item We will meet many of them\ldots
		\end{itemize}
	\item Functions require particular object types --- take care about it
	\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Popular object classes (we are going to use)}
	\begin{itemize}
		\item \texttt{AAbin} ---stores amino acid sequences (aligned or not)
		\item \texttt{alignment} --- aligned sequences (seqinr)
		\item \texttt{dapc} --- results of DAPC
		\item \texttt{dist} --- distance matrices
		\item \texttt{DNAbin} --- stores DNA sequences (aligned or not)
		\item \texttt{genind} --- stores various genetic information for individuals
		\item \texttt{genlight} --- variant of genind to store large multiple genomes
		\item \texttt{genpop} --- like genind, but on population level
		\item \texttt{haplonet} --- networks without reticulation
		\item \texttt{haplotype} --- unique sequences from DNAbin
		\item \texttt{hclust} --- output of hierarchical clustering, can be converted to phylo
		\item \texttt{loci} --- extension of data frame (DF), stores information about loci
		\item \texttt{matching} --- binary phylogenetic trees
		\item \texttt{matrix} --- general matrix (numeric or not)
		\item \texttt{pco}; \texttt{dudi} --- results of PCA, PCoA,~\ldots
		\item \texttt{phyDat} --- \enquote{preparation} of data for some phylogenetic analysis
		\item \texttt{phylo} --- phylogenetic information, typically trees
		\item \texttt{phylo4} --- derived from phylo (more data), S4 instead of S3
		\item \texttt{SNPbin} --- stores large SNP data for single genome
		\item \texttt{spca} --- results of sPCA
		\item \texttt{treeshape} --- derived from hclust
		\item \texttt{vcfR} --- imported (and possibly edited) VCF
		\item and more\ldots~common task is converting among formats\ldots
		\item \ldots not all formats are (easily) convertible among each other\ldots
		\item To get information about content of each data type see \texttt{getClassDef("data.frame")} (Or any other class name of loaded package) --- there are information about slots within that classes you can access
	\end{itemize}
\end{frame}

\begin{frame}{Conversions among data types I}
	\begin{tabular}{llll}
		\textbf{From} & \textbf{To} & \textbf{Command} & \textbf{Package}\\
		phylo & phylo4 & \texttt{as(x, "phylo4")} & phylobase\\
		phylo & matching & \texttt{as.matching(x)} & ape\\
		phylo & treeshape & \texttt{as.treeshape(x)} & apTreeshape\\
		phylo & hclust & \texttt{as.hclust(x)} & ape\\
		phylo & prop.part & \texttt{prop.part(x)} & ape\\
		phylo & splits & \texttt{as.splits(x)} & phangorn\\
		phylo & evonet & \texttt{evonet(x, from, to)} & ape\\
		phylo & network & \texttt{as.network(x)} & ape\\
		phylo & igraph & \texttt{as.igraph(x)} & ape\\
		phylo4 & phylo & \texttt{as(x, "phylo")} & phylobase\\
		matching & phylo & \texttt{as.phylo(x)} & ape
	\end{tabular}
\end{frame}

\begin{frame}{Conversions among data types II}
	\begin{tabular}{llll}
		\textbf{From} & \textbf{To} & \textbf{Command} & \textbf{Package}\\
		treeshape & phylo & \texttt{as.phylo(x)} & apTreeshape\\
		splits & phylo & \texttt{as.phylo(x)} & phangorn\\
		splits & networx & \texttt{as.networx(x)} & phangorn\\
		evonet & phylo & \texttt{as.phylo(x)} & ape\\
		evonet & networx & \texttt{as.networx(x)} & ape\\
		evonet & network & \texttt{as.network(x)} & ape\\
		evonet & igraph & \texttt{as.igraph(x)} & ape\\
		haploNet & network & \texttt{as.network(x)} & pegas\\
		haploNet & igraph & \texttt{as.igraph(x)} & pegas\\
		hclust & phylo & \texttt{as.phylo(x)} & ape\\
		hclust & dendrogram & \texttt{as.dendrogram(x)} & stats
	\end{tabular}
\end{frame}

\begin{frame}{Conversions among data types III}
	\begin{tabular}{llll}
		\textbf{From} & \textbf{To} & \textbf{Command} & \textbf{Package}\\
		DNAbin & character & \texttt{as.character(x)} & ape\\
		DNAbin & alignment & \texttt{as.alignment(x)} & ape\\
		DNAbin & phyDat & \texttt{as.phyDat(x)} & phangorn\\
		DNAbin & genind & \texttt{DNAbin2genind(x)} & adegenet\\
		character & DNAbin & \texttt{as.DNAbin(x)} & ape\\
		character & loci & \texttt{as.loci(x)} & pegas\\
		alignment & DNAbin & \texttt{as.DNAbin(x)} & ape\\
		alignment & phyDat & \texttt{as.phyDat(x)} & phangorn\\
		alignment & character & \texttt{as.matrix(x)} & seqinr\\
		alignment & genind & \texttt{alignment2genind(x)} & adegenet
	\end{tabular}
\end{frame}

\begin{frame}{Conversions among data types IV}
	\begin{tabular}{llll}
		\textbf{From} & \textbf{To} & \textbf{Command} & \textbf{Package}\\
		phyDat & DNAbin & \texttt{as.DNAbin(x)} & phangorn\\
		phyDat & character & \texttt{as.character(x)} & phangorn\\
		loci & genind & \texttt{loci2genind(x)} & pegas\\
		loci & data frame & \texttt{class(x) <- "data.frame"} & --- \\
		genind & loci & \texttt{genind2loci(x)} & pegas\\
		genind & genpop & \texttt{genind2genpop(x)} & adegenet\\
		genind & df & \texttt{genind2df(x)} & adegenet\\
		data frame & phyDat & \texttt{as.phyDat(x)} & phangorn\\
		data frame & loci & \texttt{as.loci(x)} & pegas\\
		data frame & genind & \texttt{df2genind(x)} & adegenet\\
		matrix & phyDat & \texttt{as.phyDat(x)} & phangorn
	\end{tabular}
\end{frame}

\begin{frame}{Conversions among data types V}
	\begin{tabular}{llll}
		\textbf{From} & \textbf{To} & \textbf{Command} & \textbf{Package}\\
		vcfR & chromR & \texttt{vcfR2chromR(x)} & vcfR\\
		vcfR & genind & \texttt{vcfR2genind(x)} & vcfR\\
		vcfR & migrate & \texttt{vcfR2migrate(x)} & vcfR\\
		vcfR & loci & \texttt{vcfR2loci(x)} & vcfR\\
		vcfR & tidy & \texttt{vcfR2tidy(x)} & vcfR\\
		vcfR & DNAbin & \texttt{vcfR2DNAbin(x)} & vcfR\\
		vcfR & genlight & \texttt{vcfR2genlight(x)} & vcfR
	\end{tabular}
\end{frame}

\begin{frame}[fragile]{Basic operations with data I}{\alert{R doesn't ask neither notifies when overwriting objects! Be careful!}}
	\begin{spluscode}
    x <- c(5, 6, 7, 8, 9) # Creates vector (see also ?rep)
    x # Print "x" content
    c() # Is generic function to concatenate objects into new one
    length(x) # Length of the object - for matrices and DF use dim()
    str(x) # Information about structure of the object
    mode(x) # Gets type of storage mode of the object
    class(x) # Shows class of the object
    x[2] # Shows second element of the object
    x <- x[-5] # Removes fifth element
    y <- matrix(data=5:20, nrow=4, ncol=4) # Creates a matrix
    is.matrix(y) # Is it matrix? Try is.<TAB><TAB>
    # TAB key shows available functions and objects starting by typed text
    y # Prints the matrix
    y[,2] # Prints second column
    y[3,] # Prints third row
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Basic operations with data II}
	\begin{spluscode}
    y[4,3] # Prints element from fourth row and third column
    x <- y[2,] # Replaces "x" by second row of "y" (no warning)
    rm(x) # Deletes x (no warning)
    y[,1:3] # Prints first through third column of the matrix
    y[3,] <- rep(x=20, each=4) # Replaces third line by value of 20
    y[y==20] <- 10 # If value of y's element is 20, replace it by 10
    summary(y) # Basic statistics - according to columns
    colnames(y) <- c("A", "B", "C", "D") # Set column names
    # Objects and functions are without quotation marks; files and text with
    colnames(y) # Prints column names, use rownames() in very same way
    y[,"C"] # Prints column C (R is case sensitive!)
    t(y) # Transposes the matrix
    y <- as.data.frame(y) # Turns into DF (see other functions as.*)
    y[y==17] <- "NA" # Removes values of 17 (NA = not available = missing)
    y$B # Gets variable B of data frame y ($ works similarly in S3 objects)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Basic operations with data III} % TODO Add more operations
	\begin{spluscode}
    # When loading saved project, you have to load again libraries and
    # scripts (see further), data objects are restored
    save(list=ls(), file="test.RData") # Saves all objects during the work
    load("test.RData") # Loads saved R environment with all objects
    # Use to edit matrices, data frames, functions, ...
    fix(y)
	\end{spluscode}
\end{frame}

\subsection{Packages for our work}

\begin{frame}{Repositories}
	\begin{itemize}
		\item Repositories (internet directories full of R packages --- slide~\ref{sources}) can be set via \texttt{options(repos=c())} or as \texttt{repos} parameter for each \texttt{install.packages()} command (slide~\ref{repos} and onward)
		\item Repositories doesn't have to be set as global options, e.g. Bioconductor has its own way to manage packages
		\item Similar concepts as app stores of Android, iOS, etc.
	\end{itemize}
	\begin{block}{Installation of packages in GUI}
		\begin{itemize}
			\item \textbf{RStudio:} set repositories by command from slide~\ref{repos} and in bottom right pane select \textbf{Packages} and click on \textbf{Install Packages\ldots}
			\item \textbf{RKWard:} go to menu \textbf{Settings | Configure 'RKWard'} and select \textbf{R-Packages}. Add URLs of repositories from slide~\ref{repos}. \textbf{OK}. Go to menu \textbf{Settings | Manage R packages and plugins\ldots}, click to \textbf{Install\ldots}, select and install desired packages\ldots
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}{Theory for packages and their management}
	\begin{itemize}
		\item Standalone plain R doesn't have enough tools for most of scientific disciplines --- only basic methods and tools for programmers, including for package management
		\item Users/developers contribute by making extra packages extending computational possibilities --- one of biggest R advantages --- it then has unlimited possibilities
		\item R has infrastructure for maintaining (for developers) and installing (for users) packages --- the \href{https://CRAN.R-project.org/}{CRAN} repository
		\item For various reasons, some people build their own infrastructures to maintain and install R packages --- compatible with R, bud separated
		\item User has basically two options
		\begin{enumerate}
			\item Set all repositories in R and use basic commands to install packages (slide~\ref{repos})
			\item Specify non-CRAN repository every time installing from it (e.g. slide~\ref{sources-diff}) or use special tools (e.g. for \href{https://bioconductor.org/install/}{Bioconductor} --- slide~\ref{bioc})
		\end{enumerate}
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Set repositories}
	\label{repos}
	\begin{spluscode}
    # Basic package installation
    install.packages("PackageName") # Case sensitive!
    ?install.packages # Shows all available parameters (options)
    getOption("repos") # Shows actual repositories
    options(repos=c("https://mirrors.nic.cz/R/",
      "https://r-forge.r-project.org/", "https://rforge.net/"))
    options() # Generic function to modify various settings
    ?options # Gives details
	\end{spluscode}
	\begin{itemize}
		\item \alert{Keep newest version of R and and newest versions of packages!}
		\item Installation of multiple packages may sometimes fail --- install then packages in smaller groups or one by one --- check output and examine why installation failed --- commonly due to missing external dependency (read installation output and look for notes about missing libraries, etc.)
		\item Avoid mixing of several R versions
		\item After upgrade of R (e.g. from 3.5 to 3.6), user must reinstall all packages
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Install packages}
	\begin{itemize}
		\item If repositories from slide~\ref{repos} are not set, it is possible to install in several steps packages from main repository (CRAN) and from another sources (following slides)
		\item This is the basic and default the most common usage
		\item After upgrade of R (e.g. from 3.5 to 3.6), all packages must be reinstalled
	\end{itemize}
	\begin{spluscode}
    # Simplest usage
    install.packages("PackageName") # Case sensitive!
    ?install.packages # See for more options
    install.packages(pkgs=c("pkg1", "pkg2", "pkg3", ...),
      repos=getOption("repos"), dependencies=TRUE)
    # Installed packages are "inactive" - the must by loaded to use them:
    library(PackageName) # Loads installed package (we will do it on the fly)
    # Updates installed packages (by default from CRAN)
    update.packages(repos=getOption("repos"), ask=FALSE)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Install packages needed for the course}
	\begin{spluscode}
    # Install packages
    # Installation of multiple packages may sometimes fail - install then
    # packages in smaller groups or one by one
    install.packages(pkgs=c("ade4", "adegenet", "adegraphics", "adephylo",
      "akima", "ape", "BiocManager", "caper", "corrplot", "devtools",
      "gee", "geiger", "ggplot2", "gplots", "hierfstat", "ips", "kdetrees",
      "lattice", "mapdata", "mapplots", "mapproj", "maps", "maptools",
      "nlme", "PBSmapping", "pegas", "phangorn", "philentropy", "phylobase",
      "phytools", "picante", "plotrix", "poppr", "raster", "rgdal",
      "RgoogleMaps", "Rmpi", "rworldmap",  "rworldxtra", "seqinr",
      "shapefiles", "snow", "sos", "sp", "spdep", "splancs", "StAMPP",
      "TeachingDemos", "tripack", "vcfR", "vegan"),
      repos="https://mirrors.nic.cz/R/", dependencies="Imports")
    # Regularly update installed packages
    update.packages(ask=FALSE)
    # Upgrade all packages e.g. from R 3.5 to 3.6
    install.packages(pkgs=installed.packages())
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Install Geneland package}
	\label{Geneland}
	\begin{itemize}
		\item Since version 4, not in CRAN anymore, check its \href{https://i-pri.org/special/Biostatistics/Software/Geneland/Geneland-Doc.pdf}{manual}, \href{https://github.com/gilles-guillot/Geneland}{GitHub} and homepage \url{https://i-pri.org/special/Biostatistics/Software/Geneland/}
		\item On Windows install \href{https://cran.r-project.org/bin/windows/Rtools/}{Rtools} first to be able to compile source package on Windows
	\end{itemize}
	\begin{spluscode}
    # Other packages used when using Geneland
    # Needed is PBSmapping or mapproj for conversion of coordinates
    # GUI uses for parallelisation snow and Rmpi
    # RgoogleMaps (requires rgdal) can be used to plot output on top of Google
    # map, maptools, shapefiles (requires foreign) and tripack on GIS layer
    install.packages(pkgs=c("PBSmapping", "mapproj", "rgdal", "RgoogleMaps",
      "Rmpi", "sp", "maptools", "shapefiles", "snow", "tripack"),
      repos="https://mirrors.nic.cz/R/", dependencies="Imports")
    # Install Geneland from GitHub
    # Devtools package is required to install from GitHub
    if(! "devtools" %in% installed.packages()) {install.packages("devtools")}
    # Install Geneland itself
    devtools::install_github("gilles-guillot/Geneland")
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Install phyloch package}{Example of installation of package not available in any repository}
	\label{phyloch}
	\begin{itemize}
		\item Check \url{http://www.christophheibl.de/Rpackages.html}
		\item Package phyloch is similar to \href{https://CRAN.R-project.org/package=ips}{ips} from same author (but some functions behave differently) --- both are great for usage of external applications within R, ips seems to develop more and phyloch will probably be deprecated\ldots
	\end{itemize}
	\begin{spluscode}
    # If not done already, install required packages first
    install.packages(pkgs=c("ape", "colorspace", "XML"), dependencies=TRUE)
    # It is possible to specify direct path
    # Local or web URL - be careful about correct path) to package source
    install.packages(pkgs="http://www.christophheibl.de/phyloch_1.5-3.tar.gz",
      repos=NULL, type="source")
    # If above command fails on Windows, try
    install.packages(pkgs="http://www.christophheibl.de/phyloch_1.5-3.zip",
      repos=NULL)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Bioconductor}
	\label{bioc}
	\begin{itemize}
		\item Tools for analysis of genomic data, see \url{https://bioconductor.org/}
		\item To install it, add appropriate repositories (repository has its own version number not strictly following R, see \href{https://bioconductor.org/install}{web}) and \textbf{use Bioconductor's special helper package}
		\item Explore available packages: \href{https://bioconductor.org/packages/}{https://bioconductor.org/packages/release/BiocViews.html}
	\end{itemize}
	\begin{spluscode}
    # Install CRAN package BiocManager used to manage Bioconductor packages
    if (!requireNamespace("BiocManager")) install.packages("BiocManager")
    ?BiocManager::install # See options
    # Install Bioconductor packages
    BiocManager::install("muscle") # Simplest usage
    BiocManager::install(pkgs=c("Biostrings", "muscle"))
    # Update installed packages
    BiocManager::install()
    # Search for Bioconductor packages
    BiocManager::available() # List everything
    ?BiocManager::available # See options
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Bioconductor and others --- differences from another repositories}{Bioconductor has its own installation method}
	\label{sources-diff}
	\begin{spluscode}
    # Standard installation
    install.packages(c("adegenet", "poppr", "phytools"))
    update.packages() # Update packages
    # Installation from custom repository (example for our course)
    install.packages(pkgs="ParallelStructure",
      repos="https://r-forge.r-project.org/")
    ?install.packages # See help for details
    # Install CRAN package BiocManager used to manage Bioconductor packages
    if (!requireNamespace("BiocManager")) install.packages("BiocManager")
    # Install Bioconductor packages
    BiocManager::install("muscle") # Simplest usage
    BiocManager::install(pkgs=c("Biostrings", "muscle"))
    ?BiocManager::install # See more options
    BiocManager::install() # Update installed packages
	\end{spluscode}
\end{frame}

\begin{frame}[allowframebreaks]{Non-R software}
	\begin{itemize}
		\item We use several software packages outside R
		\begin{itemize}
			\item R functions can use this software
			\item External software can be used (depending on R package) to create/modify R object, or just as different method for (batch) usage of the software (similarly to BASH, Python, etc.)
			\item User must install this software manually
		\end{itemize}
		\item Clustal (W/X; Omega is not used in the course) \url{http://clustal.org/}
		\begin{itemize}
			\item Aligner of sequences (from slide~\ref{alignment})
		\end{itemize}
		\item Gdal \url{https://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries}
		\begin{itemize}
			\item Recommended for conversion of coordinates for Geneland (from slide~\ref{GenelandUse}), loading of SHP files, etc.
		\end{itemize}
		\item GIMP \url{https://www.gimp.org/}
		\begin{itemize}
			\item Image manipulation, free open-source alternative to products of Adobe or Corel
			\item Optional, one of possibilities to view and edit output graphics from R
		\end{itemize}
		\item Inkscape \url{https://inkscape.org/}
		\begin{itemize}
			\item Vector drawing, free open-source alternative to products of Adobe or Corel
			\item Optional, one of possibilities to view and edit output graphics from R
		\end{itemize}
		\item MAFFT \url{https://mafft.cbrc.jp/alignment/software/}
		\begin{itemize}
			\item Aligner of sequences (from slide~\ref{alignment})
		\end{itemize}
		\item MPI \url{http://fisher.stats.uwo.ca/faculty/yu/Rmpi/}
		\begin{itemize}
			\item Library for parallelisation used by \href{https://CRAN.R-project.org/package=Rmpi}{Rmpi} package (optional, recommended especially on Windows, macOS and Linux have more options for parallelisation)
			\item If it is not available, respective function can sometimes use different parallelisation backend or user can turn off parallelisation for respective function
		\end{itemize}
		\item MUSCLE \url{https://www.drive5.com/muscle/}
		\begin{itemize}
			\item Aligner of sequences (from slide~\ref{alignment})
		\end{itemize}
		\item proj \url{https://proj4.org/download.html}
		\begin{itemize}
			\item Required for conversion of coordinates for Geneland (from slide~\ref{GenelandUse})
		\end{itemize}
		\item Rtools \url{https://cran.r-project.org/bin/windows/Rtools/}
		\begin{itemize}
			\item \alert{On Windows only} --- to be able to compile source packages on Windows
		\end{itemize}
		\item Structure \url{https://web.stanford.edu/group/pritchardlab/structure.html} (optionally also \href{https://web.stanford.edu/group/rosenberglab/clumpp.html}{CLUMPP} and \href{https://web.stanford.edu/group/rosenberglab/distruct.html}{distruct} --- not part of the course)
		\begin{itemize}
			\item De facto standard for analysis of population genetic structure (from slide~\ref{structure})
			\item Its outputs are usually post-processed in other software (not part of the course, see \href{https://trapa.cz/en/structure-r-linux}{web})
		\end{itemize}
	\end{itemize}
\end{frame}

\section{Data}

\begin{frame}{Our data}{Import and export of data we will use through the course, data types}
	\tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
\end{frame}

\subsection[Overview]{Overview of data and data types}

\begin{frame}[allowframebreaks]{Brief overview of molecular data types}{Sorted with respect to usage in R}
	\begin{itemize}
		\item \textbf{\href{https://en.wikipedia.org/wiki/Isozyme}{Isozymes}} --- forms of proteins differing in electrophoresis by their weight and/or charge
		\begin{itemize}
			\item Typically coded as presence/absence (1/0) data
			\item Old fashioned, but same mathematical tools can be used to analyze any presence/absence (1/0) matrices
		\end{itemize}
		\item \textbf{Fragmentation data} --- length polymorphism
		\begin{itemize}
			\item Codominant data --- e.g. \href{https://en.wikipedia.org/wiki/Microsatellite}{microsatellites} (SSRs --- Simple Sequence Repeats)
			\begin{itemize}
				\item Variability in number of short (usually 1--3~bp) oligonucleotide repeats (ATAT vs. ATATAT, typically ca. 25--250 repeats) bordered by unique primer sequences
				\item Very variable, fast evolving, species-specific primers needed
				\item Mainly for population genetics, relationships among closely related species
				\item Similarly ISSRs (Inter Simple Sequence Repeats)
			\end{itemize}
			\item Presence/absence (1/0) dominant data
			\begin{itemize}
				\item The allele \textbf{is} or \textbf{is not} present  --- it is impossible to distinguish heterozygots from dominant homozygots
				\item \href{https://en.wikipedia.org/wiki/Amplified_fragment_length_polymorphism}{AFLP} (Amplified Fragment Length Polymorphism) --- very variable, technically complicated, nowadays bit expensive and outdated
				\item Simpler methods \href{https://en.wikipedia.org/wiki/RAPD}{RAPD} (Random Amplified Polymorphic DNA) and \href{https://en.wikipedia.org/wiki/Restriction_fragment_length_polymorphism}{PCR-RFLP} (Polymerase Chain Reaction-Restriction Fragment Length Polymorphism) are not used anymore at all
			\end{itemize}
		\end{itemize}
		\item \textbf{Protein sequences} --- not used in the course
		\begin{itemize}
			\item Apart similar usage as with DNA/RNA (sequence analysis) it is possible to work with the structure and conformation of the proteins
			\item R (especially \href{https://bioconductor.org/}{Bioconductor}) has plenty of packages for specialized protein analysis and more
		\end{itemize}
		\item \textbf{\href{https://en.wikipedia.org/wiki/Nucleic_acid_sequence}{Nucleic acid sequences}} (in nearly any form) --- DNA or RNA
		\begin{itemize}
			\item From \enquote{classical} Sanger sequencing --- long individual reads
			\item From modern \href{https://en.wikipedia.org/wiki/DNA_sequencing\#High-throughput_methods}{HTS (NGS)} --- \href{https://en.wikipedia.org/wiki/Pyrosequencing}{454 pyrosequencing}, \href{https://en.wikipedia.org/wiki/Illumina_dye_sequencing}{Illumina},~\ldots{ }methods
			\begin{itemize}
				\item Probably most used are \href{https://en.wikipedia.org/wiki/Restriction_site_associated_DNA_markers}{RADseq} scanning whole genome, \href{https://bsapubs.onlinelibrary.wiley.com/doi/abs/10.3732/apps.1400042}{HybSeq} and other \href{https://en.wikipedia.org/wiki/Exome_sequencing}{target enrichment} methods using specific probes to sequence only single/low-copy nuclear markers, \href{https://bsapubs.onlinelibrary.wiley.com/doi/abs/10.3732/ajb.1100335}{Genome Skimming} getting the most abundant part of the genome (plastid and mitochondrial sequences and ITS1-5.8S rRNA-ITS2 region), \href{https://en.wikipedia.org/wiki/Genotyping_by_sequencing}{Genotyping by sequencing (GBS)}; and their variants
				\item There are special tools to process raw data from the machines --- not part of the course
				\item Modern methods are quickly developing and able to produce $\sim$10$^{12}$~bp per run and multiplex many individuals
			\end{itemize}
			\item Whole sequences (probes/loci or longer assembled regions) or \href{https://en.wikipedia.org/wiki/Single-nucleotide_polymorphism}{SNPs} (\href{https://en.wikipedia.org/wiki/SNP_genotyping}{Single Nucleotide Polymorphism} --- only polymorphic sites are retained)
		\end{itemize}
		\item Most of methods are mathematically well defined for haploids and/or diploids, higher ploidies or mixing of ploidies is not always possible
		\item Most of methods shown in the course work with more data types --- not every variant is shown
		\begin{itemize}
			\item Explore more options yourselves
		\end{itemize}
		\item For details about the molecular markers check specialized course like \href{https://is.cuni.cz/studium/eng/predmety/index.php?do=predmet&kod=MB120P44}{Use of molecular markers in plant systematics and population biology} (\href{https://is.cuni.cz/studium/predmety/index.php?do=predmet&kod=MB120P44}{česky})
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{R training data}
	\begin{itemize}
		\item R packages commonly contain training data to illustrate its abilities
		\item We will use some of them during the course
		\item We will also use data provided by the teacher and/or his colleagues
	\end{itemize}
	\begin{spluscode}
    data() # List data available in currently loaded packages
    # List data available in all installed packages (can be very long)
    data(package=rownames(installed.packages()))
    # Load selected data set; for example phylogeny and species traits
    # of shorebirds from package caper (we will use it much later)
    data(shorebird, package="caper")
    # Optional method (load respective library and then data)
    library(caper) # Library containing (among others) desired data
    data(shorebird) # Loading the data
    ?shorebird # See content of the dataset # or ?caper::shorebird
    ?adegenet::microbov
    ?adegenet::rupica
    ?ape::carnivora
	\end{spluscode}
\end{frame}

\begin{frame}[allowframebreaks]{Our data\ldots}
	\begin{itemize}
		\item We will use
		\begin{itemize}
			\item Modified subset of diploid microsatellite data of \textit{Taraxacum haussknechtii} (Asteraceae) from Macedonia by \href{https://trapa.cz/en/taraxacum-section-dioszegia}{Zeisek et al 2015}
			\item Modified subset of triploid microsatellite data of several species of \textit{Taraxacum} sect. \textit{Taraxacum} (Asteraceae) --- \textit{T.~alatum}, \textit{T.~ekmanii}, \textit{T.~hemicyclum} and \textit{T.~hepaticum} from central and northern Europe by \href{https://trapa.cz/en/identif-oligoclonal-agamospermous-microsp}{Kirschner et al 2016}
			\item Small subset of population AFLP data of \textit{Cardamine amara} (Brassicaceae) from Europe by \href{https://botany.natur.cuni.cz/brassiploidy/people}{Karol Marhold} and his team
			\item Small subset of non-synonymous SNPs from \href{https://www.arabidopsis.org/servlets/TairObject?type=locus&name=At2g46980}{ASY3} gene (required for meiosis) from diploids and tetraploids of \textit{Arabidopsis arenosa} (Brassicaceae) from central and northern Europe by \href{https://botany.natur.cuni.cz/ecolgen/people}{Magdalena Bohutínská} and her colleagues
			\item Small subset of trees and taxa from phylogeny of \textit{Oxalis} spp. (Oxalidaceae) from South Africa (the Cape region) by \href{https://onlinelibrary.wiley.com/doi/full/10.1111/1755-0998.12487}{Schmickl et al. 2016}
			\item Partial mitochondrial sequence of mm18 control region of \textit{Meles meles} (Mustelidae) from \href{https://www.nature.com/articles/hdy201445}{Frantz et al 2014} downloaded from \href{https://www.ncbi.nlm.nih.gov/popset/608602125}{GenBank}
			\item Maturase K~(matK) plastid sequences of \textit{Nothofagus} (Nothofagaceae) downloaded from \href{https://www.ebi.ac.uk/}{EMBL-EBI} (various authors)
			\item Phylogeny of selected species of Apiaceae reconstructed from several concatenated plastid genes downloaded from \href{https://www.ncbi.nlm.nih.gov/}{GenBank} and simulated trait
			\item Training data from packages \textbf{Adegenet} (sequence of influenza from USA sampled in several years; SSRs genotypes of cattle breeds, \texttt{?adegenet::microbov}; and \textit{Rupicapra rupicapra} (Bovidae) SSRs genotypes from French Bauges mountains, \texttt{?adegenet::rupica}), \textbf{ape} (morphological traits of Carnivora, \texttt{?ape::carnivora}) and \textbf{caper} (phylogeny and morphological traits of shorebirds, \texttt{?cape::shorebird})
		\end{itemize}
		\item Work with microsatellites is in most cases (except some methods taking advance from microsatellite mutational nature) same as with presence-absence data and methods can handle both data types in nearly same fashion
		\begin{itemize}
			\item Examples are shown mainly with microsatellites, but AFLP and another presence-absence (1/0) data are used in same way --- try it
		\end{itemize}
		\item Distance-based methods are same regardless input data on the beginning (microsatellites, AFLP, DNA sequences,~\ldots)
		\item Extraction of SNP from DNA is useful in case of huge data sets --- for smaller data sets it is not necessary
		\item Many methods can process (nearly) any input data type
	\end{itemize}
	\begin{alertblock}{Always save your work!}
		\alert{We will use data objects during whole course --- all the time save your workspace!} Use possibilities of your GUI or \texttt{save}/\texttt{load} functions.
	\end{alertblock}
\end{frame}

\begin{frame}[allowframebreaks]{Input/output data formats}{Representative selection}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Binary_Alignment_Map}{\textbf{BAM}} (Binary Alignment Map)
		\begin{itemize}
			\item Compressed version of SAM (see below)
			\item Suffix \texttt{*.bam}
		\end{itemize}
		\item \href{https://en.wikipedia.org/wiki/Comma-separated_values}{\textbf{CSV}} (Comma Separated Values)
		\begin{itemize}
			\item \enquote{One sheet of Excel}
			\item Common format to store data (traits, coordinates,~\ldots), similar to TSV
			\item Columns (cells) are separated by commas, cells are commonly bordered by quotation marks --- it is important to check structure before import into R (and very it after import)
			\item Suffix usually \texttt{*.csv}
		\end{itemize}
		\item \href{https://en.wikipedia.org/wiki/FASTA_format}{\textbf{FASTA}}
		\begin{itemize}
			\item Simple and popular text format to store genetic sequences (DNA, RNA, proteins)
			\item \textbf{Line 1} of every records starts with \texttt{>} and contain name/description of the sequence (e.g. \texttt{> Seq 1}), \textbf{line 2+} contain(s) the sequence (\texttt{ATCG...}) --- until end of file or next line starting with \texttt{>}
			\item Suffix usually \texttt{*.fasta} (generic, also \texttt{*.fas}, \texttt{*.fa}, \texttt{*.seq}, \texttt{*.fsa}), \texttt{*.fna} (nucleic acid), \texttt{*.ffn} (nucleotides, coding regions), \texttt{*.faa} (amino acids), \texttt{*.frn} (non-coding RNA)
		\end{itemize}
		\item \href{https://en.wikipedia.org/wiki/FASTQ_format}{\textbf{FASTQ}}
		\begin{itemize}
			\item Text based format to store sequences (mainly nucleotides)
			\item Every record consists of \textbf{4~lines}: (\textbf{1}) sequence ID (with possible description) starting with \texttt{@}, (\textbf{2}) the sequence (\texttt{ATCG...}), (\textbf{3}) \texttt{+} optionally followed by the same ID as line 1, and (\textbf{4}) quality values for nucleotides from line 2
			\item Common format for output of modern high throughput sequencing machines (e.g. Illumina)
			\item Commonly compressed by \texttt{gzip} (\texttt{*.gz}), sometimes by other compression application
			\item Suffix usually \texttt{*.fastq}, \texttt{*.fq}, \texttt{*.fastq.gz}, \texttt{*.fq.gz},~\ldots
		\end{itemize}
		\item \href{https://en.wikipedia.org/wiki/Newick_format}{\textbf{NEWICK}}
		\begin{itemize}
			\item Every line contains one tree represented by brackets, optionally with numbers (separated by \texttt{:}) labeling nodes and/or branches (bootstrap supports, likelihoods, branch lengths, ages,~\ldots)
			\item E.g. \texttt{(A,B,(C,D)E)F;} or \texttt{(A:0.1,B:0.2,(C:0.3,D:0.4):0.5);}
			\item Suffix usually \texttt{*.newick}, \texttt{*.nwk}, \texttt{*.tre},~\ldots
		\end{itemize}
		\item \href{https://en.wikipedia.org/wiki/Nexus_file}{\textbf{NEXUS}}
		\begin{itemize}
			\item Popular plain text format used by software like \href{https://mesquiteproject.org/}{Mesquite}, \href{https://nbisweden.github.io/MrBayes/}{MrBayes}, \href{https://paup.phylosolutions.com/}{PAUP*}, \href{http://www.splitstree.org/}{SplitsTree},~\ldots
			\item Structure can be complex, is divided into blocks containing e.g. sequences, trees (in NEWICK format), distance matrix, fragmentation data, networks (e.g. for SplitsTree), MrBayes commands, traits,~\ldots
			\item Several variants, sometimes problems with interoperability
			\item Suffix usually \texttt{*.nexus}, \texttt{*.nex}, \texttt{*.nxs}
		\end{itemize}
		\item \href{https://en.wikipedia.org/wiki/SAM_(file_format)}{\textbf{SAM}} (Sequence Alignment Map)
		\begin{itemize}
			\item Text-based format for storing biological sequences aligned to a~reference sequence
			\item Structure is relatively complex
			\item Used by applications like \href{https://github.com/pezmaster31/bamtools/wiki}{bamtools} or \href{https://www.htslib.org/}{SAMtools}
			\item Suffix usually \texttt{*.sam}
		\end{itemize}
		\item \href{https://en.wikipedia.org/wiki/Tab-separated_values}{\textbf{TSV}} (TAB separated values)
		\begin{itemize}
			\item \enquote{One sheet of Excel}
			\item Common format to store data (traits, coordinates,~\ldots), similar to CSV
			\item Columns (cells) are separated by tabs (\texttt{\textbackslash t}) --- it is important to check structure before import into R (and verify it after import)
			\item Suffix usually \texttt{*.tsv}, \texttt{*.tab}
		\end{itemize}
		\item \href{https://en.wikipedia.org/wiki/Text_file}{\textbf{TXT}}
		\begin{itemize}
			\item Plain text file can contain content of all listed file formats (except binary BAM) --- suffix (\texttt{*.txt}) is not really reliable\ldots
			\item Technically, all listed plain text formats belong also to this category
		\end{itemize}
		\item \href{https://en.wikipedia.org/wiki/Variant_Call_Format}{\textbf{VCF}} (Variant Call Format)
		\begin{itemize}
			\item Do not confuse with \href{https://en.wikipedia.org/wiki/VCard}{vCard} (\texttt{*.vcf}, \texttt{*.vcard}) storing virtual business cards and address books
			\item Bioinformatics plain text format storing gene variants, annotations, quality data and more information
			\item Used by software like \href{https://samtools.github.io/bcftools/}{Bcftools}, \href{https://gatk.broadinstitute.org/hc/en-us}{GATK}, \href{https://broadinstitute.github.io/picard/}{Picard}, \href{https://vcftools.github.io/}{VCFtools},~\ldots
			\item Complex structure, sequences are not stored as in FASTA, but as SNP variants on respective positions --- useful to store processed NGS/HTS data (e.g. from Illumina machines)
			\item Commonly compressed by \texttt{gzip} (\texttt{*.gz}), sometimes by other compression application
			\item Several versions and variants (including binary BCF, \texttt{*.bcf}), sometimes there are problems with interoperability
			\item Suffix usually \texttt{*.vcf} or \texttt{*.vcf.gz}
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Examples of data and formats I --- AFLP (presence/absence) gel and microsatellites from sequencing machine}
	\begin{center}
		\includegraphics[width=\textwidth-1cm]{aflp_ssrs.png}
	\end{center}
\end{frame}

\begin{frame}{Examples of data and formats II --- Aligned DNA sequences displayed in Geneious}
	\begin{center}
		\includegraphics[width=\textwidth-4cm]{alignment_geneious.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Examples of data and formats III --- FASTA and FASTQ sequences in text view}
	\begin{spluscode}
    > CY013200
    atgaagactatcattgctttgagctacattttatgtctggttttcgctcaaaaacttcccctagtgaaaaca
    ggaaatgacaacagcacagcaacgctgtgcctgggacaccatgcagtgccaaacggaacgatcacgaatgat
    > CY013781
    atgaagactatcattgctttgagctacattttatgtctggttttcgctcaaaaacttccccaaattgaagtg
    ... # FASTA continues...
	\end{spluscode}
	\vfill
	\begin{spluscode}
    @7001425F:141:CAV4JANXX:3:1104:1496:1976 1:N:0:GTGTCC
    NCGATTCATTTTAGCAATTAGACGTGAAGGTCTCTTGATGAAAGACACTAACGAACTCTTTCCTTGGACACC
    +
    #<<BBFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
    @7001425F:141:CAV4JANXX:3:1104:1250:1987 1:N:0:GTGTCC
    TCGATTCACTGAACTGAATGTCCGACAAACTTTAGTTTGTCGTTTCTACCTCACCAAAGTTCGGAGCTTCGA
    +
    ... # FASTQ continues...
	\end{spluscode}
\end{frame}

\begin{frame}{Examples of data and formats IV --- BAM displayed in IGV}{It contains Illumina short reads mapped to reference}
	\begin{center}
		\includegraphics[width=\textwidth-4cm]{bam_igv.png}
	\end{center}
\end{frame}

\begin{frame}{Examples of data and formats V --- VCF with multiple samples displayed in IGV}{Variants of alleles and depth of coverage for each sample, mapped to reference}
	\begin{center}
		\includegraphics[width=\textwidth-1.5cm]{vcf_igv.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Examples of data and formats VI --- Parts of VCF in text view}
	\begin{spluscode}
    ... # Header
    ##ALT=<ID=NON_REF,Description="Represents any possible alternative al...
    ##FILTER=<ID=DP_4,Description="DP < 4">
    ... # Information about data stored
    ##INFO=<ID=AC,Number=A,Type=Integer,Description="Allele count in geno...
    ##INFO=<ID=AF,Number=A,Type=Float,Description="Allele Frequency, for ...
    ... # Information about chromosomes etc.
    ##contig=<ID=scaffold_1,length=33132539>
    ##contig=<ID=scaffold_2,length=19320864>
    ... # The data (variants of nucleotides)
    #CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMA...
    scaffold_4      22846289        .       C       A       91.52   PASS ...
    scaffold_4      22846291        .       C       T       325.58  PASS ...
    ...AC=1;AF=1.057e-03;AN=946;BaseQRankSum=0.825;ClippingRankSum=0.118;...
    ...DP=4046;ExcessHet=3.0302;FS=0.000;InbreedingCoeff=-0.0096;MQ=79.24...
    ... # More data...
	\end{spluscode}
\end{frame}

\begin{frame}[allowframebreaks]{Notes about paths to import the data}
	\label{path}
	\begin{itemize}
		\item Generally, R can accept nearly any local or web location
		\item If unsure where you are, open any file manager, go to the R working directory (verify with \texttt{getwd()} and \texttt{dir()}) and verify where everything is
		\item Web locations start with \texttt{https://}, \texttt{http://} or \texttt{ftp://}, e.g. \texttt{FileParameter="https://server.cz/directory/file.txt"}
		\item Local paths (within one computer) can be absolute or relative
		\begin{itemize}
			\item Absolute paths start from the top of files hierarchy: on UNIX (Linux, macOS,~\ldots) it use to look like \texttt{/home/USER/}, on Windows like \texttt{C:/} (e.g. \texttt{FileParameter="/path/to/some/file.txt"})
			\item Relative paths start in current directory (so \textbf{no} with \texttt{/} or \texttt{C:})
			\begin{itemize}
	\item In the easiest case the input file is in same directory as is R's working directory --- verify by \texttt{getwd()} and \texttt{dir()} --- you then need to specify only the filename (e.g. \texttt{FileParameter="SomeFile.txt"})
	\item For subdirectory start with its name (\textbf{no} with \texttt{/} or \texttt{C:}), e.g. \texttt{FileParameter="subdirectory/another/directory/file.txt"}
	\item When going directory up, use one \texttt{..} for each level, e.g. \texttt{FileParameter="../upper/directory/file.txt"}
	\item On UNIX (macOS, Linux,~\ldots) tilde \texttt{\textasciitilde} means user's home directory (e.g. \texttt{/home/USER/}), so \texttt{FileParameter="\textasciitilde/some/file.txt"} is same as \texttt{FileParameter="/home/USER/some/file.txt"}
			\end{itemize}
			\item If loading data from computer, carefully check the paths or \textbf{use function \texttt{file.choose()} to interactively pick up the file anywhere in the computer} --- it can replace nearly any filename parameter (e.g. \alert{\texttt{FileParameter=file.choose()}})
		\end{itemize}
		\item Some R functions have problems with spaces and special (non-alphanumeric and accented) characters --- Avoid them!
		\item One of the most common source of errors --- \textbf{when the command fails, double check paths} (and Internet connection, if applicable) --- for another common problems see slide~\ref{problems}
	\end{itemize}
	\begin{alertblock}{Working in dedicated directory}
		\textbf{R} always work in some directory (see by \texttt{getwd()}) and by default load input files from there (see them by \texttt{dir()}) and save output there --- relative paths starts there. This is common source of confusion and errors for beginners.
	\end{alertblock}
\end{frame}

\begin{frame}[fragile]{Population genetics and phylogenetics in R}{Microsatellites, AFLP, SNP \& sequences}
	\begin{multicols}{2}
		\begin{itemize}
			\item Now we will use mainly packages \href{http://adegenet.r-forge.r-project.org/}{adegenet} and \href{https://grunwaldlab.github.io/poppr/}{poppr}
			\item Other important genetic packages: \href{http://ape-package.ird.fr/}{ape}, \href{http://pbil.univ-lyon1.fr/ADE-4/}{ade4} and \href{http://ape-package.ird.fr/pegas.html}{pegas}
			\item Dominant/co-dominant marker data of any ploidy level including SSRs, SNP, and AFLP are analyzed in same way
			\item Most of methods are available for polyploids (although not all)
			\item Some methods are unavailable for dominant (presence/absence) data
			\item Mixing of ploidy levels is tricky (but possible) --- it doesn't matter when data are encoded as PA, otherwise it is mathematically problematic
		\end{itemize}
		\begin{spluscode}
    library(ape)
    library(ade4)
    library(adegenet)
    library(pegas)
    library(poppr)
		\end{spluscode}
	\end{multicols}
\end{frame}

\subsection{Microsatellites}

\begin{frame}[fragile]{Load data}
	\begin{spluscode}
    # Source data
        pop  msta93 msta101 msta102 msta103 msta105 msta131 ...
    H01  He 269/269 198/198 221/223 419/419 197/197 196/196 ...
    H02  He 275/283 198/198 221/223 419/419 193/193 168/190 ...
    ... ...     ...     ...     ...     ...     ...     ... ...
    # Loading the data
    # Load training data (Taraxacum haussknechtii from Macedonia)
    hauss.loci <- read.loci(file="https://soubory.trapa.cz/rcourse/
      haussknechtii_ssrs.txt", header=TRUE, loci.sep="\t", allele.sep="/",
      col.pop=2, col.loci=3:14, row.names=1) # \t means TAB key
    hauss.loci # Data control
    print(hauss.loci, details=TRUE)
	\end{spluscode}
	\vfill
	\begin{footnotesize}
		First line starts with empty cell (if \texttt{header} is presented), there can be any extra column, take care about \texttt{col.loci}. \texttt{row.names} are individual names (first column). Take care about \texttt{loci.sep} (here TAB \texttt{\textbackslash t}) and \texttt{allele.sep} (here \texttt{/}) \alert{according to data formatting}.
	\end{footnotesize}
	\vfill
\end{frame}

\begin{frame}[fragile]{Prepare genind object for analysis and load coordinates}
	\begin{spluscode}
    # Conversion of loci to genind - used for many analysis
    hauss.genind <- loci2genind(hauss.loci)
    pop(hauss.genind) # See population names
    hauss.genind$pop # "$" separates extra slots within object
	\end{spluscode}
	\begin{spluscode}
    # Source data
    Ind      lon   lat
    H01  21.3333  41.1
    ...      ...   ...
    # Read coordinates
    hauss.coord <- read.csv("https://soubory.trapa.cz/rcourse/haussknechtii_
      coordinates.csv", header=TRUE, sep="\t", quote="", dec=".", row.names=1)
    hauss.coord
	\end{spluscode}
	\begin{itemize}
		\item Coordinates can be in any projection or scale --- according to aim
		\item Take care about parameters of \texttt{read.csv()}! See \texttt{?read.csv}
		\item \texttt{pegas::geod} calculates geodesic distances (on Earth surface)
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Add coordinates to genind and create genpop object}
	\begin{spluscode}
    # Add coordinates - note identification of slots within object
    hauss.genind$other$xy <- hauss.coord
    hauss.genind$other$xy # See result - the coordinates
    hauss.genind # See result - whole object
    # Conversion to genpop - for population-level analysis
    hauss.genpop <- genind2genpop(hauss.genind, process.other=TRUE)
    hauss.genpop # See result
    # Removes missing data - see ?missingno for types of dealing them
    # Use with caution! It modifies original data!
    hauss.genind.cor <- missingno(pop=hauss.genind, type="mean", cutoff=0.1,
      quiet=FALSE)
    ?missingno # See other options of handling missing data
    # Convert corrected genind to loci
    hauss.loci.cor <- genind2loci(hauss.genind.cor)
    # Writes loci file to the disk
    write.loci(hauss.loci.cor, file="hauss.loci.cor.txt", loci.sep="\t",
      allele.sep="/")
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Import existing data set from popular software}
	\begin{spluscode}
    read.genalex() # poppr - reads *.csv file
    read.fstat() # adegenet - reads *.dat files, only haploid/diploid data
    read.genetix() # adegenet - reads *.gtx files, only ha/diploid data
    read.genepop() # adegenet - reads *.gen files, only ha/diploid data
    read.structure() # adegenet - reads *.str files, only ha/diploids
    import2genind() # adegenet - more automated version of above functions
	\end{spluscode}
	\begin{alertblock}{One function rules them all\ldots}
		\begin{footnotesize}
			All those functions (including \texttt{read.loci()} and \texttt{read.csv()}) are only modifications of \textbf{\texttt{read.table()}}. You can use it directly to import any data. Look at \texttt{?read.table} and play with it. Take care about parameters. Does the table use quotes to mark cell (e.g. \texttt{quote="\textbackslash ""})? How are columns separated (e.g. \texttt{sep="\textbackslash t"})? Is there a~header with names of populations/loci/whatever (\texttt{header=T/F})? What is decimal separator (e.g. \texttt{dec="."})? Are there row names (used typically as names of individuals; e.g. \texttt{row.names=1})? \alert{Check data after import!}
		\end{footnotesize}
	\end{alertblock}
\end{frame}

\begin{frame}[fragile]{Import of polyploid microsatellites}
	\vfill
	\begin{itemize}
		\item \texttt{adegenet}, \texttt{poppr} and related packages can for most of functions handle any ploidy level (including mixing of ploidy levels, but not for all analysis)
		\item \texttt{polysat} package can handle mixed ploidy levels for microsatellites, but range of methods is limited
		\item As for AFLP, we need two files: the data matrix and individual's populations (it can be combined in one file --- next slide)
	\end{itemize}
	\vfill
	\textbf{Triploid microsatellite data:}
	\vfil
	\begin{spluscode}
              msat58      msat31      msat78      msat61 ...
    ala1 124/124/124 237/237/237 164/164/172 136/136/138 ...
    ala2 124/124/124 237/237/237 164/164/172 136/136/138 ...
    ala4 124/124/124 237/237/237 164/164/172 136/136/138 ...
     ...         ...         ...         ...         ... ...
	\end{spluscode}
	\vfill
	\begin{footnotesize}
		Triploid species of \textit{Taraxacum} sect. \textit{Taraxacum}
	\end{footnotesize}
	\vfill
\end{frame}

\begin{frame}[fragile]{How to import polyploid microsatellites}
	\begin{spluscode}
    # Import of table is as usual. Last column contains populations
    tarax3n.table <- read.table("http://soubory.trapa.cz/rcourse/
      tarax3n.txt", header=TRUE, sep="\t", quote="", row.names=1)
    # Check the data
    tarax3n.table
    class(tarax3n.table)
    dim(tarax3n.table)
    # See parameter "X" - we don't import whole tarax3n.table as last column
    # contains populations - this column we use for "pop" parameter (note
    # different style of calling the column - just to show the possibility).
    # Check "ploidy" and "ncode" (how many digits code one allele - must be
    # same everywhere). See ?df2genind for more details.
    tarax3n.genind <- df2genind(X=tarax3n.table[,1:6], sep="/", ncode=3,
      pop=tarax3n.table[["pop"]], ploidy=3, type="codom")
    # See resulting genind object
    tarax3n.genind
    summary(tarax3n.genind)
	\end{spluscode}
\end{frame}

\subsection{AFLP}

\begin{frame}[fragile]{Import of AFLP data --- background}
	Two files --- AFLP data with individual names, and populations
	\vfill
	\begin{multicols}{2}
	\vfill
	\textbf{AFLP or any other presence/absence data:}
	\vfill
	\begin{spluscode}
        L1 L2 L3 L4 L5 L6 L7 L8 L9 ...
    Ind1 0  0  1  1  1  0  0  0  1 ...
    IndG 0  0  1  1  0  0  0  0  0 ...
     ...  ...                      ...
	\end{spluscode}
	\vfill
	\begin{footnotesize}
		AFLP data of \textit{Cardamine amara} group
	\end{footnotesize}
	\vfill
	\textbf{Individual's populations:}
	\vfill
	\begin{spluscode}
    POP
    pop1
    popZ
    ...
	\end{spluscode}
	\vfill
	\begin{footnotesize}
		Just list of populations for respective individuals\ldots
	\end{footnotesize}
	\columnbreak
	\begin{itemize}
		\item Use any names, just keep one word (no spaces) and don't use special characters
		\item Keep names of loci as simple as possible, there are some issues when they contain dots
		\item As soon as one line of data = one individual, ploidies and their mixing doesn't matter
		\item Not all methods are available/meaningful for PA
	\end{itemize}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Import of AFLP data --- the code}
	\begin{spluscode}
    amara.aflp <- read.table(file="https://soubory.trapa.cz/rcourse/
      amara_aflp.txt", header=TRUE, sep="\t", quote="")
    amara.aflp
    dim(amara.aflp)
    class(amara.aflp) # Must be matrix or data frame
    # Populations - just one column with population names for all inds
    amara.pop <- read.table(file="https://soubory.trapa.cz/rcourse/
      amara_pop.txt", header=TRUE, sep="\t", quote="")
    amara.pop
    # You can use just one file, where populations are in last column and
    # in df2genind() use for example X=aflp[,1:XXX] and pop=aflp[,YYY]
    # Create genind object - ind.names and loc.names are taken from X
    aflp.genind <- df2genind(X=amara.aflp, sep="", ind.names=NULL,
      loc.names=NULL, pop=amara.pop[,1], type="PA")
    indNames(aflp.genind) <- amara.aflp[,1] # Add individual names
    aflp.genind
    # You can add any other variables into genind$other$XXX
	\end{spluscode}
\end{frame}

\subsection{Notes about data}

\begin{frame}[fragile]{Another data manipulation}
	\begin{spluscode}
    genind2df() # adegenet - export into data frame
    genind2genalex() # poppr - export for genalex
    splitcombine() # poppr - edits population hierarchy
    popsub() # poppr - extracts only selected population(s)
    clonecorrect() # poppr - corrects for clones
    informloci() # poppr - removes uninformative loci
    seppop() # adegenet - separates populations from genind or genlight
    seploc() # adegenet - splits genind, genpop or genlight by markers
    alleles2loci() # pegas - transforms a matrix of alleles into "loci"
    # seppop and seploc return lists of genind objects - for further
    # analysis using special functions to work on lists (see further)
    # read manual pages (?...) of the functions before usage
	\end{spluscode}
	\begin{itemize}
		\item SNPs can be into genind imported in same way as AFLP (PA)
		\item \texttt{alleles2loci()} is very useful when each allele is in separated columns (not like in our case where one column contains one loci with all alleles) --- saves time needed to change input file formatting
	\end{itemize}
\end{frame}

\begin{frame}{Notes about getting data into R}
	\begin{itemize}
		\item When importing fragmentation data, we somehow use function \texttt{read.table()} --- it is important to understand it
		\item I~recommend to use TAB (TSV --- tab separated values; encoded as \texttt{\textbackslash t} in R) to separate columns (no quotation marks, no commas)
		\item When importing microsatellites, all alleles \textbf{must} have same number of digits. Separate alleles by \enquote{\texttt{/}}, \enquote{\texttt{|}} or something similar and correctly specify it in \texttt{read.loci()} or \texttt{df2genind()} (or read the data with \texttt{read.table()}, convert into matrix and use \texttt{alleles2loci()})
		\item \textbf{Do not use} underscores (\enquote{\texttt{\_}}) or minuses (\enquote{\texttt{-}}) to name objects in R --- only numbers, Latin letters or dots
		\item \texttt{read.loci()} sometimes doesn't work correctly on AFLP or polyploid microsatellites --- try \texttt{read.table()} instead\ldots
		\item Genind object is able to store mixed ploidy data, but not all analysis are able to handle it
	\end{itemize}
\end{frame}

\subsection{DNA sequences, SNP}

\begin{frame}[fragile]{Import of DNA sequence data I}
	\begin{spluscode}
    # Reading FASTA (read.dna() reads also another formats, see ?read.dna)
    # Sequences of flu viruses from various years from USA (Adegenet toy data)
    usflu.dna <- read.dna(file="http://adegenet.r-forge.r-project.org/
      files/usflu.fasta", format="fasta")
    class(usflu.dna) # Check the object
    usflu.dna # Check the object
    # Another possibility (only for FASTA alignments, same result):
    usflu.dna2 <- fasta2DNAbin(file="http://adegenet.r-forge.r-project.org
      /files/usflu.fasta") # Normally keeps only SNP - see ?fasta2DNAbin
    class(usflu.dna2) # Check the object
    usflu.dna2 # Check the object
    as.character(usflu.dna2)[1:5,1:10] # Check the object
    dim(usflu.dna2) # Does it have correct size?
    # Read annotations
    usflu.annot <- read.csv("http://adegenet.r-forge.r-project.org/files/
      usflu.annot.csv", header=TRUE, row.names=1)
    head(usflu.annot) # See result
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Import of DNA sequence data II}
	\begin{spluscode}
    # Convert DNAbin to genind - only polymorphic loci (SNPs) are retained
    # When converting DNAbin to genind, the sequences must be aligned!
    usflu.genind <- DNAbin2genind(x=usflu.dna, pop=usflu.annot[["year"]])
    usflu.genind # Check it
    # Read sequence data in NEXUS
    read.nexus.data(file="sequences.nex")
	\end{spluscode}
	\begin{itemize}
		\item RNA or protein sequences can be handed in same way --- see \texttt{?read.dna} and \texttt{?read.FASTA}
		\item For sequences there is R class \texttt{DNAbin}, for protein \texttt{AAbin} --- they are handled in same way
		\item Do not confuse \texttt{read.nexus.data} (reads sequences) and \texttt{read.nexus} (reads trees)
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Import sequences from GenBank}
	\begin{itemize}
		\item Data from \url{https://www.ncbi.nlm.nih.gov/popset/608602125} (\textit{Meles meles}, phylogeographical study of \href{https://www.nature.com/articles/hdy201445}{Frantz et al. 2014})
	\end{itemize}
	\begin{spluscode}
    # Importing sequences according to sequence ID
    meles.dna <- read.GenBank(c("KJ161355.1", "KJ161354.1", "KJ161353.1",
      "KJ161352.1", "KJ161351.1", "KJ161350.1", "KJ161349.1", "KJ161348.1",
      "KJ161347.1", "KJ161346.1", "KJ161345.1", "KJ161344.1", "KJ161343.1",
      "KJ161342.1", "KJ161341.1", "KJ161340.1", "KJ161339.1", "KJ161338.1",
      "KJ161337.1", "KJ161336.1", "KJ161335.1", "KJ161334.1", "KJ161333.1",
      "KJ161332.1", "KJ161331.1", "KJ161330.1", "KJ161329.1", "KJ161328.1"))
    meles.dna
    class(meles.dna)
    # Converts DNAbin to genind - extracts SNP - for large data sets can be
    # computationally very intensive
    meles.genind <- DNAbin2genind(meles.dna)
    meles.genind # Check it
	\end{spluscode}
	\begin{itemize}
		\item To query on-line database as through web we use \href{https://CRAN.R-project.org/package=seqinr}{seqinr} (next slide)
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Query on-line sequence databases}
	\begin{spluscode}
    library(seqinr)
    choosebank() # List genetic banks available for seqinr
    choosebank("embl") # Choose some bank
    ?query # See how to construct the query
    # Query selected database - there are a lot of possibilities
    nothofagus <- query(listname="nothofagus",query="SP=Nothofagus AND K=rbcl",
      verbose=TRUE)
    nothofagus$req # See the sequences information
    # Get the sequences as a list
    nothofagus.sequences <- getSequence(nothofagus$req)
    nothofagus.sequences # See sequences
    nothofagus.annot <- getAnnot(nothofagus[["req"]]) # Get annotations
    nothofagus.annot
    closebank() # Close the bank when work is over
    # Convert sequences from a list to DNAbin (functions as.DNAbin*)
    nothofagus.dna <- as.DNAbin.list(nothofagus.sequences)
    nothofagus.dna # See it
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Importing SNP}
	\begin{itemize}
		\item Import from \href{http://zzz.bwh.harvard.edu/plink/}{PLINK} requires saving of data with option \href{http://zzz.bwh.harvard.edu/plink/dataman.shtml#recode}{\enquote{-recodeA}}
	\end{itemize}
	\begin{spluscode}
    read.PLINK(file="PLINKfile", ...) # See ?read.PLINK
	\end{spluscode}
	\begin{itemize}
		\item Extracting SNP from alignments reads FASTA alignments and keep only SNPs. The method is relatively efficient even for large data sets with several genomes:
	\end{itemize}
	\begin{spluscode}
    usflu.genlight <- fasta2genlight
      (file="http://adegenet.r-forge.r-project.org/files/usflu.fasta",
      quiet=FALSE, saveNbAlleles=TRUE)
    usflu.genlight # See genlight
    ?fasta2genlight # Function has several options to speed up reading
    # If it crashes (on Windows), try to add parameter "parallel=FALSE"
	\end{spluscode}
	\begin{itemize}
		\item For small data sets, keep data as genind as it is more information-rich --- genlight is more efficient for large data (> $\sim$100,000~SNPs)
		\item Adegenet has custom format to store SNP as plain text file and function \texttt{read.snp} to import it into \texttt{genlight} object --- check \href{https://github.com/thibautjombart/adegenet/wiki/Tutorials}{Adegenet tutorial} \textbf{genomics}, \texttt{?read.snp}
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Checking SNPs}
	\begin{multicols}{2}
		\begin{spluscode}
    # Position of polymorphism within
    # alignment - snpposi.plot requi-
    # res input data in form of matrix
    snpposi.plot(x=as.matrix(
      meles.dna), codon=FALSE)
    # Position of polymorphism within
    # alignment-differentiating codons
    snpposi.plot(as.matrix(meles.dna))
    # When converting DNAbin to genind
    # only polymorphic loci are kept -
    # threshold for polymorphism can
    # be arbitrary (polyThres=...)
    meles.genind <- DNAbin2genind(x=
      meles.dna, polyThres=0.01)
    meles.genind # See it
		\end{spluscode}
		\begin{flushright}
			\includegraphics[height=7cm]{snpposi.png}
		\end{flushright}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Checking sequences}
	\begin{spluscode}
    # Test is distribution of SNPs is random (1000 permutations)
    snpposi.test(as.matrix(meles.dna))
    pegas::nuc.div(x=meles.dna) # Nucleotide diversity
    ape::base.freq(x=meles.dna) # Base frequencies
    ape::GC.content(x=meles.dna) # GC content
    # Number of times any dimer/trimer/etc oligomers occur in a sequence
    # Note: count() requires single sequence as DNAbin/character
    seqinr::count(seq=as.character.DNAbin(meles.dna[["KJ161328.1"]]),
      wordsize=3)
    # View sequences - all must be of the same length
    image(x=usflu.dna, c("a", "t", "c" ,"g", "n"), col=rainbow(5))
    # Function "image" requires as input matrix
    # So that sequences must be of same length
    image(x=as.matrix(meles.dna), c("a", "t", "c" ,"g", "n"), col=rainbow(5))
    # Direct function to display the sequences
    image.DNAbin(x=usflu.dna)
    image.DNAbin(x=as.matrix(meles.dna))
	\end{spluscode}
\end{frame}

\begin{frame}{\textit{Meles} sequences}
	\begin{center}
		\includegraphics[width=\textwidth-1.5cm]{sequences_meles.png}
	\end{center}
\end{frame}

\begin{frame}{Notes about using genlight (vs. genind)}
	\begin{itemize}
		\item Genlight is \enquote{just} version of more common genind object to store large data sets with (nearly) complete multiple genomes
		\item \enquote{Large} is tricky --- there is no easy criterion (roughly, genind is inefficient since dozens or hundreds thousands of SNPs) --- try genind and when work fails because of not enough computer resources, go on with genlight
		\item Use is basically same as when working with genind --- but not all functions are able to deal with it (on the other hand, others are optimized to work well on large data sets)
		\item SNPbin is version of genind/genlight to store one large genome --- serves basically as storage, no need to deal with it
		\item Genlight as well as genind allow varying ploidy level
		\item Functions working with genlight use to use parallelisation to speed up operations --- this commonly doesn't work properly on MS~Windows
	\end{itemize}
\end{frame}

\subsection{VCF}

\begin{frame}[fragile]{Reading VCF}
	\begin{itemize}
		\item Download input file from \url{https://soubory.trapa.cz/rcourse/arabidopsis.vcf.gz}
		\item Non-synonymous SNPs from \href{https://www.arabidopsis.org/servlets/TairObject?type=locus&name=At2g46980}{ASY3} gene (required for meiosis) from diploids and tetraploids of \textit{Arabidopsis arenosa} from central and northern Europe
		\item Package vcfR has functions to manipulate and explore VCF
	\end{itemize}
	\begin{spluscode}
    library(vcfR) # Required library
    # Pick up downloaded file 'arabidopsis.vcf.gz' from the disk
    arabidopsis.vcf <- read.vcfR(file=file.choose())
    # File choose dialog can open in background - search for it :-)
    # Or directly load remote file
    arabidopsis.vcf <- read.vcfR
      (file="https://soubory.trapa.cz/rcourse/arabidopsis.vcf.gz")
    # It returns object of class vcfR-class
    ?read.vcfR # See more import options
    ?pegas::read.vcf # This one returns list of objects loci and data.frame
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Checking VCF I}
	\begin{spluscode}
    arabidopsis.vcf
    head(arabidopsis.vcf)
    arabidopsis.vcf@fix[1:10,1:5]
    # Get information about depth of coverage (DP)
    # Se description of DP slot
    strwrap(x=grep(pattern="ID=DP,", x=arabidopsis.vcf@meta, value=TRUE))
    # Extract the DP
    arabidopsis.vcf.dp <- extract.gt(x=arabidopsis.vcf, element="DP",
      as.numeric=TRUE)
    # See it
    dim(arabidopsis.vcf.dp)
    head(arabidopsis.vcf.dp)
    # Boxplot of DP (next slide)
    boxplot(x=arabidopsis.vcf.dp, col="#808080", ylab="Depth of coverage",
      las=3)
    title("DP per specimen")
    abline(h=seq(from=0, to=90, by=10), col="#b3b3b3")
	\end{spluscode}
\end{frame}

\begin{frame}{DP per specimen}
	\begin{center}
		\includegraphics[width=\textwidth-2.5cm]{vcf_dp.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Checking VCF II}{Bar plot of mean DP}
	\begin{spluscode}
    barplot(apply(X=arabidopsis.vcf.dp, MARGIN=2, FUN=mean, na.rm=TRUE), las=3)
    title("Mean DP per specimen")
    abline(h=seq(from=0, to=60, by=10), col="#b3b3b3")
	\end{spluscode}
	\begin{center}
		\includegraphics[width=\textwidth-6.5cm]{vcf_dp_mean.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Checking VCF III}{Heat map of DP}
	\begin{spluscode}
    heatmap.bp(x=arabidopsis.vcf.dp[1:100,1:100], col.ramp=rainbow(n=100,
      start=0.1)) # Subset - only first 100 loci and individuals
    title("DP per specimens and loci")
	\end{spluscode}
	\begin{center}
		\includegraphics[width=\textwidth-6cm]{vcf_dp_heatmap.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Convert VCF into genind, genlight and loci}
	\begin{spluscode}
    # Genind
    arabidopsis.genind <- vcfR2genind(x=arabidopsis.vcf)
    arabidopsis.genind # Check it
    nInd(arabidopsis.genind)
    indNames(arabidopsis.genind)
    nLoc(arabidopsis.genind)
    locNames(arabidopsis.genind)
    # Genlight (suitable for huge data, not required now)
    # On Linux/macOS and with large data use higher n.cores
    arabidopsis.genlight <- vcfR2genlight(x=arabidopsis.vcf, n.cores=1)
    arabidopsis.genlight # Check it
    # Loci
    arabidopsis.loci <- vcfR2loci(x=arabidopsis.vcf)
    arabidopsis.loci # Check it
    print(x=arabidopsis.loci, details=TRUE)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Convert VCF into DNAbin}
	\begin{multicols}{2}
	\begin{spluscode}
    # There are various options how
    # to process variants in VCF
    ?vcfR2DNAbin
    arabidopsis.dnabin <- vcfR2DNAbin
      (x=arabidopsis.vcf, consensus=
      FALSE, extract.haps=TRUE,
      unphased_as_NA=FALSE)
    # Check it
    arabidopsis.dnabin
    dim(arabidopsis.dnabin)
    as.character.DNAbin
      (arabidopsis.dnabin[1:15,1:12])
    image.DNAbin(arabidopsis.dnabin)
    snpposi.plot.DNAbin
      (arabidopsis.dnabin)
    snpposi.test.DNAbin
      (arabidopsis.dnabin)
	\end{spluscode}
	\begin{center}
		\includegraphics[height=7cm]{vcf_dna.png}
	\end{center}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Remove non-biallelic loci}
	\begin{itemize}
		\item This is commonly done with SNPs as many downstream analysis are well defined only for biallelic loci
	\end{itemize}
	\begin{spluscode}
    # Create vector of loci to keep
    arabidopsis.genind.keep <- nAll(arabidopsis.genind) < 3
    # See the vector of loci
    arabidopsis.genind.keep
    # Keep only passing loci
    arabidopsis.genind.bial <-
      arabidopsis.genind[loc=arabidopsis.genind.keep]
    # See result
    arabidopsis.genind.bial
    # Filtration of missing data
    ?poppr::missingno # Various options...
	\end{spluscode}
\end{frame}

\subsection{Export}

\begin{frame}[fragile]{Export data}
	\begin{spluscode}
    # Convert genind into DF using genind2df()
    hauss.df <- genind2df(x=hauss.genind, pop=NULL, sep="/",
      usepop=TRUE, oneColPerAll=FALSE)
    # Save microsatellites to disk - check settings of write.table
    write.table(x=hauss.df, file="haussdata.txt", quote=FALSE,
      sep="\t", na="NA", dec=".", row.names=TRUE, col.names=TRUE)
    # Export of DNA sequences into FASTA format
    write.dna(x=usflu.dna, file="usflu.fasta", format="fasta",
      append=FALSE, nbcol=6)
    seqinr::write.fasta(sequences=meles.dna, names=names(meles.dna),
      file.out="meles.fasta", open="w")
    # Export DNA sequences as NEXUS
    write.nexus.data(x=meles.dna, file="meles.nexus", format="dna")
    write.vcf(x=arabidopsis.vcf, file="arabidopsis.vcf.gz") # Export VCF
    # Export tree(s) (objects of class phylo)
    write.tree(phy=hauss.nj.bruvo, file="haussknechtii.nwk") # In NEWICK
    write.nexus(hauss.nj.bruvo, file="haussknechtii.nexus") # In NEXUS
	\end{spluscode}
\end{frame}

\subsection{Tasks}

\begin{frame}{Import your own data}
	\begin{exampleblock}{Tasks}
		\begin{enumerate}
			\item Prior to import into R, \alert{ensure your data are correct} --- same decimal separator everywhere, consistent structure of CSV/TSV, no syntactic problems in FASTA/NEXUS/NEWICK,~\ldots
			\item Import some of your data into R
			\begin{itemize}
				\item Be inspired by previous slides --- edit commands to fit your needs and process your data
				\item R is extremely flexible, but not everything is figured out within one minute\ldots
				\item Import preferably your data --- you'll later use them to perform selected analysis
			\end{itemize}
			\item \textbf{Check your data after import} to ensure they were correctly read
		\end{enumerate}
	\end{exampleblock}
	\begin{itemize}
		\item Upcoming chapters can serve like inspiration (not exhaustive) how to process your data in R, what is possible to do with them\ldots
		\item Previous examples are not covering all possibilities\ldots
	\end{itemize}
\end{frame}

\section{Alignment}

\begin{frame}[fragile]{Multiple sequence alignment}
	\tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
\end{frame}

\begin{frame}{Multiple sequence alignment}
	\label{alignment}
	\begin{itemize}
		\item Good alignment is basic condition for any analysis of DNA sequences
		\item DNA/RNA and protein sequences must be aligned prior any subsequent analysis (tree building,~\ldots)
		\item R doesn't have any possibility for visual editing (use rather software like \href{http://ugene.net/}{Unipro UGENE} \href{https://www.geneious.com/}{Geneious} or \href{https://digitalinsights.qiagen.com/products-overview/analysis-and-visualization/qiagen-clc-genomics-workbench/}{CLC Genomics Workbench}
		\item R can automatically (in batch) run multiple sequence alignments of multiple genes (there are several possibilities)
		\begin{itemize}
			\item Simple scripts for this task can be written in any scripting language like BASH, Perl or Python --- only matters what user likes, knows and wish to do with the results\ldots
		\end{itemize}
		\item R packages use common alignment software: \href{https://mafft.cbrc.jp/alignment/software/}{MAFFT}, \href{https://www.drive5.com/muscle/}{MUSCLE}, \href{http://clustal.org/}{Clustal},~\ldots
		\begin{itemize}
			\item User must install this software manually --- R is just using external applications (in the examples shown)
		\end{itemize}
	\end{itemize}
\end{frame}

\subsection{Overview and MAFFT}

\begin{frame}[fragile]{Multiple sequence alignment with MAFFT}
	\begin{itemize}
		\item MUSCLE is available in packages \texttt{muscle} and \texttt{ape} --- first one reads \enquote{\texttt{*StringSet}} class R objects and writes \enquote{\texttt{*MultipleAlignment}} R objects; the latter reads and writes object of class \enquote{\texttt{DNAbin}}
		\item \texttt{ape} also contains functions to use Clustal and T-Coffee --- both read and write \texttt{DNAbin}
		\item MAFFT is available from (same author) in packages \href{https://CRAN.R-project.org/package=ips}{ips} and \href{http://www.christophheibl.de/Rpackages.html}{phyloch} --- both read and write \texttt{DNAbin}
	\end{itemize}
	\begin{spluscode}
    library(ape)
    library(ips)
    # Requires path to MAFFT binary - set it according to your installation
    # read ?mafft and mafft's documentation
    # Change "exec" to fit your path to mafft!
    meles.mafft <- mafft(x=meles.dna, method="localpair", maxiterate=100,
      options="--adjustdirection", exec="/usr/bin/mafft")
	\end{spluscode}
\end{frame}

\subsection{MAFFT, Clustal, MUSCLE and T-Coffee}

\begin{frame}[fragile]{Clustal, MUSCLE and T-Coffee from ape}
	\begin{spluscode}
    meles.mafft
    class(meles.mafft)
    # read ?clustal and documentation of Clustal, Muscle and T-Coffee
    # when using them to set correct parameters
    meles.clustal <- ape::clustal(x=meles.dna, pw.gapopen=10, pw.gapext=0.1,
      gapopen=10, gapext=0.2, exec="/usr/bin/clustalw2", quiet=FALSE,
      original.ordering=TRUE) # Change "exec" to fit your path to clustal!
    meles.clustal
    class(meles.clustal)
    meles.muscle <- muscle(x=meles.dna, exec="muscle", quiet=FALSE,
      original.ordering=TRUE) # Change "exec" to fit your path to muscle!
    meles.muscle
    class(meles.muscle)
    ?muscle::muscle # See option in muscle package
    # Remove gaps from alignment - destroy it
    meles.nogaps <- del.gaps(meles.muscle)
    ?del.gaps # See for details
	\end{spluscode}
\end{frame}

\subsection{Multiple genes}

\begin{frame}[fragile]{Multiple sequence alignment with MUSCLE}
	\begin{spluscode}
    # Plot the alignment select bases to plot and/or modify colors
    image(x=meles.muscle, c("a", "t", "c" ,"g", "n"), col=rainbow(5))
    # Add gray dotted grid
    grid(nx=ncol(meles.muscle), ny=nrow(meles.muscle), col="lightgrey")
	\end{spluscode}
	\vfill
	\begin{center}
		\includegraphics[width=\textwidth-6cm]{muscle.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Align multiple genes}
	\begin{itemize}
		\item NGS/HTS introduced work with hundreds and thousands of genes, it makes sense to process them in batch and not manually one-by-one
	\end{itemize}
	\begin{spluscode}
    # Create a list of DNAbin objects to process
    multialign <- list(meles.dna, usflu.dna, usflu.dna2)
    # See it
    multialign
    class(multialign)
    lapply(X=multialign, FUN=class)
    # Do the alignment
    multialign.aln <- lapply(X=multialign, FUN=ips::mafft, method="localpair",
    maxiterate=100, exec="/usr/bin/mafft")
      # Change "exec" to fit your path to mafft!
    # See result
    multialign.aln
    multialign.aln[[1]]
    lapply(X=multialign.aln, FUN=class)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Align multiple genes in parallel}
	\begin{itemize}
		\item There are plenty of implementations of parallelisation and using of computer clusters, see \url{https://CRAN.R-project.org/web/views/HighPerformanceComputing.html}
	\end{itemize}
	\begin{spluscode}
    library(parallel)
    # Do the same in parallel (mclapply do the tasks in parallel, not
    # one-by-one like lapply)
    multialign.aln2 <- mclapply(X=multialign, FUN=ape::muscle,
      exec="muscle", quiet=FALSE, original.ordering=TRUE)
    # Change "path" to fit your path to muscle!
    # mclapply() relies on forking and hence is not available on Windows
    # unless "mc.cores=1"
    # See result
    multialign.aln2
    lapply(X=multialign.aln2, FUN=class)
    ?mclapply # See more options
    ?clusterApply # See more options (parLapply should work on Windows)
	\end{spluscode}
\end{frame}

\subsection{Display and cleaning}

\begin{frame}[fragile]{Checking the alignment}
	\begin{spluscode}
    # Shortcut for plotting alignment
    image.DNAbin(x=meles.mafft)
    # Display aligned sequences with gaps
    image.DNAbin(x=usflu.dna)
    # Check the alignment
    checkAlignment(x=usflu.dna, check.gaps=TRUE, plot=TRUE, what=1:4)
    checkAlignment(x=as.matrix.DNAbin(x=meles.dna), check.gaps=TRUE,
      plot=TRUE, what=1:4)
    ?checkAlignment # See details
    # DNAbin can be technically list or matrix - some functions require
    # list, some matrix, some can handle both - check manual and if needed,
    # use:
    as.matrix.DNAbin()
    as.list.DNAbin()
    # Matrix makes sense only for alignments, list for any import
    # (sequences do no have to have same lengths)
	\end{spluscode}
\end{frame}

\begin{frame}{Checking the alignment}
	\begin{center}
		\includegraphics[width=\textwidth-2cm]{checkalignment.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Cleaning the alignment}
	\begin{spluscode}
    # Delete all columns/rows containing only gaps or missing data (N, ?, -)
    usflu.dna <- deleteEmptyCells(DNAbin=usflu.dna)
    ?ips::deleteEmptyCells # See help page for details
    ?phyloch::delete.empty.cells # See help page for details
    # Delete all columns containing at least 25% of gaps
    usflu.dna.ng <- deleteGaps(x=usflu.dna, gap.max=nrow(usflu.dna)/4)
    usflu.dna.ng
    # Do not confuse with function delete.gaps() from phyloch package
    # See of settings of "nmax" value - threshold for gap deletion
    ?deleteGaps # "nmax=0" deletes all columns with any gap
    multialign.aln.ng <- lapply(X=multialign.aln, FUN=deleteGaps, gap.max=5)
    multialign.aln.ng
    # Delete every line (sample) containing at least 20% of missing data
    usflu.dna.ng <- del.rowgapsonly(x=usflu.dna.ng, threshold=0.2,
      freq.only=FALSE)
    ?ape::del.rowgapsonly # See help page for details
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Cleaning the alignment}
	\begin{spluscode}
    # Delete every alignment position having at least 20% of missing data
    usflu.dna.ng <- del.colgapsonly(x=usflu.dna.ng, threshold=0.2,
      freq.only=FALSE)
    ?ape::del.colgapsonly # See help page for details
    # Display the result
    image.DNAbin(x=usflu.dna.ng)
    lapply(X=multialign.aln.ng, FUN=image.DNAbin)
	\end{spluscode}
	\begin{itemize}
		\item \enquote{Strictness} of alignment cleaning depends on following steps --- NJ (and another distance-based methods) doesn't like more than $\sim$10--15\% of missing data, but some tree builders are able to work with gaps --- check their documentation\ldots
		\item Automated cleanup is useful especially if batch processing plenty of genes
	\end{itemize}
\end{frame}

\section{Basic analysis}

\begin{frame}{Basic analysis}
	\tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
\end{frame}

\begin{frame}[allowframebreaks]{Introductory overview of statistics and methods}
	\begin{itemize}
		\item \alert{Selected method depends on data type, question to answer,~\ldots}
		\begin{itemize}
			\item Check assumptions and requirements of the methods before usage
			\item Think if the method answers your question
		\end{itemize}
		\item \textbf{\href{https://en.wikipedia.org/wiki/Population_genetics}{Population-genetic} indices} --- from slide~\ref{popgenindx}
		\begin{itemize}
			\item Huge number\ldots
			\item Characterize differences among individuals/groups or genetic variability on various levels (within/among individuals/populations,~\ldots)
			\item One number tries to describe whole situation --- always very rough
			\item Description of heterozygosity, allelic richness, distribution of multi locus genotypes among populations, level of inbreeding,~\ldots
		\end{itemize}
		\item \textbf{\href{https://en.wikipedia.org/wiki/Genetic_distance}{Distance}-based methods} --- from slide~\ref{distances}
		\begin{itemize}
			\item \alert{It is crucial to select appropriate distance method for given data type}
			\item Usually require the distance matrix to be Euclidean
			\item Distance matrix has one single number (index) for each pair of comparisons (individuals, populations) --- rough
			\item Generally, the matrices describe pairwise similarities among the individuals/populations
			\item Distance-based methods are phenetic
			\begin{itemize}
				\item Based on similarity (described by the matrix), not on any (evolutionary) model
				\item The matrix based on genetic data is supposed to well reflect the genetic similarity, thus real relationships among individuals/populations
			\end{itemize}
			\item \textbf{\href{https://en.wikipedia.org/wiki/Hierarchical_clustering}{Hierarchical clustering}} --- from slide~\ref{hierclust}
			\begin{itemize}
				\item Several methods clustering individuals according to their (dis)similarity from top or down into clusters
				\item (Un)weighted per-group mean average (\textbf{U/WPGMA}) and others
				\item Used more in ecology, for genetic data not so much anymore (following methods use to produce better results)
			\end{itemize}
			\item \textbf{\href{https://en.wikipedia.org/wiki/Neighbor_joining}{Neighbor-Joining (NJ)}} --- from slide~\ref{NJ}
			\begin{itemize}
				\item A~tree starting from the two most similar individuals and connecting in the next steps next and next the most similar individual
				\item In some cases artificially chains individuals
				\item Several methods try to improve it --- slide~\ref{NJ-replacement}
			\end{itemize}
			\item \textbf{Principal Coordinates Analysis (PCoA)} --- from slide~\ref{pcoa}
			\begin{itemize}
				\item The most common method of \href{https://en.wikipedia.org/wiki/Multidimensional_scaling}{multivariate statistics} for genetic data
				\item Shows individuals in 2D scatter plot to retain maximum variability (by finding correlations among loci)
			\end{itemize}
		\end{itemize}
		\item \textbf{\href{https://en.wikipedia.org/wiki/Minimum_spanning_tree}{Minimum Spanning Network (MSN)}} --- slide~\ref{MSN}
		\begin{itemize}
			\item Simple network connecting the most similar genotypes/haplotypes
			\item Useful for clones, cpDNA, mtDNA,~\ldots
			\end{itemize}
		\item \textbf{\href{https://en.wikipedia.org/wiki/Multivariate_statistics}{Multivariate statistics}}
		\begin{itemize}
			\item Two variables are easily displayable in 2D xy-scatter plot (we can calculate correlation, whatever)
			\item In molecular data, each locus is more or less independent variable --- 1000~bp alignment has 1000 variables: How to display plot with 1000 axes to be able to really see something?
			\item Methods like Principal Component Analysis (\textbf{PCA}), Non-Metric Multidimensional Scaling (\textbf{NMDS}) or \textbf{PCoA} look for correlations between pairs of variables to reduce them into new variables --- after many steps new uncorrelated variables retaining maximum of original variability are constructed
			\item New variables are sorted according amount of variability they show (the decrease is very steep --- first 1--4~axes are usually enough) --- it is possible to display xy-scatter plot showing most of variability of the data
			\item Good for data display and creation of hypotheses --- not to verify them (there is no statistical test)
			\item Data are commonly scaled --- all variables are in same scale
		\end{itemize}
		\item \textbf{\href{https://en.wikipedia.org/wiki/Maximum_parsimony_(phylogenetics)}{Maximum Parsimony (MP)}} --- from slide~\ref{MP}
		\begin{itemize}
			\item Generally, the methods are looking for the most simple solution under given model, e.g. to construct phylogenetic tree requiring the lowest number of evolutionary changes (DNA mutations)
			\item It is easy to score how good the solution is (comparing to another solution), but computationally demanding to find the best one
		\end{itemize}
		\item \textbf{\href{https://en.wikipedia.org/wiki/Maximum_likelihood_estimation}{Maximum Likelihood (ML)}}
		\begin{itemize}
			\item Methods look for the most likely (probable) solution of the data under given model, e.g. the most likely tree under given mutational model
			\item It is easy to score how good the solution is (comparing to another solution), but computationally demanding to find the best one
		\end{itemize}
		\item \textbf{\href{https://en.wikipedia.org/wiki/Bayesian_statistics}{Bayesian statistics}}
		\begin{itemize}
			\item Based on \href{https://en.wikipedia.org/wiki/Bayes_theorem}{Bayesian theorem} --- probability of model under given data
			\item Methods are looking for the best (e.g. evolutionary) \textbf{model} (e.g. phylogenetic tree) \textbf{explaining the data} (e.g. DNA sequences)
			\item Algorithm exploring possible models, scoring them and approaching the best runs in steps (iterative generations)
			\begin{itemize}
				\item After some time it converges to find optimal solution (usually described by logarithms of likelihood of given model)
				\item Usually, $\sim$millions (or even more) of generations are required
				\item Beginning use to be very unstable --- it is discarded as burn-in (\enquote{heating} of \href{https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo}{Markov Chain Monte Carlo (MCMC)} doing the exploration and optimization of models), usually $\sim$10--25\%~of steps
			\end{itemize}
		\end{itemize}
		\item MP, ML and Bayesian statistics contain (evolutionary) \textbf{models} --- they are not based on similarity (as matrix-based methods), so that they are supposed to reveal real structure in the data
		\item \textbf{Permutations}, \textbf{bootstraps} and another \href{https://en.wikipedia.org/wiki/Resampling_(statistics)}{tests}
		\begin{itemize}
			\item It is necessary to test statistical significance of the obtained results
			\item Most common methods somehow shuffle the data (drop one column,~\ldots) and repeat the calculation to see how stable is the result (it might be driven by one or few loci,~\ldots)
			\item Whole process is repeated $\sim$100--1000~times and output is shown as histogram of simulations vs. the observed value, in how many percents the same result was obtained (e.g. bootstrap) or as p-value (what is probability that the pattern was created by random process)
			\item p = 0.05 means 95\% probability that the data are non-random
		\end{itemize}
	\end{itemize}
\end{frame}

\subsection{First look at the data}

\begin{frame}[fragile]{Descriptive statistics I}
	\label{popgenindx}
	\begin{itemize}
		\item We will now work mainly with diploid SSRs of \textit{Taraxacum haussknechtii}, you can try other data examples by yourselves
	\end{itemize}
	\begin{spluscode}
    # Get summary - names and sizes of populations,
    # heterozygosity, some info about loci
    hauss.summ <- summary(hauss.genind)
    # Plot expected vs. observed heterozygosity it looks like big difference
    plot(x=hauss.summ$Hexp, y=hauss.summ$Hobs,
      main="Observed vs expected heterozygosity",
      xlab="Expected heterozygosity", ylab="Observed heterozygosity")
    abline(0, 1, col="red")
    # Bartlett's K-squared test of difference
    # between observed and expected heterozygosity - not significant
    bartlett.test(list(hauss.summ$Hexp, hauss.summ$Hobs))
                  Bartlett test of homogeneity of variances
    data:  list(hauss.summ$Hexp, hauss.summ$Hobs)
    Bartlett's K-squared = 0.069894, df = 1, p-value = 0.7915
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Descriptive statistics II}
	\begin{itemize}
		\item \texttt{t.test} and \texttt{bartlett.test} require data to have normal distribution --- if the condition is not met, it is necessary to use some weaker non-parametric test (\texttt{kruskal.test}, \texttt{wilcox.test},~\ldots)
		\item See respective manual pages for details
		\item \texttt{shapiro.test()} tests the normality of given vector
	\end{itemize}
	\begin{spluscode}
    # T-test of difference between observed and expected heterozygosity
    t.test(x=hauss.summ$Hexp, y=hauss.summ$Hobs, paired=TRUE, var.equal=T)
                 Paired t-test
    data:  hauss.summ$Hexp and hauss.summ$Hobs
    t = 3.5622, df = 11, p-value = 0.004456 # strongly significant
    alternative hypothesis: true difference in means is not equal to 0
    95 percent confidence interval:
     0.06114303 0.25887357
    sample estimates:
    mean of the differences
                  0.1600083
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Descriptive statistics III}
	\begin{spluscode}
    # Create pane with some information
    par(mfrow=c(2, 2)) # Divide graphical devices into 4 smaller spaces
    # Plot alleles number vs. population sizes
    plot(x=hauss.summ$n.by.pop, y=hauss.summ$pop.nall, xlab="Populations
      sample size", ylab="Number of alleles", main="Alleles numbers and
      sample sizes", col="red", pch=20)
    # Add text description to the point
    text(x=hauss.summ$n.by.pop, y=hauss.summ$pop.nall,
      lab=names(hauss.summ$n.by.pop), cex=1.5)
    # Barplots of various data
    barplot(height=hauss.summ$loc.n.all, ylab="Number of alleles",
      main="Number of alleles per locus", las=3)
    barplot(height=hauss.summ$Hexp-hauss.summ$Hobs, main="Heterozygosity:
      expected-observed", ylab="Hexp - Hobs", las=3)
    barplot(height=hauss.summ[["n.by.pop"]], main="Sample sizes per
      population", ylab="Number of genotypes", las=3)
    dev.off() # Closes graphical device to reset graphical settings
	\end{spluscode}
\end{frame}

\begin{frame}{Graphs from previous slides}
	\begin{center}
		\includegraphics[width=\textwidth-2cm]{heterozygosity.png}
	\end{center}
\end{frame}

\subsection{Statistics}

\begin{frame}[fragile]{Population statistics by poppr()}
	\vfill
	\begin{itemize}
		\item \texttt{poppr()} is central function of \texttt{poppr} package calculating plenty of population genetic indices
	\end{itemize}
	\vfill
	\begin{spluscode}
    ?poppr # See details
    poppr(dat=hauss.genind, total=TRUE, sample=1000, method=4,
      missing="geno", cutoff=0.15, quiet=FALSE, clonecorrect=FALSE,
      plot=TRUE, index="rbarD", minsamp=1, legend=TRUE)
    # Output table with indices:
      Pop  N MLG eMLG       SE     H     G lambda   E.5  Hexp   Ia # More...
       He 13  11 1.97 1.58e-01 2.352  9.94  0.899 0.941 0.503 1.42 ...
       Ne  6   5 1.93 2.49e-01 1.561  4.50  0.778 0.930 0.604 3.44 ...
      ...... ...  ...      ...   ...   ...    ...   ...   ...  ... ...
    Total 47  43 2.00 6.07e-02 3.732 40.16  0.975 0.961 0.742 1.88 ...
	\end{spluscode}
	\vfill
	\begin{itemize}
		\item If \texttt{plot=TRUE}, histogram of simulations (\texttt{sample} must be > 1) is plotted for each population for \texttt{rbarD} or \texttt{Ia} (according to selected \texttt{index} --- see following slides for details)
	\end{itemize}
	\vfill
\end{frame}

\begin{frame}{Histograms of simulations of rbarD for each population}{The populations are significantly far from being clonal}
	\begin{center}
		\includegraphics[width=\textwidth-2.5cm]{poppr.png}
	\end{center}
\end{frame}

\begin{frame}[allowframebreaks]{Population statistics returned by poppr()}
	\begin{block}{Too much to choose from?}
		Generally, there are plenty of different population indices (and distances and another statistics) with different assumptions and usage in many packages --- it can be complicated to pick the best one\ldots{ }The course shows many examples, but the list is far from being exhaustive\ldots
	\end{block}
	\begin{itemize}
		\item \texttt{Pop} --- Population analyzed
		\begin{itemize}
			\item If \texttt{total=TRUE}, there are also statistics for whole dataset
		\end{itemize}
		\item \texttt{N} --- Number of individuals/isolates in the specified population
		\item \texttt{MLG} --- Number of multilocus genotypes found in the specified population (see \texttt{?mlg})
		\item \texttt{eMLG} --- The expected number of MLG at the lowest common sample size (set by \texttt{minsamp})
		\item \texttt{SE} --- The standard error for the rarefaction analysis (assets species richness --- how it grows with growing sample size)
		\begin{itemize}
			\item Big difference between \texttt{MLG} and \texttt{eMLG} indicate some process lowering/increasing genetic diversity
		\end{itemize}
		\item \texttt{H} --- \href{https://en.wikipedia.org/wiki/Diversity_index\#Shannon_index}{Shannon-Wiener Diversity index} --- evaluates number of genotypes and their distribution, takes entropy into account, grows with higher richness and diversity, sensitive to uneven sample size
		\item \texttt{G} --- \href{http://www.genetics.org/content/118/4/705}{Stoddard and Taylor's Index} --- roughly, similar approach as the previous one, highly enhanced
		\item \texttt{lambda} --- \href{https://en.wikipedia.org/wiki/Diversity_index\#Simpson_index}{Simpson's index} $\lambda$~=~1~minus the sum of squared genotype frequencies --- estimation of the probability that two randomly selected genotypes are different and scales from 0~(no genotypes are different) to 1~(all genotypes are different)
		\item \texttt{E.5} --- Evenness --- measure of the distribution of genotype abundances, wherein a~population with equally abundant genotypes yields a~value equal to 1~and a~population dominated by a~single genotype is closer to~0
		\item \texttt{Hexp} --- \href{http://www.genetics.org/content/89/3/583}{Nei's gene diversity} (expected heterozygosity) --- unbiased gene diversity (from 0~=~no diversity to 1~=~highest diversity)
		\item \texttt{Ia} --- Index of Association (\texttt{?ia}) --- widely used to detect clonal reproduction within populations
		\begin{itemize}
			\item Populations whose members are undergoing sexual reproduction will produce gametes via meiosis, and thus have a~chance to shuffle alleles in the next generation
			\item Populations whose members are undergoing clonal reproduction generally do so via mitosis --- most likely mechanism for a~change in genotype is via mutation --- the rate of mutation varies from species to species, but it is rarely sufficiently high to approximate a~random shuffling of alleles
			\item The index of association is a~calculation based on the ratio of the variance of the raw number of differences between individuals and the sum of those variances over each locus
			\item It as the observed variance over the expected variance --- if they are the same, then the index is zero (=prevailing clonal reproduction) after subtracting one --- it rises with with increasing differences
		\end{itemize}
		\item \texttt{p.Ia} --- P-value for \texttt{Ia} from the number of reshuffling indicated in \texttt{sample}
		\item \texttt{rbarD} --- Standardized Index of Association for each population (see \texttt{?ia}) --- corrected for higher number of loci not to rise so steeply
		\item \texttt{p.rD} --- P-value for \texttt{rbarD} from the number of reshuffles indicated in \texttt{sample}
		\item See \href{https://grunwaldlab.github.io/Population_Genetics_in_R/}{poppr's manual} and \texttt{vignette("algo", package="poppr")} for details
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Departure from Hardy-Weinberg equilibrium}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle}{In theory}, in large panmictic population without evolutionary influence everyone can mate with everyone (it is in equilibrium) and allele frequencies remain stable --- in reality, environment, behavior, mutations, genetic drift, etc. are structuring the population
	\end{itemize}
	\begin{spluscode}
    # According to loci
    hauss.hwe.test <- hw.test(x=hauss.loci, B=1000)
    hauss.hwe.test
    # According to populations
    # Separate genind object into list of genind objects for individual
    # populations
    hauss.pops <- seppop(hauss.genind)
    hauss.pops
    # Convert genind back to loci (list of loci objects according to
    # populations)
    hauss.pops.loci <- lapply(X=hauss.pops, FUN=genind2loci)
    # Calculate the results per populations
    lapply(X=hauss.pops.loci, FUN=hw.test, B=1000)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Departure from HWE --- results per locus}
	\vfill
	\texttt{hauss.hwe.test}
	\begin{tabular}{lllll}
		& chi\textasciicircum2 & df & Pr(chi\textasciicircum2 >) & Pr.exact\\
		msta93 & 383.5519728 & 190 & 3.552714e-15 & 0.000\\
		msta101 & 0.6927242 & 1 & 4.052393e-01 & 0.657\\
		msta102 & 83.0741964 & 10 & 1.250111e-13 & 0.000\\
		msta103 & 77.1819098 & 45 & 1.998865e-03 & 0.000\\
		... & ... & ... & ... & ...
	\end{tabular}
	\vfill
	\begin{itemize}
		\item Pr.exact shows significance of the departure (i.e. non-equilibrium distribution of alleles within population --- calculated per loci)
		\item $\chi^2$ \href{https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test}{test} (without or with the permutations) test the departure --- if it is significant or not --- not how much it is departing
	\end{itemize}
	\vfill
\end{frame}

\begin{frame}[fragile]{F-statistics I}
	\begin{itemize}
		\item Functions return tables of F-statistics values for populations/loci (roughly 0~--- no structure, 1~--- fully structured)
		\item The different \href{https://en.wikipedia.org/wiki/F-statistics}{F-statistics} look at different levels of population structure. F$_{IT}$ is the inbreeding coefficient of an individual relative to the total population; F$_{IS}$ is the inbreeding coefficient of an individual relative to the subpopulation and averaging them; and F$_{ST}$ is the effect of subpopulations compared to the total population
		\item For \texttt{Fst}, \texttt{fstat} and \texttt{theta.msat} the loci object \textbf{must} contain population column
	\end{itemize}
	\begin{spluscode}
    # Fit, Fst and Fis for each locus
    Fst(x=hauss.loci, pop=1)
                    Fit        Fst         Fis
    msta93   0.31835291 0.17867087  0.17006829
    msta101 -0.09968472 0.04064928 -0.14628018
        ...         ...        ...         ...
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{F-statistics II}
	\begin{spluscode}
    # Multilocus estimators of variance components and F-statistics,
    # alternative to Fst
    library(hierfstat)
    fstat(x=hauss.genind, pop=NULL, fstonly=FALSE)
                pop       Ind
    Total 0.1589501 0.2582641
    pop   0.0000000 0.1180834
    # Nei's pairwise Fst between all pairs of populations.
    # 0 = no structure; 1 = maximal difference
    pairwise.fst(x=hauss.genind, pop=NULL, res.type="matrix")
               He         Ne         Oh         Pr         Sk
    He 0.00000000 0.19960826 0.11391904 0.09404571 0.11184561
    Ne 0.19960826 0.00000000 0.07265306 0.19220430 0.10112859
    Oh 0.11391904 0.07265306 0.00000000 0.05302854 0.06287497
    Pr 0.09404571 0.19220430 0.05302854 0.00000000 0.10436469
    Sk 0.11184561 0.10112859 0.06287497 0.10436469 0.00000000
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{F-statistics for mixed ploidy data I}
	\begin{spluscode}
    # stamppFst requires population factor in genlight (here, population
    # code consists of first three letters of individual's name)
    indNames(arabidopsis.genlight)
    pop(arabidopsis.genlight) <- substr(x=indNames(arabidopsis.genlight),
      start=1, stop=3)
    pop(arabidopsis.genlight) # Check it
    popNames(arabidopsis.genlight)
    arabidopsis.fst <- StAMPP::stamppFst(geno=arabidopsis.genlight,
      nboots=100, percent=95, nclusters=1)
    # For large data use higher nclusters to parallelize calculations
    ?StAMPP::stamppFst # See method details
    arabidopsis.fst[["Fsts"]] # Matrix of Fst among populations
    arabidopsis.fst[["Pvalues"]] # Matrix of P values
    # Save results - open in spreadsheet (e.g. LibreOffice Calc)
    write.table(x=arabidopsis.fst[["Fsts"]], file="arabidopsis_fst.tsv",
      quote=FALSE, sep="\t")
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{F-statistics for mixed ploidy data II}
	\begin{itemize}
		\item Methods from StAMPP package (the same is the case for any method working somehow with distances) are sensitive to missing data\ldots
		\begin{itemize}
			\item Carefully filter the VCF before doing any analysis
		\end{itemize}
		\item Populations must be already defined in the genlight object
	\end{itemize}
	\begin{spluscode}
    # Correlation plot of pairwise Fst
    library(corrplot)
    corrplot(corr=arabidopsis.fst[["Fsts"]], method="circle", type="lower",
      col=funky(15), title="Correlation matrix of Fst among populations",
      is.corr=FALSE, diag=FALSE, outline=TRUE, order="alphabet", tl.pos="lt",
      tl.col="black")
    ?corrplot # See for more options
    # Display in similar way also another Fst tables
	\end{spluscode}
\end{frame}

% TODO population theta
%     # Estimates of population theta according to Kimmel et al. 1998
%     theta.msat(hauss.loci)
%                theta.v    theta.h theta.x
%     msta93  1287.09037 42.7450000  49.500
%     msta101  105.62800  0.6006928   0.000
%         ...        ...        ...     ...

\begin{frame}[fragile]{Multi locus genotypes}
	\begin{multicols}{2}
		\includegraphics[height=5.5cm]{mlg.png}
		\begin{spluscode}
    # Total number of MLGs
    # (simple value)
    mlg(gid=hauss.genind, quiet=FALSE)
    # MLGs shared among populations
    mlg.crosspop(gid=hauss.genind,
      df=TRUE, quiet=FALSE)
    # Detailed view on distribution
    # of MLGs into populations
    # (table and/or plot)
    mlg.table(gid=hauss.genind,
      bar=TRUE, total=TRUE,
      quiet=FALSE)
    mlg.vector(hauss.genind)
    mlg.id(hauss.genind)
		\end{spluscode}
	\end{multicols}
	Functions from poppr package --- the best for microsatellites, although available also for another data types
\end{frame}

\begin{frame}[fragile]{Inbreeding}
	\begin{multicols}{2}
		\includegraphics[height=7cm]{inbreeding.png}
		\begin{spluscode}
    # Load training data (cattle)
    data(microbov)
    # Separate populations of Salers
    microbov.pops <- seppop(microbov)
      [["Salers"]]
    microbov.pops # See it
    # Calculate the inbreeding
    microbov.inbr <- inbreeding(x=
      microbov.pops, N=100)
    ?inbreeding # Check for settings
    # population means for plotting
    microbov.bar <- sapply(X=
      microbov.inbr, FUN=mean)
    # Plot it
    hist(x=microbov.bar, col=
      "firebrick", main="Average
      inbreeding in Salers cattle")
		\end{spluscode}
	\end{multicols}
\end{frame}

\subsection{AMOVA}

\begin{frame}{AMOVA I}
	\begin{itemize}
		\item Analysis of molecular variance tests if there are significant differences among populations (and/or another levels)
		\item Some implementations can partition variance into various levels
		\item \texttt{pegas::amova} returns a~table of sums of square deviations (\texttt{SSD}), mean square deviations (\texttt{MSD}), and the number of degrees of freedom (\texttt{df}), and a~vector of variance components (\texttt{sigma2})
		\item See \texttt{sigma2} column for how much of the variance is on which level --- percentage can be calculated as percentage of each level from total
		\item For more complicated hierarchy see \texttt{?poppr::poppr.amova}
		\item For mixed-ploidy dat sets see \texttt{?StAMPP::stamppAmova}
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{AMOVA II}
	\begin{spluscode}
    hauss.pop <- pop(hauss.genind)
    hauss.amova <- pegas::amova(hauss.dist~hauss.pop, data=NULL,
      nperm=1000, is.squared=TRUE)
    # See results
    hauss.amova
    ...
                    SSD      MSD df
    hauss.pop  30.71923 7.679809  4
    Error     119.58100 2.847167 42
    Total     150.30023 3.267396 46
    ...
    Variance components:
               sigma2 P.value
    hauss.pop 0.55738       0 # From here we can calculate the percentage
    Error     2.84717
    ...
	\end{spluscode}
\end{frame}

\subsection{MSN}

\begin{frame}[fragile]{Minimum Spanning Network}{Package poppr, based on Bruvo's distance (for SSRs)}
	\label{MSN}
	\begin{multicols}{2}
		\begin{center}
			\includegraphics[height=5.5cm]{msn.png}
		\end{center}
		\begin{spluscode}
    ?bruvo.msn # See details...
		\end{spluscode}
		\columnbreak
		\begin{spluscode}
    bruvo.msn(gid=hauss.genind,
      replen=rep(2, 12), loss=TRUE,
      palette=rainbow, vertex.label
      ="inds", gscale=TRUE,
      wscale=TRUE, showplot=TRUE)
    ?msn.poppr # For another data types
    ?imsn # Interactive creation of MSN
		\end{spluscode}
		\begin{center}
			\includegraphics[width=3cm]{msn-bruvo_no_labels.png}
		\end{center}
	\end{multicols}
\end{frame}

\subsection{Genetic distances}

\begin{frame}[fragile]{Basic distances}
	\label{distances}
	\begin{spluscode}
    # See ?dist.gene for details about methods of this distance
    hauss.dist.g <- dist.gene(x=hauss.genind@tab, method="pairwise")
    # Euclidean distance for individuals (plain ordinary distance matrix)
    hauss.dist <- dist(x=hauss.genind, method="euclidean", diag=T, upper=T)
    # Nei's distance (not Euclidean) for populations (other methods are
    # available, see ?dist.genpop)
    hauss.dist.pop <- dist.genpop(x=hauss.genpop, method=1, diag=T, upper=T)
    # Test if it is Euclidean
    is.euclid(hauss.dist.pop, plot=TRUE, print=TRUE, tol=1e-10) # FALSE = No
    # Turn to be Euclidean
    hauss.dist.pop <- cailliez(distmat=hauss.dist.pop, print=FALSE, tol=1e-07,
      cor.zero=TRUE)
    is.euclid(hauss.dist.pop, plot=TRUE, print=TRUE, tol=1e-10) # TRUE = OK
	\end{spluscode}
	\vfil
	Most of analysis based on distances more or less require \href{https://en.wikipedia.org/wiki/Euclidean_distance_matrix}{Euclidean distances} (non-negative, Pythagorean theorem is valid, etc.). If the distance matrix contains non-Euclidean distances, the result can be weird\ldots
	\vfill
\end{frame}

\begin{frame}[fragile]{Distances reflecting microsatellite repeats}
	\begin{spluscode}
    # Bruvo's distances weighting SSRs repeats - take care about replen
    # parameter - requires repetition length for every SSRs locus
    hauss.dist.bruvo <- bruvo.dist(pop=hauss.genind, replen=rep(2, 12),
      loss=TRUE)
    # Test if it is Euclidean
    is.euclid(hauss.dist.bruvo, plot=TRUE, print=TRUE, tol=1e-10)
    # Turn to be Euclidean
    hauss.dist.bruvo <- cailliez(distmat=hauss.dist.bruvo, print=FALSE,
      tol=1e-07, cor.zero=TRUE)
    # Test if it is Euclidean
    is.euclid(hauss.dist.bruvo, plot=TRUE, print=TRUE, tol=1e-10)
    hauss.dist.bruvo  # Show it
	\end{spluscode}
	\begin{itemize}
		\item See poppr's manual and manual pages of the functions for details and different possibilities of settings
		\item Be careful when changing non-Euclidean distances to Euclidean --- \alert{the transformation more or less changes meaning of the distances!}
	\end{itemize}
\end{frame}

\begin{frame}{Turning distance matrix into Euclidean is controversial\ldots}
	\begin{footnotesize}
		How to deal with zero distances in original matrix? There is no really good solution\ldots\\ Histograms of Bruvo distance before and after transformation:
	\end{footnotesize}
	\begin{center}
		\includegraphics[width=\textwidth-4.5cm]{bruvodist.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{More distances\ldots}
	\begin{spluscode}
    # Nei's distance (not Euclidean) for individuals
    # (other methods are available, see ?nei.dist from poppr package)
    hauss.dist.nei <- nei.dist(x=hauss.genind, warning=TRUE)
    is.euclid(distmat=hauss.dist.nei, plot=TRUE, print=TRUE, tol=1e-10)
    # Dissimilarity matrix returns a distance reflecting the number of
    # allelic differences between two individuals
    hauss.dist.diss <- diss.dist(x=hauss.genind, percent=FALSE, mat=TRUE)
    is.euclid(as.dist(hauss.dist.diss), plot=TRUE, print=TRUE, tol=1e-10)
	\end{spluscode}
	\vfill
	\textbf{Import own distance matrix from another software:}
	\begin{multicols}{2}
		\begin{spluscode}
       Fe       He      Oh      ...
    Fe 0.00000  132.019 109.159 ...
    He 132.0191 0.00000 9.89111 ...
    Oh 109.1590 9.89111 0.00000 ...
    Pr 139.5669 8.55312 4.40562 ...
    Ne 156.7619 9.96143 16.6927 ...
    ... ...     ...     ...     ...
		\end{spluscode}
		\columnbreak
		\begin{spluscode}
    MyDistance <- read.csv("distances.
      txt", header=TRUE, sep="\t",
      dec=".", row.names=1)
    MyDistance <- as.dist(MyDistance)
    class(MyDistance)
    dim(MyDistance)
    MyDistance
		\end{spluscode}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Different distances have different use case and outputs\ldots}{Different distances available in package poppr}
	\vfill
	\begin{tabular}{llll}
		\textbf{Method} & \textbf{Function} & \textbf{Assumption} & \textbf{Euclidean}\\
		\href{https://link.springer.com/article/10.1007/BF00831894}{Prevosti 1975} & \texttt{prevosti.dist}, & --- & \alert{No}\\
			& \texttt{diss.dist} & & \\
		\href{https://www.jstor.org/stable/2459777}{Nei 1972}, \href{http://www.genetics.org/content/89/3/583.short}{1978} & \texttt{nei.dist} & Infinite Alleles, & \alert{No}\\
			& & Genetic Drift & \\
		\href{https://www.jstor.org/stable/2528824}{Edwards 1971} & \texttt{edwards.dist} & Genetic Drift & Yes\\
		\href{http://www.genetics.org/node/324318.full}{Reynolds 1983} & \texttt{reynolds.dist} & Genetic Drift & Yes\\
		Rogers 1972\footnote{Rogers (1972): Measures of genetic similarity and genetic distances. Pp. 145-153 of Studies in Genetics. University of Texas Publishers} & \texttt{rogers.dist} & --- & Yes\\
		\href{http://onlinelibrary.wiley.com/doi/10.1111/j.1365-294X.2004.02209.x/full}{Bruvo 2004} & \texttt{bruvo.dist} & Step-wise Mutation & \alert{No}
	\end{tabular}
	\vfill
	\begin{spluscode}
    # See details of distance methods in package poppr
    vignette("algo", package="poppr")
	\end{spluscode}
	\vfill
\end{frame}

\begin{frame}[fragile]{Comparison of different matrices}
	\begin{spluscode}
    # Compare different distance matrices
    # List of functions to be parsed to respective dist.* function
    distances <- c("Nei", "Rogers", "Edwards", "Reynolds", "Prevosti")
    # Calculate the distance matrices
    dists <- lapply(distances, function(x) {
      DISTFUN <- match.fun(paste(tolower(x), "dist", sep="."))
      DISTFUN(hauss.genind.cor) })
    # Add names for the distance names
    names(dists) <- distances
    dists[["Bruvo"]] <- hauss.dist.bruvo # Add Bruvo distance
    dists # Check list of distances
    par(mfrow=c(2, 3)) # Split graphical device into 2 lines, 3 panes each
    # Calculate NJ and plot all trees
    x <- lapply(names(dists), function(x) { plot(njs(dists[[x]]), main=x,
      type="unrooted")
      add.scale.bar(lcol="red", length=0.1) })
    dev.off() # Close graphical device to reset settings
	\end{spluscode}
\end{frame}

\begin{frame}{Neighbor-Joining of same dataset under different matrices}{The results are very different\ldots}
	\begin{center}
		\includegraphics[width=\textwidth-4cm]{distances.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Distances among DNA sequences}
	\begin{itemize}
		\item \alert{The sequences must be aligned before calculating distances among them!}
		\item Selection of mutational model has significant impact to results\ldots
	\end{itemize}
	\vfill
	\begin{spluscode}
    # There are various models available
    ?dist.dna
    # Create the distance matrix
    usflu.dist <- dist.dna(x=usflu.dna, model="TN93")
    # Check the resulting distance matrix
    usflu.dist
    class(usflu.dist)
    dim(as.matrix(usflu.dist))
    # Create another distance matrix
    meles.dist <- dist.dna(x=meles.dna, model="F81")
    # Check it
    meles.dist
    class(meles.dist)
    dim(as.matrix(meles.dist))
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Distances and genlight object}
	\vfill
	Pairwise genetic distances for each data block (genlight objects with whole genome data) --- sensitive to missing data (not useful in every case):
	\vfill
	\begin{spluscode}
    usflu.dists.l <- seploc(usflu.genlight, n.block=10, parallel=FALSE)
    class(usflu.dists.l)
    usflu.dists <- lapply(X=usflu.dists.l, FUN=function(D) dist(as.matrix(D)))
    class(usflu.dists)
    names(usflu.dists)
    class(usflu.dists[[1]])
    usflu.distr <- Reduce(f="+", x=usflu.dists)
    class(usflu.distr)
    usflu.distr
    # It is possible to use just basic dist function on whole genlight object
    # (might require a lot of RAM)
    usflu.distg <- dist(as.matrix(usflu.genlight))
	\end{spluscode}
	\vfil
	Rationale of this approach is to save resources when dividing whole data set into smaller blocks --- useful for huge data, not for all of the cases
	\vfill
\end{frame}

\begin{frame}[fragile]{Distances in mixed-ploidy data sets I}
	\begin{spluscode}
    # Load required library
    library(StAMPP)
    # stamppNeisD requires population factor in genlight Nei's 1972 distance
    # between individuals (use pop=TRUE to calculate among populations)
    arabidopsis.dist <- stamppNeisD(geno=arabidopsis.genlight, pop=FALSE)
    # Check it
    head(arabidopsis.dist)
    dim(arabidopsis.dist)
    class(arabidopsis.dist)
    # The same on population level
    arabidopsis.dist.pop <- stamppNeisD(geno=arabidopsis.genlight, pop=TRUE)
    # Check it
    head(arabidopsis.dist.pop)
    dim(arabidopsis.dist.pop)
    class(arabidopsis.dist.pop)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Distances in mixed-ploidy data sets II}
	\begin{spluscode}
    # Export the distance matrix as Phylip format for usage in
    # external software (e.g. SplitsTree)
    stamppPhylip(distance.mat=arabidopsis.dist, file="arabidopsis_dist.txt")
    # Genomic relationship matrix
    ?stamppGmatrix # Method details
    arabidopsis.genomat <- stamppGmatrix(geno=arabidopsis.genlight)
    # Check it
    head(arabidopsis.genomat)
    dim(arabidopsis.genomat)
    class(arabidopsis.genomat)
	\end{spluscode}
	\begin{itemize}
		\item If there are plenty of missing data and/or the distance is far from being Euclidean, it will not work very well\ldots{ } --- sanitize missing data prior calculating distance (e.g. using \texttt{poppr::missingno})
		\item Always check created distances
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Over 40 distances from philentropy package}
	\begin{itemize}
		\item There is enormous number of various distance measures\ldots
		\item For example \href{https://en.wikipedia.org/wiki/Jaccard_index}{Jaccard index} is used to compare binary (presence/absence) data like \href{https://en.wikipedia.org/wiki/Amplified_fragment_length_polymorphism}{AFLP}
	\end{itemize}
	\begin{spluscode}
    library(philentropy) # Load the library
    getDistMethods() # See available distances
    ?distance # See details of distances
    # Calculate e.g. Jaccard index for AFLP data
    # amara.aflp has 30 columns, see dim(amara.aflp)
    # column 1 contains names, see head(amara.aflp)
    amara.jac <- distance(x=amara.aflp[,2:30], method="jaccard")
    # See result
    class(amara.jac)
    amara.jac
    # Make it distance matrix
    amara.jac <- as.dist(m=amara.jac, diag=TRUE, upper=TRUE)
    amara.jac
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Visualize pairwise genetic similarities}
	\begin{multicols}{2}
		\vfil
		\begin{spluscode}
    # table.paint() requires data
    # frame, dist can't be directly
    # converted to DF
    table.paint(df=as.data.frame(
      as.matrix(usflu.dist)), cleg=0,
      clabel.row=0.5, clabel.col=0.5)
    # Same visualization, colored
    # heatmap() reorders values
    # because by default it plots
    # also dendrograms on the edges
    heatmap(x=as.matrix(usflu.dist),
      Rowv=NA, Colv=NA, symm=TRUE)
		\end{spluscode}
		\vfill
		\begin{itemize}
			\item Colored according to value
			\item Another possibility is to use \texttt{corrplot::corrplot()} for correlation plots
		\end{itemize}
		\columnbreak
		\begin{center}
			\includegraphics[height=7cm]{dna-dists.png}
		\end{center}
	\end{multicols}
\end{frame}

\subsection{Hierarchical clustering}

\begin{frame}[fragile]{Heat maps}
	\label{hierclust}
	\begin{multicols}{2}
		\includegraphics[height=7cm]{heatmap.png}
		\columnbreak
		\begin{spluscode}
    # Based on various distances
    heatmap(as.matrix(hauss.dist),
      symm=TRUE, labRow=rownames(
      as.matrix(hauss.dist.bruvo)),
      labCol=colnames(as.matrix(
      hauss.dist.bruvo)))
      # hauss.dist doesn't contain
      # names of individuals - add here
    heatmap(as.matrix(hauss.dist.pop),
      symm=TRUE)
    heatmap(as.matrix(hauss.dist.
      bruvo), symm=TRUE)
    heatmap(as.matrix(hauss.dist.
      diss), symm=TRUE)
		\end{spluscode}
		\begin{footnotesize}
			There are various settings --- colors, dendrogram,~\ldots See~\texttt{?heatmap}.
		\end{footnotesize}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Hierarchical clustering --- UPGMA and others}
	\begin{multicols}{2}
		\includegraphics[height=7cm]{hierclust.png}
		\begin{spluscode}
    # According to distance used
    # see ?hclust for methods
    plot(hclust(d=hauss.dist,
      method="complete"))
    plot(hclust(d=hauss.dist.pop,
      method="complete"))
    plot(hclust(d=hauss.dist.bruvo,
      method="complete"))
		\end{spluscode}
		\vfil
		\begin{itemize}
			\item This is very basic function to make dendrogram
			\item There are better possibilities (NJ etc --- see slide~\ref{NJ} and onward)
		\end{itemize}
	\end{multicols}
	\vfill
\end{frame}

\begin{frame}[fragile]{UPGMA and its test}
	\begin{spluscode}
    # Calculate it
    # Saving as phylo object (and not hclust) gives more
    # possibilities for further plotting and manipulations
    usflu.upgma <- as.phylo(hclust(d=usflu.dist, method="average"))
    plot.phylo(x=usflu.upgma, cex=0.75)
    title("UPGMA tree")
    # Test quality - tests correlation of original distance in the matrix
    # and reconstructed distance from hclust object
    plot(x=as.vector(usflu.dist), y=as.vector(as.dist(
      cophenetic(usflu.upgma))), xlab="Original pairwise distances",
      ylab="Pairwise distances on the tree", main="Is UPGMA
      appropriate?", pch=20, col=transp(col="black",
      alpha=0.1), cex=2)
    # Add correlation line
    abline(lm(as.vector(as.dist(cophenetic(usflu.upgma)))~
      as.vector(usflu.dist)), col="red")
	\end{spluscode}
\end{frame}

\begin{frame}{UPGMA is not the best choice here\ldots}
	\begin{center}
		\includegraphics[width=\textwidth-4cm]{upgma.png}
	\end{center}
	\vfil
	All points in the right graph should be clustered along the red line\ldots
	\vfill
\end{frame}

\subsection{NJ (and UPGMA) tree}

\begin{frame}[fragile]{Calculate and test NJ tree}
	\label{NJ}
	\begin{spluscode}
    hauss.nj <- nj(hauss.dist) # Calculates the tree (try various distances)
    # Test tree quality - plot original vs. reconstructed distance
    plot(as.vector(hauss.dist), as.vector(as.dist(cophenetic(hauss.nj))),
      xlab="Original distance", ylab="Reconstructed distance")
    abline(lm(as.vector(hauss.dist) ~
      as.vector(as.dist(cophenetic(hauss.nj)))), col="red")
    cor.test(x=as.vector(hauss.dist), y=as.vector(as.dist(cophenetic
      (hauss.nj))), alternative="two.sided") # Testing the correlation
    # Linear model for above graph
    summary(lm(as.vector(hauss.dist) ~
      as.vector(as.dist(cophenetic(hauss.nj))))) # Prints summary text
    # Plot a basic tree - see ?plot.phylo for details
    plot.phylo(x=hauss.nj, type="phylogram")
    plot.phylo(x=hauss.nj, type="cladogram", edge.width=2)
    plot.phylo(x=hauss.nj, type="fan", edge.width=2, edge.lty=2)
    plot.phylo(x=hauss.nj, type="radial", edge.color="red", edge.width=2,
      edge.lty=3, cex=2) # There are enormous graphical possibilities...
	\end{spluscode}
\end{frame}

\begin{frame}{Choose your tree\ldots}
	\begin{center}
		\includegraphics[width=\textwidth-5.5cm]{nj1.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Bootstrap}
	\begin{spluscode}
    # boot.phylo() re-samples all columns - remove population column first
    hauss.loci.nopop <- hauss.loci
    hauss.loci.nopop[["population"]] <- NULL
    # Calculate the bootstrap
    hauss.boot <- boot.phylo(phy=hauss.nj, x=hauss.loci.nopop,
      FUN=function(XXX) nj(dist(loci2genind(XXX))), B=1000)
    # boot.phylo returns NUMBER of replicates - NO PERCENTAGE
    # Plot the tree
    plot.phylo(x=hauss.nj, type="unrooted", main="Neighbor-Joining tree")
    # Labels for nodes - bootstrap - see ?nodelabels for graphical settings
    nodelabels(text=round(hauss.boot/10))
    ?boot.phylo # See details
    # Another possibility
    hauss.aboot <- aboot(x=hauss.genind, tree="nj", distance=nei.dist,
      sample=100) # Bootstrap values are in slot node.label
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Plotting bootstrap and nicer trees}
	\begin{spluscode}
    # Plot the tree, explicitly display node labels
    plot.phylo(x=hauss.aboot, show.node.label=TRUE)
    ?aboot # Package poppr
    ## Plot a nice tree with colored tips
    plot.phylo(x=hauss.nj, type="unr", show.tip=F, edge.width=3, main="NJ")
    # Labels for nodes - bootstrap - see ?nodelabels for graphical settings
    nodelabels(text=round(hauss.boot/10))
    # Colored labels - creates vector of colors according to populations
    nj.rainbow<-colorRampPalette(rainbow(length(levels(pop(hauss.genind)))))
    tiplabels(text=indNames(hauss.genind), bg=fac2col(x=pop(hauss.genind),
      col.pal=nj.rainbow)) # Colored tips
    ## Plot BW tree with tip symbols and legend
    plot.phylo(x=hauss.nj, type="clad", show.tip=F, edge.width=3, main="NJ")
    axisPhylo() # Add axis with distances
    # From node labels let's remove unneeded frame
    nodelabels(text=round(hauss.boot/10), frame="none", bg="white")
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Nicer trees}
	\begin{spluscode}
    # As tip label we use only symbols - see ?points for graphical details
    tiplabels(frame="none", pch=rep(0:4, times=c(13, 17, 2, 6, 9)), lwd=2,
      cex=2)
    # Plot a legend explaining symbols
    legend(x="topleft", legend=c("He", "Oh", "Pr", "Ne", "Sk"),
      border="black", pch=0:4, pt.lwd=2, pt.cex=2, bty="o", bg="lightgrey",
      box.lwd=2, cex=1.2, title="Populations")
    # See more options...
    ?plot.phylo
    ?nodelabels
    ?legend
    ?axis.phylo
	\end{spluscode}
\end{frame}

\begin{frame}{Choose your tree\ldots}
	\begin{center}
		\includegraphics[width=\textwidth-2cm]{nj2.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Trees based on Bruvo's distance}{Package poppr (bootstrap is incorporated within the function)}
	\begin{spluscode}
    # NJ
    hauss.nj.bruvo <- bruvo.boot(pop=hauss.genind, replen=rep(2, 12),
      sample=1000, tree="nj", showtree=TRUE, cutoff=1, quiet=FALSE)
    plot.phylo(x=hauss.nj.bruvo, type="unrooted", show.tip=FALSE,
      edge.width=3, main="Neighbor-Joining tree")
    # Call node labels as phylo$node.labels or phylo[["node.labels"]]
    nodelabels(hauss.nj.bruvo[["node.labels"]]) tiplabels(hauss.nj.bruvo
      [["tip.label"]], bg=fac2col(x=hauss.genind$pop, col.pal=nj.rainbow))
    # UPGMA
    hauss.upgma <- bruvo.boot(pop=hauss.genind, replen=rep(2, 12),
      sample=1000, tree="upgma", showtree=TRUE, cutoff=1, quiet=FALSE)
    plot.phylo(hauss.upgma, type="unrooted", show.tip=FALSE, edge.width=3,
      main="UPGMA tree")
    nodelabels(hauss.upgma[["node.labels"]])
    tiplabels(hauss.upgma[["tip.label"]], bg=fac2col(x=hauss.genind@pop,
      col.pal=nj.rainbow))
	\end{spluscode}
\end{frame}

\begin{frame}{Choose your tree\ldots}
	\begin{center}
		\includegraphics[width=\textwidth-2cm]{nj-upgma-bruvo.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{NJ tree of populations}
	\begin{spluscode}
    ?poppr::aboot # aboot() can use distances implemented in poppr:
    ?poppr::nei.dist
    # Calculations
    hauss.nj.pop <- aboot(x=hauss.genpop, tree="nj", distance="nei.dist",
      sample=1000, showtree=FALSE)
    print.phylo(hauss.nj.pop) # Information about result
    # Plot a tree
    plot.phylo(x=hauss.nj.pop, type="radial", show.node.label=TRUE,
      cex=1.2, edge.width=3, main="Neighbor-Joining tree of populations")
	\end{spluscode}
	\begin{center}
		\includegraphics[height=2.5cm]{nj_pop.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{NJ tree based on DNA sequences}
	\begin{spluscode}
    # Calculate the tree
    usflu.tree <- nj(X=usflu.dist)
    # Plot it
    plot.phylo(x=usflu.tree, type="unrooted", show.tip=FALSE)
    title("Unrooted NJ tree")
    # Colored tips
    usflu.pal <- colorRampPalette(topo.colors(length(levels(as.factor(
      usflu.annot[["year"]])))))
    # Tip labels
    tiplabels(text=usflu.annot$year, bg=num2col(usflu.annot$year,
      col.pal=usflu.pal), cex=0.75)
    # Legend - describing years - pretty() automatically shows best
    # values from given range, num2col() selects colors from color scale
    legend(x="bottomright", fill=num2col(x=pretty(x=1993:2008, n=8),
      col.pal=usflu.pal), leg=pretty(x=1993:2008, n=8), ncol=1)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Root the tree}
	\begin{spluscode}
    # Root the tree - "outgroup" is name of accession (in quotation
    # marks) or number (position within phy object)
    usflu.tree.rooted <- root.phylo(phy=usflu.tree, outgroup=1)
    # Plot it
    plot.phylo(x=usflu.tree.rooted, show.tip=FALSE, edge.width=2)
    title("Rooted NJ tree")
    # Labeling of tips
    tiplabels(text=usflu.annot$year, bg=transp(num2col(x=usflu.annot$year,
      col.pal=usflu.pal), alpha=0.7), cex=0.75, fg="transparent")
    # Add axis with phylogenetic distance
    axisPhylo()
    # Legend - describing years - pretty() automatically shows best
    # values from given range, num2col() selects colors from color scale
    legend(x="topright", fill=num2col(x=pretty(x=1993:2008, n=8),
      col.pal=usflu.pal), leg=pretty(x=1993:2008, n=8), ncol=1)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Bootstrap rooted tree}
	\begin{spluscode}
    # Calculate it
    usflu.boot <- boot.phylo(phy=usflu.tree.rooted, x=usflu.dna, FUN=
      function(EEE) root.phylo(nj(dist.dna(EEE, model="TN93")), outgroup=1),
      B=1000)
    # Plot the tree
    plot.phylo(x=usflu.tree.rooted, show.tip=FALSE, edge.width=2)
    title("NJ tree + bootstrap values")
    tiplabels(frame="none", pch=20, col=transp(num2col(x=usflu.annot[["year"]],
      col.pal=usflu.pal), alpha=0.7), cex=3.5, fg="transparent")
    axisPhylo()
    # Legend - describing years - pretty() automatically shows best
    # values from given range, num2col() selects colors from color scale
    legend(x="topright", fill=num2col(x=pretty(x=1993:2008, n=8),
      col.pal=usflu.pal), leg=pretty(x=1993:2008, n=8), ncol=1)
    # Plots bootstrap support - note usflu.boot contains raw numbers
    # transform it into percent
    nodelabels(text=round(usflu.boot/10), cex=0.75)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Collapse branches with low bootstrap support}
	\begin{spluscode}
    usflu.tree.usflu.na.density <- usflu.tree.rooted
    # Determine branches with low support - note BS values are in raw
    # numbers - use desired percentage with respect to number of bootstraps
    usflu.tocollapse <- match(x=which(usflu.boot < 700)+length(usflu.tree.
      rooted$tip.label), table=usflu.tree.usflu.na.density$edge[,2])
    # Set length of bad branches to zero
    usflu.tree.usflu.na.density$edge.length[usflu.tocollapse] <- 0
    # Create new tree
    usflu.tree.collapsed <- di2multi(usflu.tree.usflu.na.density, tol=0.00001)
    # Plot the consensus tree
    plot.phylo(x=usflu.tree.collapsed, show.tip=FALSE, edge.width=2)
    title("NJ tree after collapsing weak nodes")
    tiplabels(text=usflu.annot$year, bg=transp(num2col(x=usflu.annot
      [["year"]], col.pal=usflu.pal), alpha=0.7), cex=0.5, fg="transparent")
    axisPhylo()
    legend(x="topright", fill=num2col(x=pretty(x=1993:2008, n=8),
      col.pal=usflu.pal), leg=pretty(x=1993:2008, n=8), ncol=1)
	\end{spluscode}
\end{frame}

\begin{frame}{The trees}
	\begin{center}
		\includegraphics[width=\textwidth-7cm]{nj_dna.png}
	\end{center}
	\end{frame}

\begin{frame}{NJ is death. Long live NJ!}
	\label{NJ-replacement}
	\begin{itemize}
		\item \enquote{Basic} NJ has many limitations (problems with missing data, chaining of individuals,~\ldots) --- there are several tries to overcome them
		\item Package \texttt{phangorn} has functions \texttt{NJ()} and unweighted version \texttt{UNJ()}
		\item Package \texttt{ape} has functions \texttt{njs()} and \texttt{bionjs()} which are designed to perform well on distances with (more) missing values
		\item Function \texttt{bionj()} from \texttt{ape} implements BIONJ algorithm
		\item FastME functions (package \texttt{ape}) perform the minimum evolution algorithm and aim to be replacement of NJ --- read \texttt{?fastme} before use
		\item All those functions read distance matrix and their usage is same as with \enquote{classical} \texttt{nj()} (read manual pages before using them) --- it is also from package \texttt{ape}
	\end{itemize}
\end{frame}

\subsection{PCoA}

\begin{frame}[fragile]{PCoA I}
	\label{pcoa}
	\begin{spluscode}
    hauss.pcoa <- dudi.pco(d=dist(x=scaleGen(x=hauss.genind, center=TRUE,
      scale=FALSE, truenames=TRUE), method="euclidean"), scannf=FALSE, nf=3)
    s.label(dfxy=hauss.pcoa$li, clabel=0.75) # Basic display
    # To plot different axes use for example dfxy=hauss.pcoa$li[c(2, 3)]
    s.kde2d(dfxy=hauss.pcoa$li, cpoint=0, add.plot=TRUE) # Add kernel density
    # Add histogram of Eigenvalues
    add.scatter.eig(w=hauss.pcoa$eig, nf=3, xax=1, yax=2, posi="bottomleft",
      sub="Eigenvalues")
    # Percentage of variance explained by each PC axis
    100*hauss.pcoa$eig/sum(hauss.pcoa$eig)
    # Colored display according to populations
    # Creates vector of colors according to populations
    hauss.pcoa.col <- rainbow(length(levels(pop(hauss.genind))))
    s.class(dfxy=hauss.pcoa$li, fac=pop(hauss.genind), col=hauss.pcoa.col)
    add.scatter.eig(w=hauss.pcoa$eig, nf=3, xax=1, yax=2, posi="bottomleft",
      sub="Eigenvalues")
    title("Principal Coordinates Analysis") # Adds title to the graph
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{PCoA II}
	\begin{multicols}{2}
		\begin{center}
			\includegraphics[height=7cm]{pcoa.png}
		\end{center}
		\columnbreak
		\begin{spluscode}
    # Based on Bruvo's distance
    hauss.pcoa.bruvo <- dudi.pco(d=
      bruvo.dist(pop=hauss.genind,
      replen=rep(2, 12)),
      scannf=FALSE, nf=3)
    s.class(dfxy=hauss.pcoa.bruvo$li,
      fac=pop(hauss.genind),
      col=hauss.pcoa.col)
    add.scatter.eig(hauss.pcoa.bruvo$
      eig, posi="bottomright", 3,1,2)
    # Another possibility for colored
    # plot (see ?colorplot for details)
    colorplot(xy=hauss.pcoa$li[c(1,2)],
      X=hauss.pcoa$li, transp=TRUE,
      cex=3, xlab="PC 1", ylab="PC 2")
    title(main="PCoA, axes 1 and 2")
    abline(v=0, h=0, col="gray", lty=2)
		\end{spluscode}
	\end{multicols}
\end{frame}

\begin{frame}{PCoA --- Bruvo and colorplot}
	\begin{center}
		\includegraphics[width=\textwidth-2cm]{pcoa-dalsi.png}
	\end{center}
\end{frame}

\subsection{Tasks}

\begin{frame}{Process more data}{Not all combinations and possibilities were shown\ldots}
	\begin{exampleblock}{Tasks}
		\begin{enumerate}
			\item Most of examples of basic analysis were shown with the \textit{Taraxacum haussknechtii} microsatellite dataset --- try to do some analysis with another imported data
			\item Try some of the introduced analysis with your own custom imported data
			\item Try at least 2--3 analysis according to your interests
		\end{enumerate}
	\end{exampleblock}
	\begin{itemize}
		\item Of course, following chapters will show more possible analysis\ldots
		\item Previous examples are not covering all possibilities\ldots
		\item It is crucial to be able to edit the introduced commands to be able to handle your data
		\item Check help pages of the functions for more options what to do with your data
	\end{itemize}
\end{frame}

\section{SNP}

\begin{frame}{Single Nucleotide Polymorphism}{Special methods for large next-generation sequencing data}
	\tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
\end{frame}

\begin{frame}[fragile]{Special functions to work with huge SNP data sets}
	\begin{spluscode}
    # Plot of missing data (white) and number of 2nd alleles
    glPlot(x=usflu.genlight, legend=TRUE, posi="topleft")
    # Sum of the number of second allele in each SNP
    usflu.freq <- glSum(usflu.genlight)
    # Plot distribution of (second) allele frequencies
    hist(x=usflu.freq, proba=TRUE, col="gold", xlab="Allele frequencies",
      main="Distribution of (second) allele frequencies")
    lines(x=density(usflu.freq)$x, y=density(usflu.freq)$y*1.5, col="red",
      lwd=3 )
    # Mean number of second allele in each SNP
    usflu.mean <- glMean(usflu.genlight)
    usflu.mean <- c(usflu.mean, 1-usflu.mean)
    # Plot distribution of allele frequencies
    hist(x=usflu.mean, proba=TRUE, col="darkseagreen3", xlab="Allele
      frequencies", main="Distribution of allele frequencies", nclass=20)
    lines(x=density(usflu.mean, bw=0.05)$x, y=density(usflu.mean, bw=0.05)$y*2,
      lwd=3)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Number of missing values in each locus}
	\begin{spluscode}
    # Play with bw parameter to get optimal image
    usflu.na.density <- density(glNA(usflu.genlight), bw=10)
    # Set range of xlim parameter from 0 to the length of original alignment
    plot(x=usflu.na.density, type="n", xlab="Position in the alignment",
      main="Location of the missing values (NA)", xlim=c(0, 1701))
    polygon(c(usflu.na.density$x, rev(usflu.na.density$x)),
      c(usflu.na.density$y, rep(0, length(usflu.na.density$x))),
      col=transp("blue", alpha=0.3))
    points(glNA(usflu.genlight), rep(0, nLoc(usflu.genlight)), pch="|", cex=2,
      col="blue")
	\end{spluscode}
	\begin{itemize}
		\item Those tools are designed mainly for situation when having multiple (nearly) complete genomes --- not needed for smaller data sets
		\item Lets keep hoping in fast development of computers\ldots
		\item \alert{Windows users:} To speed up the processing, \texttt{gl*} functions use parallelisation library unavailable on Windows --- add parameter \texttt{parallel=FALSE} to be able to use them
	\end{itemize}
\end{frame}

\begin{frame}{Basic information about SNP: distribution of 2$^{nd}$ allele frequencies, missing data and number of 2$^{nd}$ allele, distribution of allele frequencies, and number of missing values in each locus}
	\begin{center}
		\includegraphics[width=\textwidth-2cm]{flu_alleles.png}
	\end{center}
\end{frame}

\subsection{PCA and NJ}

\begin{frame}[fragile]{PCA, NJ and genlight objects}
	\begin{spluscode}
    usflu.pca <- glPca(x=usflu.genlight, center=TRUE, scale=FALSE,
      loadings=TRUE) # Select number of retained PC axes, about 10 here
    scatter.glPca(x=usflu.pca, posi="bottomright") # Plot PCA
    title("PCA of the US influenza data")
    # Loading plot - contribution of variables to the pattern observed
    loadingplot.glPca(x=usflu.pca)
    colorplot(usflu.pca$scores, usflu.pca$scores, transp=TRUE, cex=4) # Cols
    title("PCA of the US influenza data")
    abline(h=0, v=0, col="gray")
    add.scatter.eig(usflu.pca[["eig"]][1:40], 2, 1, 2, posi="topright",
      inset=0.05, ratio=0.3)
    usflu.tree.genlight <- nj(dist(as.matrix(usflu.genlight))) # Get the tree
    # Plot colored phylogenetic tree
    plot.phylo(x=usflu.tree.genlight, type="fan", show.tip=FALSE)
    tiplabels(pch=20, col=num2col(usflu.annot[["year"]], col.pal=usflu.pal),
      cex=4)
    title("NJ tree of the US influenza data")
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{PCA, NJ and genlight objects}
	\begin{spluscode}
    legend(x="topright", fill=num2col(x=pretty(x=1993:2008, n=8),
      col.pal=usflu.pal), leg=pretty(x=1993:2008, n=8), ncol=1)
	\end{spluscode}
	\begin{center}
		\includegraphics[width=\textwidth-5.5cm]{flu_pcoa_nj.png}
	\end{center}
\end{frame}

\section{DAPC}

\begin{frame}{Discriminant Analysis of Principal components}
	\tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
\end{frame}

\begin{frame}[fragile]{DAPC}
	\label{DAPC}
	\begin{itemize}
		\item Discriminant Analysis of Principal components (\href{https://bmcgenet.biomedcentral.com/articles/10.1186/1471-2156-11-94}{Jombart et al. 2010})
		\item Runs K-means Bayesian clustering on data transformed with PCA (reduces number of variables, speeds up process)
		\item Finally it runs discriminant analysis (DA) to maximize differences among groups
		\item Various modes of displaying of results --- \enquote{Structure-like}, \enquote{PCA-like} and more
		\item More information at \url{http://adegenet.r-forge.r-project.org/} and \texttt{adegenetTutorial("dapc")}
		\item If following commands would seem too complicated to you, try web interface by this command:
	\end{itemize}
	\begin{spluscode}
    adegenetServer("DAPC") # Recommended to open in Google Chrome/Chromium
	\end{spluscode}
\end{frame}

\begin{frame}{Principal difference between PCA and DA}
	\begin{center}
		\includegraphics[height=6.5cm]{dapc-da-pca.png}
	\end{center}
\end{frame}

\subsection{Bayesian clustering}

\begin{frame}[fragile]{K-find --- Bayesian K-means clustering}
	\begin{spluscode}
    # Retain all informative PC (here about 35)
    # According to second graph select best K (here 2 or 3)
    # Now we select K=2 and later rerun the analysis for K=3 (lines 14-18)
    hauss.kfind <- find.clusters(x=hauss.genind, stat="BIC",
      choose.n.clust=TRUE, max.n.clust=10, n.iter=100000, n.start=100,
      scale=FALSE, truenames=TRUE)
    table(pop(hauss.genind), hauss.kfind$grp) # See results as text
    hauss.kfind
    # Graph showing table of original and inferred populations and
    # assignment of individuals
    table.value(df=table(pop(hauss.genind), hauss.kfind$grp), col.lab=
      paste("Inferred\ncluster", 1:length(hauss.kfind$size)), grid=TRUE)
    # For K=3 - note parameters n.pca and n.clust - we just rerun the
    # analysis and when results are stable, no problem here
    hauss.kfind3 <- find.clusters(x=hauss.genind, n.pca=35, n.clust=3,
      stat="BIC", choose.n.clust=FALSE, n.iter=100000, n.start=100,
      scale=FALSE, truenames=TRUE)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{K-find outputs}
	\begin{multicols}{2}
		\begin{itemize}
			\item Cumulative variance of axis
			\item BIC helps to select the best K
			\item Original and inferred groups
		\end{itemize}
		\includegraphics[height=5cm]{kmeans.png}
		\begin{spluscode}
    # See results as text
    table(pop(hauss.genind),
      hauss.kfind3$grp)
    hauss.kfind3
    # Graph showing table of original
    # and inferred populations and
    # assignment of individuals
    table.value(
      df=table(pop(hauss.
      genind), hauss.kfind3$grp),
      col.lab=paste("Inferred\n
      cluster",
      1:length(hauss.kfind3$size)),
      grid=TRUE)
    # If needed, use custom text for
    # parameter col.lab=c("...", "...")
    # as many labels as inferred groups
		\end{spluscode}
	\end{multicols}
\end{frame}

\subsection{Discriminant analysis and visualization}

\begin{frame}[fragile]{DAPC code I}
	\begin{spluscode}
    ## K=2
    # Create DAPC
    # Number of informative PC (Here 15, adegenet recommends < N/3). Select
    # number of informative DA (here only one is available - no PCA graph)
    hauss.dapc <- dapc(x=hauss.genind, pop=hauss.kfind$grp, center=TRUE,
      scale=FALSE, var.contrib=TRUE, pca.info=TRUE, truenames=TRUE)
    # Information
    hauss.dapc
    # Density function - only for first axis here!
    scatter(x=hauss.dapc, xax=1, yax=1, main="DAPC", bg="white", solid=0.5,
      leg=TRUE, txt.leg=c("Group 1", "Group 2"), posi.leg="topright")
    # Assignment of individuals to clusters
    assignplot(x=hauss.dapc)
    # Structure-like plot
    compoplot(x=hauss.dapc, xlab="Individuals", leg=FALSE)
    # Loadingplot - alleles the most adding to separation of individuals
    loadingplot(x=hauss.dapc$var.contr)
	\end{spluscode}
\end{frame}

\begin{frame}{DAPC for K=2}
	\begin{center}
		\includegraphics[width=\textwidth-5.5cm]{dapc2.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{DAPC code II}
	\begin{spluscode}
    # alfa-score - according to number of PC axis
    optim.a.score(x=hauss.dapc)
    ## K=3
    # Create DAPC
    # Number of informative PC (Here 15, adegenet recommends < N/3)
    # Select number of informative DA (here 2 - usually keep all of them)
    hauss.dapc3 <- dapc(x=hauss.genind, pop=hauss.kfind3$grp, center=TRUE,
      scale=FALSE, var.contrib=TRUE, pca.info=TRUE, truenames=TRUE)
    hauss.dapc # Information
    # A la PCA graph
    scatter(x=hauss.dapc3, main="DAPC, Taraxacum haussknechtii",
      bg="white", cex=3, clab=0, col=rainbow(3), posi.da="bottomleft",
      scree.pca=TRUE, posi.pca="bottomright", leg=TRUE,
      txt.leg=c("Group 1", "Group 2", "Group 3"), posi.leg="topleft")
	\end{spluscode}
	\begin{itemize}
		\item Especially graphical parameters have huge possibilities\ldots
		\item See \texttt{?scatter} and play with it\ldots
	\end{itemize}
\end{frame}

\begin{frame}{DAPC for K=3}
	\begin{center}
		\includegraphics[width=\textwidth-3cm]{dapc3.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{DAPC code III}
	\begin{spluscode}
    # Same in BW
    scatter(x=hauss.dapc3, main="DAPC, Taraxacum haussknechtii",
      bg="white", pch=c(15:17), cell=0, cstar=0, solid=1, cex=2.5, clab=0,
      col=gray.colors(3, start=0, end=0.8, gamma=2, alpha=0), posi.da=
      "bottomleft", scree.pca=TRUE, posi.pca="bottomright", leg=TRUE,
      txt.leg=c("Group 1", "Group 2", "Group 3"), posi.leg="topleft")
    # Density function - only for first axis here!
    scatter(x=hauss.dapc3, xax=1, yax=1, main="DAPC", bg="white", solid=0.5,
      leg=T, txt.leg=c("Group 1", "Group 2", "Group 3"), posi.leg="topleft")
    # Assignment of individuals to clusters
    assignplot(hauss.dapc3)
    # Structure-like plot
    compoplot(hauss.dapc3, xlab="Individuals", leg=FALSE)
    # Loadingplot - alleles the most adding to separation of individuals
    loadingplot(hauss.dapc3$var.contr)
    # alfa-score - according to number of PC axis
    optim.a.score(hauss.dapc3)
	\end{spluscode}
\end{frame}

\begin{frame}{DAPC for K=3, extra information}
	\begin{center}
		\includegraphics[width=\textwidth-5.5cm]{dapc3-extra.png}
	\end{center}
\end{frame}

\begin{frame}{Another DAPC example}
	\begin{center}
		\includegraphics[width=\textwidth-6cm]{dapc.png}
	\end{center}
\end{frame}

\section{Structure}

\begin{frame}{Bayesian clustering with Structure}
	\tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
\end{frame}

\begin{frame}[allowframebreaks]{Structure}
	\label{structure}
	\begin{itemize}
		\item Population genetic software for Bayesian clustering, \url{https://web.stanford.edu/group/pritchardlab/structure.html}
		\item De facto standard for population genetics, one of the most used software tools
		\item Uses Bayesian algorithm to find optimal distribution of individuals into the most natural number of groups (K)
		\item One Structure run tests one selected K
		\begin{itemize}
			\item User must run it repeatedly for several Ks to find the best division, e.g. from K=1 to K=10 (grouping into 1, 2, 3, \ldots, 10 clusters)
			\item User must run it repeatedly for each K~to see if the result is stable (because of stochasticity of the computational algorithm), e.g. 10 times each
			\item Finally there use to be hundreds of runs\ldots{ } (e.g. 100 like in this example)
			\item The best grouping into K~groups is selected according to posterior probability of each run (different groupings have different probability of being correct, we need to select the best one) and stability of runs (independent runs for a~given same K~return same results)
			\item Structure has Java GUI to set up repeated runs --- another possibility is to use R (or possibly any other scripting language like BASH, Perl or Python, depending on user's preference and knowledge)
		\end{itemize}
		\item Full procedure (parallel running of Structure using R and post-processing results with R and BASH) for Linux/UNIX computers is described at \url{https://trapa.cz/en/structure-r-linux}
		\item Relatively complicated tool requiring plenty of work\ldots
		\item Here is shown processing option using \href{https://r-forge.r-project.org/R/?group_id=1636}{ParallelStructure}, another option is package \href{https://CRAN.R-project.org/package=strataG}{strataG} (see \texttt{?strataG::structure})
	\end{itemize}
\end{frame}

\begin{frame}{Structure work flow}
	\begin{enumerate}
		\item Run multiple runs of Structure
		\begin{itemize}
			\item User must test several numbers of genetic clusters (K) and test each several times
			\item ParallelStructure (see later) can do this
		\end{itemize}
		\item Decide which K~is the best --- explore outputs
		\begin{itemize}
			\item Plain command line Structure does not help with this
			\item There is need for external application reading Structure output, summing them and helping decide which K~is the best
			\item \href{http://taylor0.biology.ucla.edu/structureHarvester/}{Structure Harvester} or Structure-sum R script (see later) can do this
		\end{itemize}
		\item Post process Structure outputs to prepare them for plotting
		\begin{itemize}
			\item Sort and align Structure outputs
			\item Probably most commonly done in \href{https://web.stanford.edu/group/rosenberglab/clumpp.html}{CLUMPP}
		\end{itemize}
		\item Plot the final graphs
		\begin{itemize}
			\item Can be done in nearly any enough advanced graphical tool (including some R functions), probably the most commonly used is \href{https://web.stanford.edu/group/rosenberglab/distruct.html}{distruct}
		\end{itemize}
	\end{enumerate}
\end{frame}

\subsection{Running Structure from R}

\begin{frame}[fragile]{Running Structure in parallel with R}
	\begin{itemize}
		\item Let's use modern multi-core CPUs and plenty of RAM in current computers --- parallelisation saves time
		\item \href{https://r-forge.r-project.org/R/?group_id=1636}{ParallelStructure} R library can optimally distribute computations of independent Structure runs among CPU cores
		\item When using it, cite \href{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0070651}{Besnier \& Glover 2013}
		\item I~show slightly modified way from \href{https://www.molecularecologist.com/2013/09/using-r-to-run-parallel-analysis-of-population-genetic-data-in-structure-parallelstructure/}{The Molecular Ecologist}
		\item Authors recommend to run it without GUI and not on Windows\ldots
		\item For this chapter start new R project in new working directory
	\end{itemize}
	\begin{spluscode}
    # Prepare special new empty directory and set working directory
    setwd("~/dokumenty/vyuka/r_mol_data/examples/structure/")
    install.packages("ParallelStructure",
      repos="https://r-forge.r-project.org") # Install the package
    library(ParallelStructure) # Load the library
    # It takes more or less same parameter as normal Structure
    ?parallel_structure # See Structure manual and function's documentation
	\end{spluscode}
\end{frame}

\begin{frame}{Preparing for ParallelStructure}
	Within working \enquote{structure} directory you need
	\begin{itemize}
		\item Subdirectory for results
		\item Text file describing jobs (\enquote{joblist})
			\begin{itemize}
				\item One row for one Structure run
				\item Every line contains name of run, list of populations separated by comas (e.g. 1,2,3,4,5) --- you don't have to use all populations in all runs
				\item K~for actual run
				\item Length of burnin chain
				\item Number of steps (in practice use much higher number than for the example --- also for length of burnin chain)
				\item Columns are separated by spaces (or TABs)
			\end{itemize}
		\item Data input file (see Structure manual)
			\begin{itemize}
				\item Make it as simple as possible --- remove all unneeded columns
				\item For population names use subsequent numbers from 1~to number of populations
				\item For individual names use only alphanumerical characters
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Input files}
	\vfil
	\textbf{Joblist file:}
	\vfil
	\begin{tabular}{lllll}
		S02 & 1,2,3,4,5 & 1 & 500 & 10000\\
		S06 & 1,2,3,4,5 & 2 & 500 & 10000\\
		S08 & 1,2,3,4,5 & 2 & 500 & 10000\\
		\ldots & \ldots & \ldots & \ldots & \ldots
	\end{tabular}
	\vfill
	\textbf{Input file:}
	\vfil
	\begin{tabular}{lllllllllll}
		& & & msta93 & msta101 & msta102 & msta103 & \ldots\\
		H01 & 1 & 0 & 269 & 198 & 221 & 419 & \ldots\\
		H01 & 1 & 0 & 269 & 198 & 223 & 419 & \ldots\\
		H02 & 1 & 0 & 275 & 198 & 221 & 419 & \ldots\\
		H02 & 1 & 0 & 283 & 198 & 223 & 419 & \ldots\\
		\ldots & \ldots & \ldots & \ldots & \ldots & \ldots & \ldots & \ldots
	\end{tabular}
	\vfil
\end{frame}

\begin{frame}[fragile]{Running ParallelStructure}
	\begin{spluscode}
    parallel_structure(joblist="joblist.txt", n_cpu=3, structure_path=
      "~/bin/", infile="hauss_stru.in", outpath="results/", numinds=47,
      numloci=12, plot_output=1, label=1, popdata=1, popflag=1,
      phenotypes=0, markernames=1, mapdist=0, onerowperind=0, phaseinfo=0,
      extracol=0, missing=-9, ploidy=2, usepopinfo=0, revert_convert=1,
      printqhat=1, locdata=0, recessivealleles=0, phased=0, noadmix=0,
      linkage=0, locprior=0, inferalpha=1)
	\end{spluscode}
	\begin{itemize}
		\item Choose \texttt{n\_cpu} according to your computer
		\item \texttt{structure\_path} points to \alert{directory} containing Structure binary
		\item \texttt{outpath} should aim to \alert{empty} directory
		\item \texttt{plot\_output=1} will produce plots for all runs
		\item Check all other settings according to Structure manual and your needs
		\item Get toy input file \url{https://soubory.trapa.cz/rcourse/hauss_stru.in} and joblist \url{https://soubory.trapa.cz/rcourse/joblist.txt}
	\end{itemize}
\end{frame}

\subsection{ParallelStructure on Windows}

\begin{frame}[fragile]{ParallelStructure and Windows}
	\begin{itemize}
		\item Authors do not recommend to run ParallelStructure on Windows\ldots
		\item \texttt{parallel\_structure()} uses for parallelisation library which is not available on Windows, instead try
	\end{itemize}
	\begin{spluscode}
    # Install Rmpi library required by ParallelStructure for
    # parallelisation on Windows (installation can be very problematic)
    install.packages("Rmpi")
    library(Rmpi)
    # Instead of parallel_structure() use MPI_structure()
    # with same arguments
    MPI_structure(...) # Same arguments as on previous slide
	\end{spluscode}
	\begin{itemize}
		\item It may help to set \texttt{n\_cpu=1}, but it is only for testing then, not for real work...
		\item If this fails, look for some UNIX machine (Linux, macOS, BSD,~\ldots)\ldots
	\end{itemize}
\end{frame}

\subsection{Post processing}

\begin{frame}[fragile]{Post process Structure results --- select the best K}
	\begin{itemize}
		\item Using Structure-sum-2011 R script by \href{https://en.uit.no/om/enhet/ansatte/person?p_document_id=41186&p_dimension_id=88165}{Dorothee Ehrich}
	\end{itemize}
	\begin{spluscode}
    # Load the script
    source("https://soubory.trapa.cz/rcourse/structure-sum-2011.r")
    # Create new directory with result files results_job_*_f and set
    # working directory accordingly
    setwd("~/dokumenty/vyuka/r_mol_data/examples/structure/structure_sum/")
	\end{spluscode}
	\begin{itemize}
		\item When using it, cite \href{https://onlinelibrary.wiley.com/doi/full/10.1111/j.1471-8286.2006.01380.x}{Ehrich 2006}. If you don't have the script, ask (it is not my so I~don't want to post it on the net), see \href{https://soubory.trapa.cz/rcourse/structure-sum-2011.pdf}{manual}
		\item Prepare \textbf{list\_k.txt} containing on each line K~and name of output file
		\item Get list K~(example of the joblist below) from \url{https://soubory.trapa.cz/rcourse/list_k.txt}
	\end{itemize}
	\vfil
	\begin{tabular}{ll}
		2 & results\_job\_S010\_f\\
		3 & results\_job\_S011\_f\\
		\ldots & \ldots
	\end{tabular}
\end{frame}

\begin{frame}[fragile]{Run Structure-sum}
	\begin{spluscode}
    # See documentation for details. Functions take as an argument
    # list_k file and number of populations
    Structure.table("list_k.txt", 5)
    Structure.simil("list_k.txt", 5)
    Structure.deltaK("list_k.txt", 5)
    graphics.off() # Close graphics
    Structure.cluster("list_k.txt", 5)
    # Reordering ("alignment") of runs to get same clusters in same columns
    # (prepare respective list_k files - one for each K)
    # Preparing data for CLUMPP
    Structure.order("list_k_02.txt", 5)
    Structure.order("list_k_03.txt", 5)
    Structure.order("list_k_04.txt", 5)
    Structure.order("list_k_05.txt", 5)
    Structure.order("list_k_06.txt", 5)
    Structure.order("list_k_07.txt", 5) # Continue with CLUMPP and distruct...
	\end{spluscode}
	\begin{itemize}
		\item Details: \url{https://trapa.cz/en/structure-r-linux}
	\end{itemize}
\end{frame}

\begin{frame}{Outputs of Structure-sum --- the best K~is 2, may be 3~--- stability of runs, good posterior probability}{Results from different data set, not from our toy}
	\begin{center}
		\includegraphics[width=\textwidth-1.5cm]{structure.png}
	\end{center}
\end{frame}

\begin{frame}{Example of final Structure plot}{Drawn by distruct after alignment of Structure outputs by CLUMPP}
	\begin{itemize}
		\item Each bar is one individual
		\item Each color is one genetic cluster (here is shown clustering for K=12)
		\item Individuals with columns composing of more colors are genetically mixture of more clusters
		\item Details: \url{https://trapa.cz/en/structure-r-linux}
	\end{itemize}
	\includegraphics[width=\textwidth]{structure-fin.png}
\end{frame}

\section{Spatial analysis}

\begin{frame}[fragile]{Spatial analysis and genetic data}{Correlation of genes and space, spatial structure of genotypes}
	\tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
	\vfill
	\begin{spluscode}
    # Go back to the original working directory
    # Go to YOUR OWN directory, same as on beginning
    setwd("~/dokumenty/vyuka/r_mol_data/examples/")
	\end{spluscode}
\end{frame}

\begin{frame}{Short overview of spatial genetics (in R)}{Basic approaches}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Moran\%27s_I}{Moran's~\textit{I}} --- several implementations (here as basic autocorrelation index, in sPCA and in Monmonier's algorithm), generally it is autocorrelation coefficient with broader use
		\item \href{https://en.wikipedia.org/wiki/Mantel_test}{Mantel test} --- several implementations, popular, although recently criticized as biologically irrelevant, generally correlation of two matrices (here genetic and geographical)
		\item Bayesian clustering using geographical information as a~proxy and showing results in geographical context (here as implemented in Geneland)
		\item There are unlimited possibilities with connections with GIS software --- check specialized courses and literature
	\end{itemize}
\end{frame}

\subsection{Moran's~I}

\begin{frame}{Moran's~\textit{I}}
	\begin{multicols}{2}
		\begin{itemize}
			\item \enquote{Only} autocorrelation index --- no genetic/evolutionary model involved --- sometimes criticized as biologically irrelevant mechanism
			\item This (or similar) approach can be used to test correlation between another characteristics (typically used in ecology)
			\item Calculations are done according to connectivity network connecting individuals/populations (created by \texttt{chooseCN}) --- carefully check its options and try several parameters
			\item Pay attention which hypothesis is tested (i.e. if lower, greater or two-sided) --- similar to T-test
		\end{itemize}
		\begin{center}
			\includegraphics[width=4.5cm]{choosecn.png}
		\end{center}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Calculation of Moran's \textit{I} I}
	\begin{spluscode}
    library(spdep) # Load required library
    # Creates connection network
    hauss.connectivity <- chooseCN(xy=hauss.genind$other$xy, type=5, d1=0,
      d2=1, plot.nb=TRUE, result.type="listw", edit.nb=FALSE)
    hauss.connectivity
    # Test of Moran's I for 1st PCoA axis
    # Results can be checked against permuted values of moran.mc()
    moran.test(x=hauss.pcoa[["li"]][,1], listw=hauss.connectivity,
      alternative="greater", randomisation=TRUE)
    Moran's I test under randomisation
    data:  hauss.pcoa$li[, 1]
    weights: hauss.connectivity
    Moran I statistic standard deviate = -18.514, p-value = 1
    alternative hypothesis: greater
    sample estimates:
    Moran I statistic       Expectation          Variance
        -0.5232003724     -0.0217391304      0.0007336276
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Calculation of Moran's \textit{I} II}
	\begin{spluscode}
    # Test of Moran's I for 1st PCoA axis
    hauss.pcoa1.mctest <- moran.mc(x=hauss.pcoa$li[,1],
      listw=hauss.connectivity, alternative="greater", nsim=1000)
    hauss.pcoa1.mctest
    # Output:
      Monte-Carlo simulation of Moran I
    data:  hauss.pcoa$li[, 1]
    weights: hauss.connectivity
    number of simulations + 1: 1001
    statistic = -0.5163, observed rank = 1, p-value = 0.999
    alternative hypothesis: greater
    # Plot the results
    plot(hauss.pcoa1.mctest) # Plot of densitiy of permutations
    moran.plot(x=hauss.pcoa$li[,1], listw=hauss.connectivity) # PC plot
	\end{spluscode}
\end{frame}

\begin{frame}{Moran's~\textit{I} for our 1$^{st}$ axis isn't significant}
	\begin{center}
		\includegraphics[width=\textwidth-5cm]{moran1.png}
	\end{center}
	\begin{itemize}
		\item Tested hypothesis \enquote{greater} --- \textbf{no} significant \textbf{positive} autocorrelation
		\item If testing for hypothesis \enquote{less} --- significant \textbf{negative} autocorrelation --- individuals are significantly different
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Calculation of Moran's \textit{I} (2$^{nd}$ axis)}
	\begin{spluscode}
    # Test of Moran's I for 2nd PCoA axis
    moran.test(x=hauss.pcoa$li[,2], listw=hauss.connectivity,
      alternative="greater", randomisation=TRUE)
    hauss.pcoa2.mctest <- moran.mc(x=hauss.pcoa$li[,2],
      listw=hauss.connectivity, alternative="greater", nsim=1000)
    hauss.pcoa2.mctest
    # Output
    Monte-Carlo simulation of Moran's I
    data:  hauss.pcoa$li[, 2]
    weights: hauss.connectivity
    number of simulations + 1: 1001
    statistic = 0.0545, observed rank = 1001, p-value = 0.000999
    alternative hypothesis: greater
    # Plot the results
    plot(hauss.pcoa2.mctest) # Plot of densitiy of permutations
    moran.plot(x=hauss.pcoa$[,2], listw=hauss.connectivity) # PC plot
	\end{spluscode}
\end{frame}

\begin{frame}{Second axis is surprisingly significant}
	\begin{center}
		\includegraphics[width=\textwidth-4cm]{moran2.png}
	\end{center}
	\begin{itemize}
		\item Tested hypothesis \enquote{greater} --- there \textbf{is} significant positive autocorrelation --- individuals are genetically similar over space
	\end{itemize}
\end{frame}

\subsection{sPCA}

\begin{frame}[fragile]{Spatial Analysis of Principal Components (sPCA)}
	\begin{itemize}
		\item Implemented in adegenet, see \texttt{adegenetTutorial("spca")}
		\item Analyzes matrix of relative allele frequencies of genotypes/populations and spatial weighting matrix
		\item The geographical matrix is usually (as for Moran's~\textit{I}) created by \texttt{chooseCN()} --- creates connectivity network among entities (genotypes/populations) --- spatial coordinates are not directly used
		\item When using \texttt{chooseCN()}, look at the documentation and try various methods with changing settings to see differences
	\end{itemize}
	\begin{spluscode}
    data(rupica) # Loads adegenet's training dataset
                 # Rupicapra rupicapra from French Prealps
    # Try various settings for chooseCN (type=X) - type 1-4 as there
    # are identical coordinates (multiple sampling from same locality)
    chooseCN(xy=rupica$other$xy, ask=TRUE, type=5/6/7, plot.nb=TRUE,
      edit.nb=FALSE, ...) # Play with settings little bit...
    ?chooseCN # See for more details - select the best "type" for your data
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Calculations of sPCA}
	\begin{spluscode}
    hauss.spca <- spca(obj=hauss.genind, cn=hauss.connectivity,
      scale=TRUE, scannf=TRUE)
    # Plot eigenvalues of sPCA - global vs. local structure
    barplot(height=hauss.spca$eig, main="Eigenvalues of sPCA",
      col=spectral(length(hauss.spca$eig)))
    legend("topright", fill=spectral(2), leg=c("Global structures",
      "Local structures")) # Add legend
    abline(h=0, col="gray") # Add line showing zero
    print.spca(hauss.spca) # Information about sPCA
    summary.spca(hauss.spca) # Summary of sPCA results
    # Shows connectivity network, 3 different scores
    # barplot of eigenvalues and eigenvalues decomposition
    plot.spca(hauss.spca)
    colorplot.spca(hauss.spca, cex=3) # Display of scores in color canals
    title("sPCA - colorplot of PC 1 and 2 (lagged scores)", line=1, cex=1.5)
    # Spatial and variance components of the eigenvalues
    screeplot.spca(x=hauss.spca, main=NULL)
	\end{spluscode}
\end{frame}

\begin{frame}{sPCA outputs I}
	\begin{center}
		\includegraphics[width=\textwidth-6cm]{spca.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Test if global/local structure is significant}
	\begin{spluscode}
    hauss.spca.glo <- global.rtest(X=hauss.genind$tab, listw=hauss.spca$lw,
      nperm=999)
    hauss.spca.glo
    plot(hauss.spca.glo)
    hauss.spca.loc <- local.rtest(X=hauss.genind$tab, listw=hauss.spca$lw,
      nperm=999)
    hauss.spca.loc
    plot(hauss.spca.loc)
	\end{spluscode}
	\vfill
	\begin{center}
		\includegraphics[width=\textwidth-5cm]{spca-glob-loc.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Map of genetic clines}
	\begin{spluscode}
    library(akima) # It is needed for manipulation with coordinates
    # Transform the coordinates
    hauss.spca.temp <- interp(other(hauss.genind)$xy[,1],
      other(hauss.genind)$xy[,2], hauss.spca$ls[,1],
      xo=seq(min(other(hauss.genind)$xy[,1]),
      max(other(hauss.genind)$xy[,1]), le=200),
      yo=seq(min(other(hauss.genind)$xy[,2]),
      max(other(hauss.genind)$xy[,2]), le=200), duplicate="median")
    # For 1st axis
    image(x=hauss.spca.temp, col=spectral(100))
    s.value(dfxy=hauss.genind$other$xy, z=hauss.pcoa$li[,1], add.p=TRUE,
      csize=0.5, sub="PCoA - first PC", csub=2, possub="topleft")
    # For 2nd axis
    image(x=hauss.spca.temp, col=spectral(100))
    s.value(dfxy=hauss.genind$other$xy, z=hauss.pcoa[["li"]][,2],
      add.p=TRUE, csize=0.5, sub="PCoA - second PC", csub=2, possub="topleft")
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{sPCA outputs II}
	\begin{spluscode}
    # Interpolated lagged score on a map
    hauss.spca.annot <- function() {
      title("sPCA - interpolated map of individual scores")
      points(other(hauss.genind)$xy[,1], other(hauss.genind)$xy[,2])
      }
    filled.contour(hauss.spca.temp, color.pal=colorRampPalette(
      lightseasun(100)), pch=20, nlevels=100, key.title=title("Lagged\n
      score 1"), plot.title=hauss.spca.annot())
	\end{spluscode}
	\begin{center}
		\includegraphics[width=\textwidth-6cm]{spca-pc.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Loading plots --- which alleles contribute the most?}
	\begin{spluscode}
    hauss.spca.loadings <- hauss.spca[["c1"]][,1]^2
    names(hauss.spca.loadings) <- rownames(hauss.spca$c1)
    loadingplot(x=hauss.spca.loadings, xlab="Alleles", ylab="Weight of the
      alleles", main="Contribution of alleles to the first sPCA axis")
    boxplot(formula=hauss.spca.loadings~hauss.genind$loc.fac, las=3,
      ylab="Contribution", xlab="Marker", main="Contribution by markers into
      the first global score", col="gray")
	\end{spluscode}
	\vfill
	\begin{center}
		\includegraphics[width=\textwidth-5cm]{spca-loading.png}
	\end{center}
\end{frame}

\subsection{Monmonier}

\begin{frame}[fragile]{Monmonier's algorithm --- genetic boundaries}
	\begin{itemize}
		\item Finds boundaries of maximum differences between contiguous polygons of a~tessellation
		\item Detects genetic boundaries among georeferenced genotypes (or populations)
		\item For more information see \texttt{adegenetTutorial("basics")}
		\item Requires every point to have unique coordinates --- in case of population data it is better to work with populations, not individuals (but it is not ideal)
		\item It uses \href{https://en.wikipedia.org/wiki/Voronoi_diagram}{Voronoi tessellation}
	\end{itemize}
	\begin{spluscode}
    # Calculates Monmonier's function (for threshold use 'd')
    hauss.monmonier <- monmonier(xy=hauss.genpop$other$xy, dist=
      dist(hauss.genpop@tab), cn=chooseCN(hauss.genpop$other$xy,
      ask=FALSE, type=2, plot.nb=FALSE, edit.nb=FALSE), nrun=1)
    coords.monmonier(hauss.monmonier) # See result as text
	\end{spluscode}
\end{frame}

\begin{frame}{Voronoi tessellation}
	\begin{multicols}{2}
		\includegraphics[height=5.5cm]{voronoi_diagram.png}
		\begin{itemize}
			\item In simplest case, all points have certain area and all points within this area are closer to the respective \enquote{main} point than to any other \enquote{neighbor} point
			\item Extreme differences among size of areas make computational problems and results are unstable --- this typically occurs when calculations are done on individual level an there are large distances among populations
		\end{itemize}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Plot genetic boundaries}
	\begin{multicols}{2}
		\includegraphics[height=5.5cm]{monmonier.png}
		\begin{spluscode}
    plot.monmonier(hauss.monmonier,
      add.arrows=FALSE, bwd=10,
      sub="Monmonier plot", csub=2)
    points(hauss.genpop$other$xy,
      cex=2.5, pch=20, col="red")
    text(x=hauss.genpop$other$xy$lon,
      y=hauss.genpop$other$xy$lat,
      labels=popNames(hauss.genpop),
      cex=3)
    legend("bottomright",
      leg="Genetic boundaries\n
      among populations")
    # For plotting see
    ?points
    ?text
    ?legend
		\end{spluscode}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Monmonier notes}
	\begin{itemize}
		\item Sometimes it is needed to get rid of random noise in data. To do so use as parameter \texttt{dist} of \texttt{monmonier()} table from PCA (\texttt{pcaObject\$li}):
	\end{itemize}
	\begin{spluscode}
    monmonier(..., dist=dudi.pco(d=dist(x=GenindObject$tab),
      scannf=FALSE, nf=1)$li, ...)
	\end{spluscode}
	\begin{itemize}
		\item Generally (when dataset is bigger and more diverse) it is recommended to run it several times (parameter \texttt{nrun}) --- there will be several iterations
		\item See \texttt{?plot.monmonier} for various graphical parameters to customize the plot
		\item Use \texttt{points()} to add for example colored symbols of samples and/or \texttt{text()} to add text labels
	\end{itemize}
\end{frame}

\subsection{Mantel test}

\begin{frame}{Mantel test}
	\begin{itemize}
		\item Originally created for biomedicine to test correlation between treatment and diseases
		\item \enquote{Only} correlation of two matrices --- no biologically relevant underlying model --- because of that it is heavily criticized (mainly in ecology)
		\item It is universal method usable for plenty of tasks
		\item Test of spatial and genetic relationships is probably one of few biologically relevant applications
		\item Package vegan (set of ecological tools) has implementation to test genetic similarity in various distance classes --- not only overall result --- very useful
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Mantel test --- isolation by distance}
	\begin{spluscode}
    # Geographical distance
    hauss.gdist <- dist(x=hauss.genind$other$xy, method="euclidean", diag=TRUE,
      upper=TRUE)
    # Mantel test
    hauss.mantel <- mantel.randtest(m1=hauss.dist, m2=hauss.gdist, nrepet=1000)
    hauss.mantel # See text output
    plot(hauss.mantel, nclass=30)
    # Libraries required by mantel.correlog:
    library(permute)
    library(lattice)
    library(vegan)
    # Different implementation of Mantel test testing distance classes
    hauss.mantel.cor <- mantel.correlog(D.eco=hauss.dist,D.geo=hauss.gdist,
      XY=NULL, n.class=0, break.pts=NULL, cutoff=FALSE, r.type="pearson",
      nperm=1000, mult="holm", progressive=TRUE)
    hauss.mantel.cor # See results for respective classes
    summary(hauss.mantel.cor)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Mantel test outputs --- strongly significant}
	\begin{multicols}{2}
		\includegraphics[height=7cm]{mantel.png}
		\vfill
		\begin{spluscode}
    hauss.mantel # See output
    Monte-Carlo test
    Call: mantel.randtest(m1 =
      hauss.dist, m2 =
      hauss.gdist, nrepet = 1000)
    Observation: 0.35409
    Based on 1000 replicates
    Simulated p-value: 0.000999001
    Alternative hypothesis: greater
      Std.Obs Expectation  Variance
    7.61967545 0.001687140 0.0021389
		\end{spluscode}
		\vfill
		\begin{spluscode}
    # Plot correlogram (next slide)
    plot(hauss.mantel.cor)
		\end{spluscode}
		\vfill
	\end{multicols}
\end{frame}

\begin{frame}{Plot of Mantel Correlogram Analysis}
	\vfil
	\begin{center}
		\includegraphics[width=\textwidth-5.5cm]{mantel-cor.png}
	\end{center}
	\vfil
	Correlation (genetic similarity) in several distance classes (positive \textbf{[up]} in short distance \textbf{[left]}, negative \textbf{[down]} in long \textbf{[right]}; \textbf{[full]} --- significant, \textbf{[empty]} --- not significant) --- see \texttt{?mantel.correlog} for details
	\vfill
\end{frame}

\begin{frame}[fragile]{Mantel correlogram --- text output}
	\begin{spluscode}
    hauss.mantel.cor # See the text output:
    Mantel Correlogram Analysis
    Call:
    mantel.correlog(D.eco = hauss.dist, D.geo = hauss.gdist, XY = NULL,
     n.class = 0, break.pts = NULL, cutoff = FALSE, r.type = "pearson",
     nperm = 1000, mult = "holm", progressive = TRUE)
            class.index     n.dist Mantel.cor Pr(Mantel) Pr(corrected)
    D.cl.1     0.054757 532.000000   0.409545     0.0010      0.000999 ***
    D.cl.2     0.164271   0.000000         NA         NA            NA
    D.cl.3     0.273784  52.000000   0.028055     0.2797      0.279720
    D.cl.4     0.383298   0.000000         NA         NA            NA
    D.cl.5     0.492812 466.000000  -0.097214     0.0160      0.031968 *
    D.cl.6     0.602325  36.000000  -0.086288     0.0140      0.041958 *
    D.cl.7     0.711839 108.000000  -0.044109     0.1568      0.313686
       ...          ...        ...        ...        ...           ...
    ---
    Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
	\end{spluscode}
\end{frame}

\subsection{Geneland}

\begin{frame}[fragile]{About Geneland}
	\label{GenelandUse}
	\begin{itemize}
		\item For installation see slide~\ref{Geneland}
		\item Works with haploid and diploid co-dominant markers (microsatellites or SNPs)
		\item Spatially explicit Bayesian clustering
		\item Produces maps of distribution of inferred genetic clusters
		\item Relative complicated tool with various modeling options
		\item For more information see \url{https://i-pri.org/special/Biostatistics/Software/Geneland/}
	\end{itemize}
	\vfill
	\begin{spluscode}
    # Load needed libraries
    library(PBSmapping) # Required to transform coordinates
    library(Geneland)
    # Graphical interface is available, we will use only command line...
    Geneland.GUI()
	\end{spluscode}
\end{frame}

\begin{frame}{Geneland GUI}
	\begin{itemize}
		\item Some tasks are easier in GUI, some in command line\ldots
		\item Command line is great for its repeatability\ldots
		\item Always read manual! It is not the simplest tool\ldots
	\end{itemize}
	\begin{center}
		\includegraphics[height=5cm]{geneland_gui.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Loading and conversions of coordinates}
	\begin{spluscode}
    # Geneland requires specific coordinate space
    # hauss.cord is DF, we need just plain matrix
    hauss.geneland.coord <- as.matrix(hauss.coord)
    colnames(hauss.geneland.coord) <- c("X", "Y")
    attr(hauss.geneland.coord, "projection") <- "LL"
    attr(hauss.geneland.coord, "zone") <- NA
    hauss.geneland.coord.utm <- convUL(hauss.geneland.coord)
    dim(hauss.geneland.coord)
    hauss.geneland.coord
    dim(hauss.geneland.coord.utm)
    hauss.geneland.coord.utm # Final coordinates
    # Load data (only haploid or diploid data are supported)
    # only plain table with alleles
    hauss.geneland.data <- read.table(file= "https://soubory.trapa.cz/rcourse/
      haussknechtii_geneland.txt", na.string="-999", header=FALSE, sep="\t")
    dim(hauss.geneland.data)
    hauss.geneland.data
	\end{spluscode}
\end{frame}

\begin{frame}{Before running MCMC}
	\begin{multicols}{2}
		\begin{itemize}
			\item Monte Carlo Markov Chains (MCMC) require usually millions of generations (iterations, \texttt{nit)} to find optimal solution
			\item Beginning ($\sim$10--20\%) of the steps (\texttt{burnin}) use to be very unstable and useless for following analysis and it is discarded
			\item Geneland allows to set density of sampling among generations (\texttt{thinning}) --- it is not necessary to sample every generation
			\item Within millions of generations we can sample every 1000--10000$^{th}$ generation
			\item Denser sampling produces smoother data, but can consume too much disk space\ldots
		\end{itemize}
		\vfill
		Directory structure for Geneland:
		\vfil
		\begin{center}
			\includegraphics[width=3cm]{genelad_dirs.png}
		\end{center}
		\vfill
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Settings and running MCMC}
	\begin{spluscode}
    hauss.geneland.nrun <- 5 # Set number of independent runs
    hauss.geneland.burnin <- 100 # Set length of burnin chain
    hauss.geneland.maxpop <- 10 # Set maximal K (number of populations)
    # FOR loop will run several independent runs and produce output maps
    # of genetic clusters - outputs are written into subdirectory within
    # geneland directory (this has to exist prior launching analysis)
    for (hauss.geneland.irun in 1:hauss.geneland.nrun) {
      hauss.geneland.path.mcmc <- paste("geneland/", hauss.geneland.irun, "/",
      sep="") # paste is good especially for joining several texts
      # On Windows, remove following line and create subdirectories from
      # 1 to max K manually (creating subdirs in Windows in R is complicated)
      system(paste("mkdir ", hauss.geneland.path.mcmc)) # Creates subdirs
      # Inference - MCMC chain - see ?MCMC for details
      MCMC(coordinates=hauss.geneland.coord.utm, geno.dip.codom=hauss.geneland
        .data, path.mcmc=hauss.geneland.path.mcmc, delta.coord=0.001, varnpop=
        TRUE, npopmin=1, npopmax=hauss.geneland.maxpop, nit=10000, thinning=10,
        freq.model="Uncorrelated", spatial=TRUE) # Loop continues on next slide
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Running MCMC}
	\begin{spluscode}
      # Start of FOR loop is on previous page. In practice set much higher
      # number of iterations (nit, millions), appropriate sampling (thinning,
      # thousands) and longer burnin. Post-process chains
      PostProcessChain(coordinates=hauss.geneland.coord.utm, path.mcmc=hauss.
        geneland.path.mcmc, nxdom=500, nydom=500, burnin=hauss.geneland.burnin)
      # Output
      # Simulated number of populations
      Plotnpop(path.mcmc=hauss.geneland.path.mcmc, printit=TRUE,
        file=paste(hauss.geneland.path.mcmc, "/geneland-number_of_clusters
        .pdf", sep=""), format="pdf", burnin=hauss.geneland.burnin)
      dev.off() # We must close graphical device manually
      # Map of estimated population membership
      PosteriorMode(coordinates=hauss.geneland.coord.utm,
        path.mcmc=hauss.geneland.path.mcmc, printit=TRUE, format="pdf",
        file=paste(hauss.geneland.path.mcmc,"/geneland-map.pdf", sep=""))
      dev.off() # We must close graphical device manually
      } # End of FOR loop from previous slide
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Estimate F$_{ST}$}
	\begin{spluscode}
    # Prepare list to record values of Fst for all runs
    hauss.geneland.fstat <- list()
    # Estimate Fst
    for (hauss.geneland.irun in 1:hauss.geneland.nrun) {
      hauss.geneland.path.mcmc <- paste("geneland/",
      hauss.geneland.irun, "/", sep="")
      # F-statistics - Fis and Fst
      hauss.geneland.fstat[[hauss.geneland.irun]] <- Fstat.output(
        coordinates=hauss.geneland.coord.utm,
        genotypes=hauss.geneland.data,
        burnin=hauss.geneland.burnin, ploidy=2,
        path.mcmc=hauss.geneland.path.mcmc)
      }
      # Print Fst output
      hauss.geneland.fstat
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{MCMC inference under the admixture model}
	\begin{spluscode}
    for (hauss.geneland.irun in 1:hauss.geneland.nrun) {
      hauss.geneland.path.mcmc <- paste("geneland/",
        hauss.geneland.irun, "/", sep="")
      hauss.geneland.path.mcmc.adm <- paste(hauss.geneland.path.mcmc,
        "admixture", "/", sep="")
      # On Windows, remove following line of code and create in each
      # result directory (from 1 to max K) new subdirectory "admixture"
      # (creating subdirs in Windows in R is complicated)
      system(paste("mkdir ", hauss.geneland.path.mcmc.adm))
      HZ(coordinates=hauss.geneland.coord.utm, geno.dip.codom=
        hauss.geneland.data, path.mcmc.noadm=hauss.geneland.path.mcmc,
        nit=10000, thinning=10,
        path.mcmc.adm=hauss.geneland.path.mcmc.adm)
      }
	\end{spluscode}
	\begin{itemize}
		\item Currently, there is no much use for admixture results, at lest not without extra work\ldots
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Produce maps of respective inferred clusters}
	\begin{spluscode}
    for (hauss.geneland.irun in 1:hauss.geneland.nrun) {
      hauss.geneland.path.mcmc <- paste("geneland/",
        hauss.geneland.irun, "/", sep="")
      # Maps - tessellations
      PlotTessellation(coordinates=hauss.geneland.coord.utm,
        path.mcmc=hauss.geneland.path.mcmc, printit=TRUE,
        path=hauss.geneland.path.mcmc)
      for (hauss.geneland.irun.img in 1:hauss.geneland.maxpop) {
        dev.off() } # We must close graphical device manually
      }
	\end{spluscode}
	\begin{itemize}
		\item Maps are produced as PS (PostScript) files in output directories
		\item Not every graphical software can handle PS (try for example \href{https://www.gimp.org/}{GIMP})
		\item There are as many plots as was maximal K, but only those up to inferred number of clusters have some content (the others are empty)
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Estimate frequencies of null alleles}
	\begin{spluscode}
    hauss.geneland.fna <- list()
    for (hauss.geneland.irun in 1:hauss.geneland.nrun) {
      hauss.geneland.path.mcmc <- paste("geneland/", hauss.geneland.irun,
        "/", sep="")
      # Estimation
      hauss.geneland.fna[[hauss.geneland.irun]] <-
        EstimateFreqNA(path.mcmc=hauss.geneland.path.mcmc)
      }
    # See output
    hauss.geneland.fna
	\end{spluscode}
	\begin{itemize}
		\item Each item of the \texttt{list} object \texttt{hauss.geneland.fna} (from 1~to number of runs) contains vector of estimated frequencies of null alleles for every locus
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Determine which run is the best}
	\begin{spluscode}
    # Calculate average posterior probability
    hauss.geneland.lpd <- rep(NA, hauss.geneland.nrun)
    for (hauss.geneland.irun in 1:hauss.geneland.nrun) {
      hauss.geneland.path.mcmc <- paste("geneland/", hauss.geneland.irun, "/",
        sep="")
      hauss.geneland.path.lpd <- paste(hauss.geneland.path.mcmc,
        "log.posterior.density.txt", sep="")
      hauss.geneland.lpd[hauss.geneland.irun] <-
        mean(scan(hauss.geneland.path.lpd)[-(1:hauss.geneland.burnin)]) }
    order(hauss.geneland.lpd, decreasing=TRUE) # Sorts runs according to decre-
    [1] 5 1 4 3 2 # Run 5 is the best here     # asing posterior probability
    hauss.geneland.lpd # Here the runs are unsorted
    [1] -645.0238 -782.7912 -676.9559 -664.9947 -601.7902 # Run 5 wins
	\end{spluscode}
	\begin{itemize}
		\item We will use figures and F$_{ST}$ outputs only from the best run
		\item It is useful to keep all runs especially for comparison if there are different solutions with similar posterior probability
	\end{itemize}
\end{frame}

\begin{frame}{MCMC chain, number of clusters and their map}{MCMC did not converge yet --- too few generations, the most likely solution is K=4 followed by K=5. Final product is map of distribution of genetic clusters.}
	\begin{center}
		\includegraphics[width=\textwidth-4cm]{geneland1.png}
	\end{center}
\end{frame}

\begin{frame}{Map of posterior probability of belonging into cluster 1}
	\begin{center}
		\includegraphics[width=\textwidth-6cm]{geneland2.png}
	\end{center}
\end{frame}

\begin{frame}{When using Geneland, remember\ldots}
	\begin{itemize}
		\item Within \texttt{MCMC()}, there must be at least hundreds thousands or millions of generations (\texttt{nit}) and appropriate sampling (thousands or higher, \texttt{thinning} --- not to fill whole disk)
		\item To analyze geo-referenced data with a~non-spatial prior set in \texttt{MCMC()} \texttt{spatial=FALSE}
		\item To analyze non-spatial data remove parameter \texttt{coordinates} from \texttt{MCMC()} function
		\item To obtain structure-like plots, file \texttt{proba.pop.membership.indiv.txt} in Geneland output directory can be used as input file for \href{https://web.stanford.edu/group/rosenberglab/distruct.html}{distruct}
		\item To use SNPs, ATCG bases must be recoded as \texttt{1, 2, 3, 4}, fixed alleles must be removed
		\item Geneland can handle only haploids and diploids (no ploidy mixing)
		\item When unsure, consult \href{https://i-pri.org/special/Biostatistics/Software/Geneland/Geneland-Doc.pdf}{manual}
	\end{itemize}
\end{frame}

\subsection{Plotting maps}

\begin{frame}[fragile]{Very basic mapping in R}
	\begin{spluscode}
    library(sp) # Load libraries
    library(rworldmap) # Basic world maps
    library(TeachingDemos) # To be able to move text little bit
    library(RgoogleMaps) # Google and OpenStreetMaps
    library(mapplots) # Plot pie charts
    # Plot basic map with state boundaries within selected range
    plot(x=getMap(resolution="high"), xlim=c(19, 24), ylim=c(39, 44), asp=1,
      lwd=1.5)
    box() # Add frame around the map
    # Plot location points
    points(x=hauss.genpop@other$xy[["lon"]], y=hauss.genpop@other$xy [["lat"]],
      pch=15:19, col="red", cex=4)
    # Add text descriptions for points. Text is aside and with background
    shadowtext(x=hauss.genpop@other$xy[["lon"]], y=hauss.genpop@other$xy
      [["lat"]], labels=as.vector(popNames(hauss.genind)), col="black", bg=
      "white", theta=seq(pi/4, 2*pi, length.out=8), r=0.15, pos=c(1, 3, 2, 4,
      4), offset=0.75, cex=1.5)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Basic map}
	\begin{spluscode}
    # Insert legend
    legend(x="topright", inset=1/50, legend=c("He", "Oh", "Pr", "Ne", "Sk"),
      col="red", border="black", pch=15:19, pt.cex=2, bty="o", bg="lightgrey",
      box.lwd=1.5, cex=1.5, title="Populations")
	\end{spluscode}
	\begin{center}
		\includegraphics[height=4.5cm]{map.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Google map}
	\begin{multicols}{2}
		\begin{spluscode}
    # Google map is produced into a
    # file. Parameter markers contain
    # data frame with coordinates and
    # possibly with more information
    hauss.gmap <- GetMap(center=c(lat=
      41, lon=21), size=c(640, 640),
      destfile="gmap.png", zoom=8,
      markers=hauss.coord, maptype=
      "terrain", API_console_key="XXX")
    # Plot the map
    PlotOnStaticMap(MyMap=hauss.gmap)
		\end{spluscode}
		\begin{itemize}
			\item Google recently started to require \href{https://developers.google.com/maps/documentation/maps-static/intro}{API key}, it doesn't work without it\ldots
			\item See \href{http://rgooglemaps.r-forge.r-project.org/}{documentation} and more options, it can use plenty of map resources (Bing maps,~\ldots)
			\item Many on-line map services do require (paid) API key\ldots
		\end{itemize}
		\begin{center}
			\includegraphics[height=4.5cm]{gmap1.jpg}
		\end{center}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{More options for Google map}
	\begin{multicols}{2}
		\begin{spluscode}
    hauss.gmap2 <- GetMap(center=c(
      lat=41, lon=21), size=c(640,
      640), destfile="gmap2.png",
      zoom=8, maptype="satellite",
      API_console_key="XXX")
    PlotOnStaticMap(MyMap=hauss.gmap2,
      lat=hauss.genpop@other$xy[["lat"
      ]], lon=hauss.genpop@other$xy
      [["lon"]], FUN=points, pch=19,
      col="blue", cex=5)
    PlotOnStaticMap(MyMap=hauss.gmap2,
      lat=hauss.genpop@other$xy[["lat"
      ]], lon=hauss.genpop@other$xy
      [["lon"]], add=TRUE, FUN=points,
      pch=19, col="red", cex=3)
    PlotOnStaticMap(MyMap=hauss.gmap2,
      lat=hauss.genpop@other$xy[["lat"
      ]], lon=hauss.genpop@other$xy
		\end{spluscode}
		\begin{spluscode}
      [["lon"]], add=TRUE, FUN=text,
      labels=as.vector(popNames(
      hauss.genind)), pos=4, cex=3,
      col="white")
    # Google maps have their own
    # internal scaling, adding of
    # points by standard functions
    # will not work correctly
		\end{spluscode}
		\begin{center}
			\includegraphics[height=3.5cm]{gmap2.jpg}
		\end{center}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Adding pie charts to map I}
	\begin{spluscode}
    # Prepare matrix with some data (exemplary distribution of haplotypes)
    hauss.pie <- cbind(c(20, 30, 15, 40, 10), c(30, 10, 25, 5, 45),
      c(10, 20, 20, 15, 5))
    # Add row names according to populations
    rownames(hauss.pie) <- popNames(hauss.genpop)
    # Add column names according to data displayed
    colnames(hauss.pie) <- c("HapA", "HapB", "HapC")
    class(hauss.pie) # Check it is matrix
    hauss.pie # See resulting matrix
    # Plot basic map with state boundaries within selected range
    plot(x=getMap(resolution="high"),xlim=c(20,23),ylim=c(41,42),asp=1,lwd=1.5)
    box() # Add frame around the map
    # Plot the pie charts
    for (L in 1:5) { add.pie(z=hauss.pie[L,], x=as.vector(hauss.genpop@other
      $xy[["lon"]])[L], y=as.vector(hauss.genpop@other$xy[["lat"]])[L],
      labels=names(hauss.pie[L,]), radius=0.1, col=topo.colors(3)) }
    ?add.pie # See more options
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Adding pie charts to map II}
	\begin{spluscode}
    # Add population labels
    text(x=hauss.genpop@other$xy[["lon"]], y=hauss.genpop@other$xy[["lat"]],
      labels=as.vector(popNames(hauss.genind)), col="red", cex=2)
	\end{spluscode}
	\begin{center}
		\includegraphics[height=5cm]{map_pie.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Pie charts on Google map I}
	\begin{spluscode}
    # Prepare list to store recalculated coordinates
    hauss.gmap2.coord <- list()
    # Calculation of coordinates to form required by Google Maps
    for (LC in 1:5) { hauss.gmap2.coord[[LC]] <- LatLon2XY.centered(MyMap=
      hauss.gmap2, lat=as.vector(hauss.genpop@other$xy[["lat"]])[LC],
      lon=as.vector(hauss.genpop@other$xy[["lon"]])[LC], zoom=8) }
    hauss.gmap2.coord # See result
    # Plot plain map
    PlotOnStaticMap(MyMap=hauss.gmap2)
    # Plot pie charts
    for (LP in 1:5) { add.pie(z=hauss.pie[LP,], x=hauss.gmap2.coord[[LP]]
      $newX, y=hauss.gmap2.coord[[LP]]$newY, labels=names(hauss.pie[LP,]),
      radius=25, col=topo.colors(n=3, alpha=0.7)) }
    # Alternative option to plot pie charts
    for (LF in 1:5) { plotrix::floating.pie(xpos=hauss.gmap2.coord[[LF]]
      $newX, ypos=hauss.gmap2.coord[[LF]]$newY, x=hauss.pie[LF,], radius=30,
      col=heat.colors(n=3, alpha=0.5) ) }
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Pie charts on Google map II}
	\begin{spluscode}
    # Add population text labels
    PlotOnStaticMap(MyMap=hauss.gmap2, lat=hauss.genpop@other$xy[["lat"]],
      lon=hauss.genpop@other$xy[["lon"]], add=TRUE, FUN=text,
      labels=as.vector(popNames(hauss.genind)), cex=2.5, col="white")
	\end{spluscode}
	\begin{center}
		\includegraphics[height=4.5cm]{map_pie_google.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Datasets from mapproj}
	\begin{spluscode}
    # Plot on data sets from mapproj package
    library(maps) # Various mapping tools (plotting, ...)
    # More detailed maps, but political boundaries often outdated, see
    # https://CRAN.R-project.org/package=mapdata
    library(mapdata)
    library(mapproj)
    # Convert latitude/longitude into projected coordinates
    # Plot a map, check parameters
    # Check among others "projection" and ?mapproject for its details
    map(database="worldHires", boundary=TRUE, interior=TRUE, fill=TRUE,
      col="lightgrey", plot=TRUE, xlim=c(16, 27), ylim=c(37, 46))
    # If you'd use projection, use mapproject to convert also coordinates!
    ?mapproject # See for details
    points(x=hauss.genpop@other$xy[["lon"]], y=hauss.genpop@other$xy[["lat"]],
      pch=15:19, col="red", cex=3)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Plotting on SHP files I}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Shapefile}{Shapefile} (SHP) is common format for geographical data
		\item Get SHP files from \url{https://soubory.trapa.cz/rcourse/macedonia.zip} and unpack them into R working directory
		\item Data were originally downloaded from \url{https://download.geofabrik.de/europe/macedonia.html}
		\item R working directory has to contain also respective DBF and SHX files (same name, only different suffix)
	\end{itemize}
	\begin{spluscode}
    library(maptools)
    dir() # Verify required files are unpacked in the working directory
    # There are several functions readShape* - select appropriate
    # according to data stored in respective SHP file
    # Check correct import by plotting all layers
    macedonia_building <- readShapeLines(fn="macedonia_buildings.shp")
    plot(macedonia_building) # Continues on next slide...
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Plotting on SHP files II}
	\begin{spluscode}
    macedonia_landuse <- readShapeLines(fn="macedonia_landuse.shp")
    plot(macedonia_landuse)
    macedonia_natural <- readShapeLines(fn="macedonia_natural.shp")
    plot(macedonia_natural)
    macedonia_railways <- readShapeLines(fn="macedonia_railways.shp")
    plot(macedonia_railways)
    macedonia_roads <- readShapeLines(fn="macedonia_roads.shp")
    plot(macedonia_roads)
    macedonia_waterways <- readShapeLines(fn="macedonia_waterways.shp")
    plot(macedonia_waterways)
    # Plot all layers into single image, add more information
    plot(macedonia_building)
    plot(macedonia_landuse, add=TRUE, col="darkgreen", fill=TRUE)
    plot(macedonia_natural, add=TRUE, col="green", fill=TRUE)
    plot(macedonia_railways, add=TRUE, col="brown", lty="dotted")
    plot(macedonia_roads, add=TRUE, col="orange")
    plot(macedonia_waterways, add=TRUE, col="blue", lwd=2) # Ends on next slide
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Plotting on SHP files III}
	\begin{spluscode}
    # Add state boundaries
    plot(x=getMap(resolution="high"), xlim=c(19, 24), ylim=c(39, 44), asp=1,
      lwd=5, add=TRUE) # Or e.g.
    map(database="worldHires", boundary=TRUE, interior=TRUE, fill=FALSE,
      col="red", add=TRUE, plot=TRUE, xlim=c(16, 27), ylim=c(37, 46), lwd=5)
    # Add sampling points
    points(x=hauss.genpop@other$xy[["lon"]], y=hauss.genpop@other$
      xy[["lat"]], pch=15:19, col="red", cex=4)
    # Add description of sampling points
    shadowtext(x=hauss.genpop@other$xy[["lon"]], y=hauss.genpop@other$
      xy[["lat"]], labels=as.vector(popNames(hauss.genind)), col="black",
      bg="white", theta=seq(pi/4, 2*pi, length.out=8), r=0.15,
      pos=c(1, 3, 2, 4, 4), offset=0.75, cex=1.5)
    # Add legend
    legend(x="topright", inset=1/50, legend=c("He", "Oh", "Pr", "Ne", "Sk"),
      col="red", border="black", pch=15:19, pt.cex=2, bty="o", bg="lightgrey",
      box.lwd=1.5, cex=1.5, title="Populations")
	\end{spluscode}
\end{frame}

\begin{frame}{Plotting on SHP files IV and maps from mapproj}
	\begin{center}
		\includegraphics[width=\textwidth-2cm]{mapy.png}
	\end{center}
\end{frame}

\section{Trees}

\begin{frame}{Manipulation, display and analysis of sets of trees}{Work with individual trees and sets of trees, finding species trees from multiple gene trees}
	\tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
\end{frame}

\subsection{Manipulations}

\begin{frame}[fragile]{Read and write tree and drop tips}
	\begin{spluscode}
    # Read trees in NEWICK format - single or multiple tree(s)
    oxalis.trees<-read.tree(file="https://soubory.trapa.cz/rcourse/oxalis.nwk")
    summary(oxalis.trees)
    length(oxalis.trees)
    names(oxalis.trees)
    # Export trees in NEWICK format
    write.tree(phy=oxalis.trees, file="trees.nwk")
    oxalis.trees[[1]][["tip.label"]] # See tip labels
    # Drop a tip from multiPhylo
    plot.multiPhylo(x=oxalis.trees)
    oxalis.trees.drop<-lapply(X=oxalis.trees,FUN=drop.tip,tip="O._callosa_S15")
    class(oxalis.trees.drop) <- "multiPhylo"
    plot.multiPhylo(x=oxalis.trees.drop)
    plot.phylo(hauss.nj) # Drop a tip from single tree
    hauss.nj[["tip.label"]] # See tip labels (and numbers)
    hauss.nj.drop <- drop.tip(phy=hauss.nj, tip=47)
    plot.phylo(hauss.nj.drop)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Extract clades from trees and drop extinct tips}
	\begin{spluscode}
    # Interactively extract tree
    plot.phylo(hauss.nj) # Plot source tree
    nodelabels() # See node labels (numbers) - needed for some tasks
    # Select clade to extract by clicking on it
    hauss.nj.extracted <- extract.clade(phy=hauss.nj, interactive=TRUE)
    # See new extracted tree
    plot.phylo(hauss.nj.extracted)
    # Non-interactively extract tree
    hauss.nj.extracted <- extract.clade(phy=hauss.nj,node=60,interactive=FALSE)
    # See new extracted tree
    plot.phylo(hauss.nj.extracted)
    # Drop "extinct" tips - those who don't reach end the tree tolerance is
    # respective to the used metrics
    plot.phylo(hauss.nj)
    axisPhylo()
    hauss.nj.fossil <- drop.fossil(phy=hauss.nj, tol=0.4)
    plot.phylo(hauss.nj.fossil)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Join two trees, rotate tree}
	\begin{spluscode}
    # Bind two trees into one
    hauss.nj.bind <- bind.tree(x=hauss.nj.fossil, y=hauss.nj.extracted,
      where="root", position=0, interactive=FALSE)
    plot.phylo(hauss.nj.bind)
    # Bind two trees interactively
    # Plot tree receiving the new one
    plot.phylo(hauss.nj.fossil)
    # Select where to bind new tree to
    hauss.nj.bind <- bind.tree(x=hauss.nj.fossil, y=hauss.nj.extracted,
      interactive=TRUE)
    plot.phylo(hauss.nj.bind)
    # Rotate tree
    # plot.phylo plots tree in exact order as it is in the phylo object
    plot.phylo(hauss.nj)
    nodelabels()
    hauss.nj.rotated <- rotate(phy=hauss.nj, node="70")
    plot.phylo(hauss.nj.rotated)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Ladderize and (un)root the tree}
	\begin{spluscode}
    plot.phylo(hauss.nj) # Ladderize the tree
    hauss.nj.ladderized <- ladderize(hauss.nj)
    plot.phylo(hauss.nj.ladderized)
    # Root the tree
    plot.phylo(hauss.nj)
    print.phylo(hauss.nj)
    # resolve.root=TRUE ensures root will be bifurcating (needed here)
    # (without this parameter it sometimes doesn't work)
    hauss.nj.rooted <- root.phylo(phy=hauss.nj, resolve.root=TRUE, outgroup=10)
    print.phylo(hauss.nj.rooted)
    plot.phylo(hauss.nj.rooted)
    # Root the tree interactive
    plot.phylo(hauss.nj)
    hauss.nj.rooted <- root.phylo(phy=hauss.nj, interactive=TRUE)
    plot.phylo(hauss.nj.rooted)
    unroot.phylo() # Unroot the tree
    is.rooted() # Check if it is rooted
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Check tree and compute branch lengths and times}
	\begin{spluscode}
    # Check if the tree is ultrametric - is variance of distances of all tips
    # to node 0? It is required for some analysis
    is.ultrametric()
    # Make tree ultrametric
    ?chronos # Check it for mode how to calculate the lengths
    # chronos has more uses - it is mainly used for dating
    # Compute branch lengths for trees without branch lengths
    ?compute.brlen # Check it for mode how to calculate the lengths
    # Computes the branch lengths of a tree giving its branching
    # times (aka node ages or heights)
    ?compute.brtime # Check it for mode how to calculate the lengths
	\end{spluscode}
	\begin{itemize}
		\item Class \texttt{multiPhylo} is just a~\texttt{list} of \texttt{phylo} objects to store multiple trees --- you can perform most of analysis on it as on \texttt{phylo}, commonly using \texttt{lapply} (afterward use \texttt{class(x) <- "multiPhylo"})
	\end{itemize}
\end{frame}

\subsection{MP}

\begin{frame}{Maximum parsimony --- theory}
	\label{MP}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Maximum_parsimony_(phylogenetics)}{Maximum parsimony} finds optimal topology of the phylogenetic tree by minimizing of the total number of character-state changes
		\item It minimizes homoplasy (convergent evolution, parallel evolution, evolutionary reversals)
		\item Very simple criterion, easy to score the tree, but not to find it --- exhaustive search to explore all possible trees is realistic until $\sim$9 taxa, branch-and-bound swapping (guaranteeing finding the best tree) until $\sim$20 taxa, for more heuristic search is needed --- it doesn't always guarantee to find the most probable tree
		\item To speed up calculations, initial tree (usually NJ --- slide~\ref{NJ}) is used to start the search
		\item With rising performance of computers, it uses to be replaced maximum likelihood or Bayesian methods
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Maximum parsimony --- code and result}
	\begin{multicols}{2}
		\vfil
		\includegraphics[height=6.75cm]{parsimony.png}
		\vfil
		\begin{spluscode}
    # Conversion to phyDat
    meles.phydat<-as.phyDat(meles.dna)
    # Prepare starting tree
    meles.tre.ini <- nj(dist.dna
      (x=meles.dna, model="raw"))
    # Maximum parsimony score
    ?parsimony # Parsimony details
    parsimony(tree=meles.tre.ini,
      data=meles.phydat)
    # Optimization
    # Maximum parsimony tree
    meles.tre.pars <- optim.parsimony
      (tree=meles.tre.ini,
      data=meles.phydat)
    # Draw a tree
    plot.phylo(x=meles.tre.pars,
      type="clad", edge.width=2)
		\end{spluscode}
	\end{multicols}
\end{frame}

\subsection{Seeing trees in the forest}

\begin{frame}[allowframebreaks]{Topographical distances among trees I --- implementations}
	\begin{itemize}
		\item Robinsons-Foulds distance in \texttt{phytools::multiRF}
		\begin{itemize}
			\item The index adds 1~for each difference between pair of trees
			\item Well defined only for fully bifurcating trees --- if not fulfilled, some results might be misleading
			\item Allow comparison of trees created by different methods
			\item If the difference is very close to root, RF value can be large, even there are not much differences in the tree at all --- \texttt{dist.multiPhylo} from package \href{https://CRAN.R-project.org/package=distory}{distory} can be an alternative, although interpretation of that geodesic distance is sometimes not so straightforward as simple logic of RF
		\end{itemize}
		\item Methods implemented in \texttt{ape::dist.topo} allow comparison of trees with polytomies (\texttt{method="PH85"}) or use of squared lengths of internal branches (\texttt{method="score"})
		\item Final matrices are commonly not \href{https://en.wikipedia.org/wiki/Euclidean_distance_matrix}{Euclidean} --- may be problematic for usage in methods like PCA
		\begin{itemize}
			\item Test it with \texttt{ade4::is.euclid}, can be scaled (forced to became Euclidean) by functions like \texttt{quasieuclid} or \texttt{cailliez} in \texttt{ade4} --- carefully, it can damage meaning of the data
			\item We get matrix of pairwise differences among trees (from multiple genes), we need display and analyze it
		\end{itemize}
		\item Set of tools for identifying discordant phylogenetic trees are e.g. in package \href{https://CRAN.R-project.org/package=kdetrees}{kdetrees}
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Topographical distances among trees II}{We have plenty of trees. How much are their topologies different?}
	\begin{spluscode}
    library(gplots)
    library(corrplot)
    library(phytools)
    # Compute matrix of topological distances among phylogenetic trees
    ?dist.topo # See details of available computing methods
    oxalis.trees.d <- dist.topo(x=oxalis.trees, method="score")
    # Basic information about the distance matrix
    dim(as.matrix(oxalis.trees.d))
    head.matrix(as.matrix(oxalis.trees.d))
	\end{spluscode}
	\begin{itemize}
		\item There are more options how to display the differences and identify (and possibly exclude) outlying trees --- heatmap, PCoA, hierarchical clustering (e.g. package \href{https://CRAN.R-project.org/package=dbscan}{dbscan}),~\ldots
		\item Sources of incongruencies among trees: low-quality DNA/laboratory mistake, problem with alignment/gene tree reconstruction, gene duplication and \href{https://en.wikipedia.org/wiki/Sequence_homology}{paralogy} (e.g. in polyploids), \href{https://en.wikipedia.org/wiki/Incomplete_lineage_sorting}{ILS}, \href{https://en.wikipedia.org/wiki/Horizontal_gene_transfer}{HGT},~\ldots{ } --- such problems must be inspected
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Topographical distances among trees III}{Post process the matrix and plot it}
	\begin{itemize}
		\item There are several methods for calculating distance matrices among the trees --- some take branch lengths into account, some only topology
		\item There are plenty of heatmap functions, like \texttt{heatmap}, \texttt{heatmap.plus::heatmap.plus}, and more\ldots
	\end{itemize}
	\begin{spluscode}
    # Create heat maps using heatmap.2 function from gplots package
    heatmap.2(x=as.matrix(x=oxalis.trees.d), Rowv=FALSE, Colv="Rowv",
      dendrogram="none", symm=TRUE, scale="none", na.rm=TRUE, revC=FALSE,
      col=rainbow(15), cellnote=round(x=as.matrix(x=oxalis.trees.d), digits=2),
      notecex=1, notecol="white", trace="row", linecol="black",
      labRow=names(oxalis.trees), labCol=names(oxalis.trees), key=TRUE,
      keysize=2, density.info="density", symkey=FALSE, main="Correlation
      matrix of topographical distances", xlab="Trees", ylab="Trees")
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Topographical distances among trees IV}{Calculate Robinsons-Foulds distance matrix among trees and plot it}
	\begin{itemize}
		\item \texttt{phytools::multiRF} can handle \texttt{multiPhylo} objects and directly create matrices (no need to create loops)
	\end{itemize}
	\begin{spluscode}
    # Robinsons-Foulds distance
    oxalis.trees.d.rf <- multiRF(oxalis.trees)
    # Add names of columns and rows
    colnames(oxalis.trees.d.rf) <- names(oxalis.trees)
    rownames(oxalis.trees.d.rf) <- names(oxalis.trees)
    # Create heatmap using corrplot function from corrplot package
    corrplot(corr=oxalis.trees.d.rf, method="circle", type="upper",
      col=rainbow(15), title="Correlation matrix of topographical
      distances", is.corr=FALSE, diag=FALSE, outline=TRUE,
      order="alphabet", tl.pos="lt", tl.col="black")
    corrplot(corr=oxalis.trees.d.rf, method="number", type="lower",
      add=TRUE, col=rainbow(15), title="Correlation matrix of
      topographical distances", is.corr=FALSE, diag=FALSE,
      outline=FALSE, order="alphabet", tl.pos="ld", cl.pos="n")
	\end{spluscode}
\end{frame}

\begin{frame}{Topographical distances among trees V~--- the matrices}
	\includegraphics[width=\textwidth]{oxalis-dist.png}
\end{frame}

\begin{frame}[fragile]{PCoA from distance matrices of topographical differences among trees --- the code}{PC plots help to identify outliers --- trees with noticeably different topology}
	\begin{spluscode}
    # Test if the distance matrix is Euclidean or not
    is.euclid(distmat=oxalis.trees.d, plot=TRUE)
    [1] TRUE # If FALSE, we can use e.g. quasieuclid() to make it Euclidean
    # Calculate the PCoA
    oxalis.trees.pcoa <- dudi.pco(d=oxalis.trees.d, scannf=TRUE, full=TRUE)
    # Plot PCoA and add kernel densities
    s.label(dfxy=oxalis.trees.pcoa$li)
    s.kde2d(dfxy=oxalis.trees.pcoa$li, cpoint=0, add.plot=TRUE)
    # Add histogram of eigenvalues
    add.scatter.eig(oxalis.trees.pcoa[["eig"]], 3,1,2, posi="topleft")
    # Add title to the plot
    title("PCoA of matrix of pairwise trees distances")
    scatter(x=oxalis.trees.pcoa, posieig="topleft") # Alternative plotting PCA
	\end{spluscode}
\end{frame}

\begin{frame}{PCoA from distance matrices of topographical differences among trees --- the plot}
	\begin{center}
		\includegraphics[width=\textwidth-3.5cm]{pcoa-trees.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Consensus tree}
	\begin{multicols}{2}
		\begin{center}
			\includegraphics[height=5.75cm]{oxalis-cons.png}
		\end{center}
		\begin{spluscode}
    # Root all trees
    oxalis.trees.rooted <-
      root.multiPhylo(phy=oxalis.trees,
      outgroup="O._fibrosa_S159",
      resolve.root=TRUE)
    # Consensus tree (50 % rule)
    oxalis.tree.con <- consensus
      (oxalis.trees.rooted, p=0.5,
      check.labels=TRUE)
    print.phylo(oxalis.tree.con)
    # Plot the tree
    plot.phylo(oxalis.tree.con,
      edge.width=2, label.offset=0.3)
    axisPhylo(side=1)
    # What a nice tree... :-P
		\end{spluscode}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{kdetrees --- identification of outlying trees I}
	\begin{itemize}
		\item Distance-based method of identification of trees with significantly different topology
		\item Function \texttt{kdetrees} has plenty of options\ldots
		\item Parameter \texttt{k} sets threshold for trees to be removed --- it requires repeated running with different \texttt{k} (and plotting the figures) to decide which trees to remove and which to keep
	\end{itemize}
	\begin{spluscode}
    # Load library
    library(kdetrees)
    ?kdetrees # See options
    # Run main function - play with parameter k
    oxalis.kde <- kdetrees(trees=oxalis.trees, k=0.4, distance="dissimilarity",
      topo.only=FALSE, greedy=TRUE)
    # See results
    oxalis.kde
    plot(oxalis.kde)
    hist(oxalis.kde)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{kdetrees --- identification of outlying trees II}
	\begin{spluscode}
    # See removed trees
    plot.multiPhylo(oxalis.kde[["outliers"]])
    # Save removed trees
    write.tree(phy=oxalis.kde[["outliers"]], file="oxalis_trees_outliers.nwk")
    # Save kdetrees report
    write.table(x=as.data.frame(x=oxalis.kde), file="oxalis_trees_scores.tsv",
      quote=FALSE, sep="\t")
    # Extract passing trees
    oxalis.trees.good <- oxalis.trees[names(oxalis.trees) %in%
      names(oxalis.kde[["outliers"]]) == FALSE]
    oxalis.trees.good
    # Save passing trees
    write.tree(phy=oxalis.trees.good, file="trees_good.nwk")
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Species tree --- all trees must be ultrametric}
	\begin{multicols}{2}
		\begin{center}
			\includegraphics[height=6.5cm]{oxalis-sp.png}
		\end{center}
		\begin{spluscode}
    # Chronos scale trees
    oxalis.trees.ultra <- lapply
      (X=oxalis.trees.rooted,
      FUN=chronos, model="correlated")
    class(oxalis.trees.ultra) <-
      "multiPhylo"
    # Mean distances
    oxalis.tree.sp.mean <- speciesTree
      (oxalis.trees.ultra, mean)
    # Plot the tree
    plot.phylo(oxalis.tree.sp.mean,
      edge.width=2, label.offset=0.01)
    edgelabels(text=round(oxalis.
      tree.sp.mean[["edge.length"]],
      digits=2), frame="none",
      col="red", bg="none")
    axisPhylo(side=1)
		\end{spluscode}
	\end{multicols}
	\end{frame}

\begin{frame}[fragile]{Parsimony super tree}
	\begin{multicols}{2}
		\begin{center}
			\includegraphics[height=6.5cm]{oxalis-pars.png}
		\end{center}
		\begin{spluscode}
    library(phytools)
    oxalis.tree.sp <- mrp.supertree
      (tree=oxalis.trees.rooted,
      method="optim.parsimony",
      rooted=TRUE)
    print.phylo(oxalis.tree.sp)
    plot.phylo(oxalis.tree.sp,
      edge.width=2, label.offset=0.01)
    axisPhylo(side=1)
    # Similar function
    ?phangorn::superTree
    # Coalescence model to handle
    # multiple individuals per species
    ?phangorn::coalSpeciesTree
		\end{spluscode}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Density tree I}
	\begin{spluscode}
    # Prepare list of trees to show
    hauss.nj.trees <- list(hauss.nj, hauss.nj.bruvo, hauss.nj.rooted)
    hauss.nj.trees <- lapply(X=hauss.nj.trees, FUN=compute.brlen)
    hauss.nj.trees <- lapply(X=hauss.nj.trees, FUN=chronos)
    class(hauss.nj.trees) <- "multiPhylo"
    # The trees should be (otherwise plotting works, but may be ugly)...
    is.rooted.multiPhylo(hauss.nj.trees) # rooted,
    is.ultrametric.multiPhylo(hauss.nj.trees) # ultrametric and
    is.binary.multiPhylo(hauss.nj.trees) # binary bifurcating.
    # Plotting has various options, play with it
    phangorn::densiTree(x=hauss.nj.trees, direction="downwards",
      scaleX=TRUE, col=rainbow(3), width=5, cex=1.5) # See next slide
    densiTree(x=hauss.nj.trees, direction="upwards", scaleX=TRUE, width=5)
    densiTree(x=hauss.nj.trees, scaleX=TRUE, width=5, cex=1.5)
    # Compare this option with similar on following slide
    ?phangorn::densiTree
    ?phytools::densityTree
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Density tree II}
	\includegraphics[width=\textwidth]{oxalis_density_phangorn.png}
\end{frame}

\begin{frame}[fragile]{Density tree III}
	\begin{spluscode}
    phytools::densityTree(trees=oxalis.trees.ultra, fix.depth=TRUE,
      use.gradient=TRUE, alpha=0.5, lwd=4) # Probably to much noise... :-?
    phytools::densityTree(trees=oxalis.trees.ultra[1:3], fix.depth=TRUE,
      use.gradient=TRUE, alpha=0.5, lwd=4) # Nice selection
    phytools::densityTree(trees=oxalis.trees.ultra[c(2,4,6,7)],
      fix.depth=TRUE, use.gradient=TRUE, alpha=0.5, lwd=4) # Nice selection
	\end{spluscode}
	\begin{center}
		\includegraphics[width=\textwidth-8cm]{oxalis_density_phytools.png}
	\end{center}
\end{frame}

% \begin{frame}[fragile]{Species trees from phybase} % TODO phybase
% 	\begin{itemize}
% 		\item Package \href{https://github.com/lliu1871/phybase}{phybase} (\href{https://academic.oup.com/bioinformatics/article/26/7/962/212978}{citation}) implements several methods of building of species tree ouf of list of gene trees (and some functions to manipulate trees, data, etc.) --- we try \href{http://online.liebertpub.com/doi/abs/10.1089/cmb.2012.0101}{STAR} and \href{https://academic.oup.com/sysbio/article/58/5/468/1635625}{STEAC}
% 	\end{itemize}
% 	\begin{spluscode}
%
% 	\end{spluscode}
% \end{frame}

\begin{frame}[fragile]{Kronoviz --- see all trees on same scale}
	\begin{multicols}{2}
		\includegraphics[height=6.5cm]{kronoviz.png}
		\begin{spluscode}
    kronoviz(x=oxalis.trees.rooted,
      layout=length(oxalis.trees.
      rooted), horiz=TRUE)
    # Close graphical device to
    # cancel division of plotting
    # device
    dev.off()
		\end{spluscode}
		\vfill
		\begin{itemize}
			\item The plot can be very long and it can be hard to see details
			\item But one can get impression if all trees are more or less in same scale (have comparable length) or not
		\end{itemize}
		\vfil
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Networks}
	\begin{spluscode}
    library(phangorn)
    oxalis.tree.net <- consensusNet(oxalis.trees.rooted, prob=0.25)
    plot(x=oxalis.tree.net, planar=FALSE, type="2D", use.edge.length=TRUE,
      show.tip.label=TRUE, show.edge.label=TRUE, show.node.label=TRUE,
      show.nodes=TRUE, edge.color="black", tip.color="blue") # 2D
    plot(x=oxalis.tree.net, planar=FALSE, type="3D", use.edge.length=TRUE,
      show.tip.label=TRUE, show.edge.label=TRUE, show.node.label=TRUE,
      show.nodes=TRUE, edge.color= "black", tip.color="blue") # 3D
	\end{spluscode}
	\begin{center}
		\includegraphics[height=2.5cm]{oxalis-net.png}
	\end{center}
\end{frame}

\subsection{Comparisons}

\begin{frame}[fragile]{Compare two trees}
	\begin{spluscode}
    # Compare topology of the species trees - basically outputs TRUE/FALSE
    all.equal.phylo(oxalis.tree.sp, oxalis.tree.sp.mean, use.edge.length=FALSE)
    ?all.equal.phylo # Use to see comparison possibilities
    # Plot two trees with connecting lines
    # We need 2 column matrix with tip labels
    tips.labels <- matrix(data=c(sort(oxalis.tree.sp[["tip.label"]]),
      sort(oxalis.tree.sp.mean[["tip.label"]])), nrow=length
      (oxalis.tree.sp[["tip.label"]]), ncol=2)
    # Draw a tree - play with graphical parameters and use rotate=TRUE
    # to be able to adjust fit manually
    cophyloplot(x=ladderize(oxalis.tree.sp), y=ladderize(oxalis.tree.sp.mean),
      assoc=tips.labels, use.edge.length=FALSE, space=60, length.line=1, gap=2,
      type="phylogram", rotate=TRUE, col="red", lwd=1.5, lty=2)
    title("Comparing the trees\nParsimony super tree\tSpecies tree")
    legend("topleft", legend="Red lines\nconnect tips", text.col="red",
      cex=0.75, bty="n", x.intersp=-2, y.intersp=-2)
	\end{spluscode}
\end{frame}

\begin{frame}{Cophyloplot comparing two trees}
	\begin{multicols}{2}
		\begin{center}
			\includegraphics[height=4.5cm]{cophyloplot.png}
		\end{center}
		\begin{itemize}
			\item \texttt{ladderize()} pre-sorts tips in the tree --- it can help to \texttt{cophyloplot()} to reduce crossings
			\item \texttt{cophyloplot()} has not any optimization to plot the lines
			\item Automatic plot is usually not perfect --- there use to be unneeded crossing lines --- \texttt{rotate=TRUE} is recommended to can fix this manually by clicking to the nodes
			\item \texttt{cophyloplot()} has similar parameters like \texttt{plot.phylo()} --- play with it and/or adjust in graphical editor
			\item Other options are in package \href{https://CRAN.R-project.org/package=dendextend}{dendextend}
		\end{itemize}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Alternative implementation --- phytools::cophylo}
	\begin{spluscode}
    ?cophylo # See options
    # Prepare the object for plotting
    oxalis.cophylo <- cophylo(tr1=oxalis.tree.sp, tr2=oxalis.tree.sp.mean,
      assoc=(cbind(sort(oxalis.tree.sp$tip.label),
      sort(oxalis.tree.sp$tip.label))), rotate=TRUE)
    plot.cophylo(x=oxalis.cophylo, lwd=2, link.type="curved") # Plot it
    title("Comparison of species tree (left) and parsimony supertree (right)")
	\end{spluscode}
	\begin{center}
		\includegraphics[height=3.25cm]{cophylo.png}
	\end{center}
\end{frame}

\subsection{Notes about plotting the trees}

\begin{frame}[fragile]{Change orientation of plots}
	\begin{itemize}
		\item \alert{\texttt{plot.phylo()} has plenty of possibilities to influence --- check \texttt{?plot.phylo}, \texttt{?par}, \texttt{?points},~\ldots}
	\end{itemize}
	\begin{spluscode}
    ?plot.phylo # check it for various possibilities what to influence
    par(mfrow=c(1, 2)) # Plot two plots in one row
    plot.phylo(x=hauss.nj, type="cladogram", use.edge.length=FALSE,
      direction="rightwards")
    plot.phylo(x=hauss.nj, type="cladogram", use.edge.length=FALSE,
      direction="leftwards")
    dev.off() # Close graphical device to cancel par() settings
	\end{spluscode}
	\begin{center}
		\includegraphics[height=2.25cm]{lr.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Highlighted labels}
	\begin{multicols}{2}
		\vfill
		\begin{center}
			\includegraphics[height=6.5cm]{highlight.png}
		\end{center}
		\vfill
		\begin{spluscode}
    # Load tree in text format
    trape <- read.tree(text=
      "((Homo, Pan), Gorilla);")
    # Plot the tree
    plot.phylo(x=trape,
      show.tip.label=FALSE)
    # Add colored tip labels
    tiplabels(trape[["tip.label"]],
      bg=c("white", "black",
      "white"), col=c("black",
      "white", "black"), cex=2)
    # Add colored node labels
    nodelabels(text=c("6.4 Ma",
      "5.4 Ma"), frame="circle",
      bg="yellow")
    add.scale.bar() # Add scale bar
    # Note vectors for tip/nodelabels
		\end{spluscode}
	\end{multicols}
\end{frame}

\section{Evolution}

\begin{frame}{Reconstruction of evolution of traits}
	\tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
\end{frame}

\begin{frame}[allowframebreaks]{Overview of methods of reconstruction of evolution of traits}
	\begin{itemize}
		\item Testing if there is correlation between evolution of two or more characters (if they evolve together)
		\item Testing if there is correlation between one character and phylogenetic history (if trait changes follow evolution)
		\item Reconstruction of ancestral states of character
		\item For some methods, taxonomic level can be taken into account (if there is significant evolutionary signal on the trait evolution on e.g. level of genus or family)
		\item Generally available for continuous as well as discrete characters (not in all methods)
		\item Some methods can handle more observations per accession
		\item There are various methods how to display everything
		\item Methods and models are highly debated in the literature
		\begin{itemize}
			\item Different experts commonly disagree what is the best method\ldots
			\item General methods are not usable everywhere (e.g. evolution of genome size must take into account polyploidization --- \href{https://www.tau.ac.il/~itaymay/cp/chromEvol/}{chromEvol})
			\item Usage is better to be consulted with some relevant expert
			\item This is very difficult chapter by meaning of how to find the best method to analyze particular data\ldots
		\end{itemize}
		\item Always read manual and original papers explaining the methods
	\end{itemize}
\end{frame}

\subsection{PIC}

\begin{frame}[fragile]{Phylogenetic independent contrast}
	\begin{itemize}
		\item When analyzing comparative data takes phylogeny into account
		\item If we assume that a~continuous trait evolves randomly in any direction (i.e. the \href{https://en.wikipedia.org/wiki/Brownian_motion}{Brownian motion} model), then the \enquote{\href{https://en.wikipedia.org/wiki/Contrast_(statistics)}{contrast}} between two species is expected to have a~normal distribution with mean zero, and variance proportional to the time since divergence
	\end{itemize}
	\begin{spluscode}
    # Prepare the data # Body mass of primates
    primates.body <- c(4.09434, 3.61092, 2.37024, 2.02815, 1.46968)
    # Longevity of primates
    primates.longevity <- c(4.74493, 3.3322, 3.3673, 2.89037, 2.30259)
    # Add names to the values
    names(primates.body) <- names(primates.longevity) <- c("Homo", "Pongo",
      "Macaca", "Ateles", "Galago")
    # Create a tree in Newick format
    primates.tree <- read.tree(text="((((Homo:0.21, Pongo:0.21):0.28,
      Macaca:0.49):0.13, Ateles:0.62):0.38, Galago:1.00);")
    plot.phylo(primates.tree)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{PIC and its plotting}
	\begin{spluscode}
    primates.pic.body <- pic(x=primates.body, phy=primates.tree,
      scaled=TRUE, var.contrasts=FALSE, rescaled.tree=FALSE)
    primates.pic.longevity <- pic(x=primates.longevity, phy=primates.tree,
      scaled=TRUE, var.contrasts=FALSE, rescaled.tree=FALSE)
    # Plot a tree with PIC values
    plot.phylo(x=primates.tree, edge.width=2, cex=1.5)
    nodelabels(round(primates.pic.body, digits=3), adj=c(0, -0.5),
      frame="none")
    nodelabels(round(primates.pic.longevity, digits=3), adj=c(0, 1),
      frame="none")
    add.scale.bar()
    # Plot PIC
    plot(x=primates.pic.body, y=primates.pic.longevity, pch=16, cex=1.5)
    abline(a=0, b=1, lty=2) # x=y line
    # Correlation coefficient of both PICs
    cor(x=primates.pic.body, y=primates.pic.longevity, method="pearson")
    [1] -0.5179156
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Plot of PIC (on the tree)}
	\begin{spluscode}
    # Testing if there is positive correlation
    cor.test(x=primates.pic.body, y=primates.pic.longevity,
      alternative="greater", method="pearson")
	\end{spluscode}
	\begin{center}
		\includegraphics[width=\textwidth-5cm]{pic.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Test it}
	\label{pic-test}
	\begin{spluscode}
    lm(formula=primates.pic.longevity~primates.pic.body)
    Coefficients:
      (Intercept)  primates.pic.body
           1.6957            -0.3081
    # Because PICs have expected mean zero - such linear regressions
    # should be done through the origin (the intercept is set to zero)
    lm(formula=primates.pic.longevity~primates.pic.body-1)
    Coefficients:
    primates.pic.body
               0.4319
    # Permutation procedure to test PIC
    lmorigin(formula=primates.pic.longevity~primates.pic.body, nperm=1000)
    Coefficients and parametric test results
                       Coefficient Std_error t-value Pr(>|t|)
    primates.pic.body     0.43193   0.28649  1.5077   0.2288
    F-statistic: 2.273067 on 1 and 3 DF:
      permutational p-value: 0.2377622
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Intraspecific variation}
	\begin{itemize}
		\item \texttt{pic.ortho()} requires list of measurements (vectors) for all taxa --- their lengths can differ
		\item If we have sets of measurements in separated vectors (each vector has measurements for all taxa), we must for each \texttt{list} item use \texttt{cbind} to join columns and select appropriate line (from 1~to number of taxa)
		\item In example below, \texttt{jitter()} adds random noise
		\item Other usage is same in previous case\ldots
	\end{itemize}
	\begin{spluscode}
    # Preparing tips with fake random variable values
    primates.pic.var <- list(cbind(primates.body, jitter(primates.body),
      jitter(primates.body))[1,], cbind(primates.body, jitter(primates.
      body), jitter(primates.body))[2,], cbind(primates.body, jitter(
      primates.body), jitter(primates.body))[3,], cbind(primates.body,
      jitter(primates.body), jitter(primates.body))[4,], cbind(
      primates.body, jitter(primates.body), jitter(primates.body))[5,])
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Explanation of the cbind trick}
	\begin{spluscode}
    cbind(primates.body, jitter(primates.body), jitter(primates.body))
    Homo         4.09434 4.113074 4.038092
    Pongo        3.61092 3.671217 3.558953
    Macaca       2.37024 2.426757 2.430310
    Ateles       2.02815 1.986006 2.091402
    Galago       1.46968 1.494281 1.496831
    cbind(primates.body, jitter(primates.body), jitter(primates.body))[1,]
      4.094340      4.072501      4.035324
    cbind(primates.body, jitter(primates.body), jitter(primates.body))[2,]
      3.610920      3.572728      3.664654
    class(cbind(primates.body, jitter(primates.body),
      jitter(primates.body)))
    [1] "matrix"
    class(cbind(primates.body, jitter(primates.body),
      jitter(primates.body))[1,])
    [1] "numeric"
    # jitter() adds random noise every time, so that the values differ
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Calculation of phylogenetic independent contrast with intraspecific variation}
	\begin{spluscode}
    # Check list of numeric vectors - required as input for pic.ortho()
    primates.pic.var
    primates.pic.var[[1]]
    class(primates.pic.var)
    class(primates.pic.var[[1]])
    # Calculate for one character - this must be done for at least one more
    # character and correlation of PICs must be tested
    primates.pic.ortho <- pic.ortho(x=primates.pic.var, phy=primates.tree,
      var.contrasts=FALSE, intra=FALSE)
    primates.pic.var
	\end{spluscode}
	\begin{itemize}
		\item Resulting vector (here \texttt{primates.pic.ortho}) can then be used in absolutely same way as output of classical \texttt{pic()} --- testing by \texttt{lmorigin()} (slide~\ref{pic-test}) etc.
	\end{itemize}
\end{frame}

\subsection{Autocorrelation}

\begin{frame}[fragile]{Phylogenetic autocorrelation}
	\begin{itemize}
		\item Autocorrelation coefficient to quantify whether the distribution of a~trait among a~set of species is affected or not by their phylogenetic relationships
		\item In the absence of phylogenetic autocorrelation, the mean expected value of I~and its variance are known - it is thus possible to test the null hypothesis of the absence of dependence among observations
	\end{itemize}
	\begin{spluscode}
    # Let's choose weights as wij = 1/dij, where the d’s is the distances
    # measured on the tree - cophenetic() calculates cophenetic distances
    # can be just cophenetic(primates.tree) or some other transformation
    primates.weights <- 1/cophenetic(primates.tree)
    primates.weights # See it
    class(primates.weights)
    diag(primates.weights) <- 0 # Set diagonal to 0
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Testing of Moran's~\textit{I}}
	\begin{spluscode}
    # Calculate Moran's I
    # Slightly significant positive phylogenetic correlation among body mass
    Moran.I(x=primates.body, weight=primates.weights, alternative="greater")
    # Positive, but non-significant
    Moran.I(x=primates.longevity, weight=primates.weights,
      alternative="greater")
    # Test of Moran's with randomization procedure
    # Body is significant - nonrandom, longevity not (random)
    gearymoran(bilis=primates.weights, X=data.frame(primates.body,
      primates.longevity), nrepet=1000)
    # Test of Abouheif designed to detect phylogenetic autocorrelation in
    # a quantitative trait - in fact Moran's I test using a particular
    # phylogenetic proximity between tips
    library(adephylo)
    abouheif.moran(x=cbind(primates.body, primates.longevity),
      W=primates.weights, method="oriAbouheif", nrepet=1000, alter="greater")
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Correlogram to visualize results of phylogenetic autocorrelation analysis}
	\begin{spluscode}
    data(carnivora) # Loads training data set
    head(carnivora) # Look at the data
    # Calculate the correlogram
    carnivora.correlogram <- correlogram.formula
      (formula=SW~Order/SuperFamily/Family/Genus, data=carnivora)
    carnivora.correlogram # See results
    # Calculate the correlogram - test for both body masses
    carnivora.correlogram2 <- correlogram.formula
      (formula=SW+FW~Order/SuperFamily/Family/Genus, data=carnivora)
    carnivora.correlogram2 # See results
    plot(x=carnivora.correlogram, legend=TRUE, test.level=0.05, col=c("white",
      "black")) # Plot it
    # Plot it - test for both body masses - two or one graph(s)
    plot(x=carnivora.correlogram2, lattice=TRUE, legend=TRUE, test.level=0.05)
    plot(x=carnivora.correlogram2, lattice=FALSE, legend=TRUE, test.level=0.05)
	\end{spluscode}
\end{frame}

\begin{frame}{Correlograms of SW and SW+FW (in one or two graphs) depending on taxonomic level with marked significance}
	\includegraphics[width=\textwidth]{correlog.png}
\end{frame}

\subsection{Decomposition}

\begin{frame}[fragile]{Prepare toy data set (tree)}
	\begin{spluscode}
    # Load MrBayes tree in NEXUS format
    apiaceae.tree <- read.nexus
      (file="https://soubory.trapa.cz/rcourse/apiaceae_mrbayes.nexus")
    print.phylo(apiaceae.tree) # See it
    plot.phylo(apiaceae.tree) # See it
    apiaceae.tree <- root.phylo(apiaceae.tree, "Aralia_elata") # Root the tree
    # Remove "_" from taxa names
    # plot.phylo() by default omits "_" from tip names
    apiaceae.tree$tip.label <- gsub(pattern="_", replacement=" ",
      x=apiaceae.tree$tip.label)
    # Drop outgroup (Aralia and Hydrocotyle)
    # Click on last common ancestor of ingroup desired to be kept
    plot.phylo(apiaceae.tree)
    apiaceae.tree <- extract.clade(apiaceae.tree, interactive=TRUE)
    plot.phylo(apiaceae.tree)
    library(adephylo)
    library(phylobase)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Modified tree}
	\begin{center}
		\includegraphics[width=\textwidth-5cm]{apiaceae_tree.png}
	\end{center}
	\begin{spluscode}
    # Decomposition of topographical distances (right plot)
    table.phylo4d(x=phylo4d(x=apiaceae.tree, tip.data=treePart(x=apiaceae.tree,
      result="orthobasis")), treetype="cladogram")
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Prepare toy data set (the variable)}
	\begin{spluscode}
    # Generate some random variable
    library(geiger)
    apiaceae.eco <- sim.char(phy=apiaceae.tree, par=0.1, nsim=1,
      model="BM")[,,1]
    ?sim.char # See it for another possibilities to simulate data
    # Names for the values
    names(apiaceae.eco) <- apiaceae.tree[["tip.label"]]
    apiaceae.eco # See it
	\end{spluscode}
	\begin{itemize}
		\item \texttt{sim.char()} creates an array (we keep only numeric vector of 1$^{st}$ simulation --- \texttt{[,,1]}) of simulated characters, with \texttt{model="BM"} under Brownian motion
		\item Many methods compare \textbf{names} of character values with \texttt{tip.label} slot of the tree to pair character values with correct taxa
		\begin{itemize}
			\item Otherwise values must be ordered in same way as in \texttt{tip.label} slot
			\item \alert{Always check manual for respective function and all data!}
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Orthonormal decomposition - phylogenetic eigenvector regression}
	\begin{spluscode}
    anova(lm(apiaceae.eco ~ as.matrix(orthobasis.phylo(x=apiaceae.tree,
      method="patristic")[,1:2])))
	\end{spluscode}
	\begin{itemize}
		\item Significant result --- significant phylogenetic inertia (phylogenetic effect) --- the tendency for traits to resist evolutionary change despite environmental perturbations
		\item \texttt{orthobasis.phylo()} return matrix, which is linear transformation of cophenetic distances --- columns 1~and 2~can be used to calculate phylogenetic variance --- it can be used to calculate linear regression
	\end{itemize}
	\begin{spluscode}
                 Df   Sum Sq  Mean Sq F value Pr(>F)
    as.matrix...  2 0.063689 0.031845  2.2275 0.1422
    Residuals    15 0.214443 0.014296
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Orthonormal decomposition of variance of a~quantitative variable on an orthonormal basis}
	\begin{spluscode}
    orthogram(x=apiaceae.eco, tre=apiaceae.tree, nrepet=1000,
      alter="two-sided")
    ?orthogram # See another calculation possibilities
	\end{spluscode}
	\begin{itemize}
		\item Analyses one quantitative trait
		\item Do not confuse with \texttt{ade4::orthogram} --- similar, but require data in little bit different form, marked as deprecated and replaced by the \texttt{adephylo} version
		\item It returns results of 5~non-parametric tests associated to the variance decomposition
		\item Procedure decomposes data matrix to separate phylogeny and phenotype to see if there is significant signal
	\end{itemize}
\end{frame}

\begin{frame}{Orthogram}
	\begin{center}
		\includegraphics[width=\textwidth-4cm]{orthogram.png}
	\end{center}
	\begin{itemize}
		\item Observed value is within permutations --- no significant inertia of the trait to phylogeny\ldots
	\end{itemize}
\end{frame}

\subsection{PGLS}

\begin{frame}[fragile]{Phylogenetic Generalized Least Squares}
	\begin{itemize}
		\item Model-based testing if there is significant correlation between two traits (after removing the phylogenetic component)
		\item \texttt{nlme::gls} fits a~linear model using generalized least squares
		\item Functions \texttt{corBlomberg}, \texttt{corBrownian}, \texttt{corMartins} and \texttt{corPagel} from \texttt{ape} package create correlation matrix of evolution of continuous character according to the given tree
	\end{itemize}
	\begin{spluscode}
    library(nlme)
    library(ape)
    summary(gls(model=primates.longevity ~ primates.body,
      data=as.data.frame(cbind(primates.longevity, primates.body)),
      correlation=corBrownian(value=1, phy=primates.tree)))
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Implementation in caper package}
	\begin{spluscode}
    library(caper) # Load needed library
    data(shorebird) # Load training data, see ?shorebird.data
    # Calculate the model
    shorebird.pgls <- pgls(formula=shorebird.data[["F.Mass"]] ~
      shorebird.data[["Egg.Mass"]], data=comparative.data(phy=
      shorebird.tree, data=as.data.frame(cbind(shorebird.data[["F.Mass"]],
      shorebird.data[["Egg.Mass"]], shorebird.data[["Species"]])),
      names.col=V3, vcv=TRUE))
    # See the result
    summary(shorebird.pgls)
    # See the plot of observer and fitted values
    plot(shorebird.pgls)
    abline(a=0, b=1, col="red")
    # ANOVA view of the model
    anova(shorebird.pgls)
    # Akaike's information criterion (smaller = better)
    AIC(shorebird.pgls)
	\end{spluscode}
\end{frame}

\begin{frame}{Results of PGLS}
	\begin{multicols}{2}
		\includegraphics[height=5.5cm]{shorebirds.png}
		\begin{itemize}
			\item \texttt{pgls()} uses maximum likelihood to test for phylogenetic signal
			\item The signal is clearly presented
			\item Usually, tuning the model (possible data transformations and or changing model parameters) is necessary to find the best model --- AIC helps
			\item See \href{https://CRAN.R-project.org/package=caper}{caper manual} for details
		\end{itemize}
	\end{multicols}
\end{frame}

\subsection{GEE}

\begin{frame}[fragile]{Generalized Estimating Equations}
	\begin{itemize}
		\item Extension of GLM for correlated data --- usage is similar
		\item It is possible to use phylogeny or correlation matrix (typically based on phylogeny)
	\end{itemize}
	\vfil
	\begin{spluscode}
    # Calculate the model
    compar.gee(formula=primates.longevity ~ primates.body,
      phy=primates.tree)
    # or with correlation matrix:
    compar.gee(formula=primates.longevity ~ primates.body,
      corStruct=corMartins(value=1, phy=primates.tree, fixed=TRUE))
    # for corStruct there are similar functions corBlomberg, corMartins,
    # corPagel, corBrownian - see manuals for differences
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Not significant in this case\ldots}
	\begin{spluscode}
    Call: compar.gee(formula = primates.longevity ~
      primates.body, phy = primates.tree)
    Number of observations: 5
    Model:
                         Link: identity
    Variance to Mean Relation: gaussian
    QIC: 7.310142
    Summary of Residuals:
           Min         1Q     Median         3Q        Max
    -0.8031302 -0.0132754  0.0999588  0.1988258  0.2862064
    Coefficients:
                   Estimate      S.E.        t Pr(T > |t|)
    (Intercept)   1.0670417 0.5838429 1.827618   0.2695894
    primates.body 0.8497249 0.2157006 3.939372   0.1101432
	\end{spluscode}
\end{frame}

% \subsection{Partitioning} % TODO Partitioning
%
% \begin{frame}[fragile]{Variance partitioning}
% 	\begin{spluscode}
%
% 	\end{spluscode}
% \end{frame}

\subsection{Phylosignal}

\begin{frame}[fragile]{Phylogenetic signal}
	\begin{itemize}
		\item Direct consequence of the evolution of trait depends on evolution --- if trait variation is driven by environment, phylogenetic signal is~0
	\end{itemize}
	\begin{spluscode}
    library(picante)
    # Test for Bloomberg's K statistics
    Kcalc(x=apiaceae.eco, phy=apiaceae.tree, checkdata=TRUE)
    # Test with permutations
    phylosignal(x=apiaceae.eco, phy=apiaceae.tree, reps=1000,
      checkdata=TRUE)
	\end{spluscode}
	\begin{itemize}
		\item Blomberg's values of 1~correspond to a~Brownian motion process, which implies some degree of phylogenetic signal or conservatism
		\item K~values closer to zero correspond to a~random or convergent pattern of evolution, while K~values greater than 1~indicate strong phylogenetic signal and conservatism of traits
		\item Blomberg's K~statistic of phylogenetic signal
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Analyze multiple traits in once}
	\begin{spluscode}
    # sapply performs analysis on list of variables (numeric vectors)
    sapply(X=list(body=primates.body, longevity=primates.longevity),
      FUN=Kcalc, phy=primates.tree, checkdata=FALSE)
    sapply(X=list(body=primates.body, longevity=primates.longevity),
      FUN=phylosignal, phy=primates.tree, reps=1000)
    # Alternative to use multiPhylosignal instead of sapply
    multiPhylosignal(x=as.data.frame(cbind(primates.body,
      primates.longevity)), phy=primates.tree, reps=1000)
    # Note sapply() and multiPhylosignal() return same data, but the
    # matrices are transposed - use t() to transpose one to look like
    # the other:
    t(multiPhylosignal(x=as.data.frame(cbind(primates.body,
      primates.longevity)), phy=primates.tree, reps=1000))
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{When there are vectors with standard errors of measurements}
	\begin{itemize}
		\item Functions for testing of phylogenetic signal do not work with more measurements per taxon
		\begin{itemize}
			\item Currently, the only possibility is \texttt{phylosig()} which is able to work with SE (user must prepare this vector from the data manually; from e.g. \texttt{plotrix::std.error})
		\end{itemize}
		\item \texttt{phylosig()} can be used as an alternative to \texttt{phylosignal()} --- the functions are similar in basic usage
	\end{itemize}
	\begin{spluscode}
    library(phytools)
    ?phylosig # See for details
    # Test for phylogenetic signal (here without SE)
    phylosig(tree=apiaceae.tree, x=apiaceae.eco, method="K", test=TRUE,
      nsim=1000)
    phylosig(tree=primates.tree, x=primates.body, method="lambda",
      test=TRUE)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Alternative testing for phylogenetic signal with GLM}
	\begin{itemize}
		\item It is possible to use intercept-only (\texttt{model/formula} will be something like \texttt{variable $\sim$ 1}, not \texttt{variable1 $\sim$ variable2}) GLM to quantify phylogenetic signal in trait
		\item It is tricky to select the best correlation structure --- AIC can help with selections (\texttt{AIC(pgls(\ldots))})
	\end{itemize}
	\begin{spluscode}
    # Examples of usage of GLS for testing of phylogenetic signal
    summary(gls(model=primates.longevity ~ 1, data=as.data.frame
      (primates.longevity), correlation=corBrownian(value=1,
      phy=primates.tree)))
    summary(pgls(formula=shorebird.data[["M.Mass"]] ~ 1,
      data=comparative.data(phy=shorebird.tree, data=as.data.frame
      (cbind(shorebird.data[["M.Mass"]], shorebird.data[["Species"]])),
      names.col=V2, vcv=TRUE)))
	\end{spluscode}
\end{frame}

\subsection{pPCA}

\begin{frame}{Phylogenetic principal component analysis}{PCA corrected for phylogeny}
	\begin{itemize}
		\item It requires as input phylogenetic tree and respective comparative data
		\item Phylogenetic component is removed from the data, then classical PCA is calculated
		\item Together with nodes (taxa), PCA scores for PC axes are plotted --- not the taxa --- it shows trends of character evolution on the tree, not positions of taxa in PC space
		\item Other graphs show global vs. local structure, eigenvalues decomposition and positions of characters in virtual space (if they correlate or not)
		\item From package \href{https://academic.oup.com/bioinformatics/article/26/15/1907/188748}{adephylo} by \href{https://www.sciencedirect.com/science/article/pii/S0022519310001736}{Jombart et al. 2010}
		\item It doesn't contain any test, it is more method of data exploration or dealing with big data sets, it is not for verifying hypothesis
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Phylogenetic principal component analysis --- the code}
	\begin{spluscode}
    # Library needed to create phylo4d object required by ppca
    library(adephylo)
    # Calculate pPCA
    primates.ppca <- ppca(x=phylo4d(x=primates.tree, cbind(primates.body,
      primates.longevity)), method="patristic", center=TRUE, scale=TRUE,
      scannf=TRUE, nfposi=1, nfnega=0)
    # Print results
    print(primates.ppca)
    # See summary information
    summary(primates.ppca)
    # See PCA scores for variables on phylogenetic tree
    scatter(primates.ppca)
    # See decomposition of pPCA eigenvalues
    screeplot(primates.ppca)
    # Plot pPCA results - global vs. local structure, decomposition of pPCA
    # eigenvalues, PCA plot of variables and PCA scores for variables on tree
    plot(primates.ppca)
	\end{spluscode}
\end{frame}

\begin{frame}{Plot pPCA results - global vs. local structure, decomposition of pPCA eigenvalues, PCA plot of variables and PCA scores for variables on phylogenetic tree}
	\begin{center}
		\includegraphics[width=\textwidth-5cm]{ppca.png}
	\end{center}
\end{frame}

\subsection{Ancestral state}

\begin{frame}[fragile]{Ancestral state reconstruction}
	\begin{itemize}
		\item By default \texttt{ape::ace()} performs estimation for continuous characters assuming a~Brownian motion model fit by maximum likelihood
		\item \texttt{ace()} can handle continuous as well as discrete data
	\end{itemize}
	\begin{spluscode}
    library(ape)
    # See ?ace for possible settings and estimations
    primates.body.ace <- ace(x=primates.body, phy=primates.tree,
      type="continuous", method="REML", corStruct=corBrownian(value=1,
      phy=primates.tree)) # See result - reconstructions are in $ace slot
    # To be plotted on nodes - 1st column are node numbers
    primates.body.ace
    # Plot it
    plot.phylo(x=primates.tree, edge.width=2, cex=2)
    tiplabels(round(primates.body, digits=3), adj=c(0, -1), frame="none",
      col="blue", cex=2)
    nodelabels(round(primates.body.ace$ace, digits=3), frame="circle",
      bg="red", cex=1.5)
	\end{spluscode}
\end{frame}

\begin{frame}{Ancestral state reconstructions of primates body weights}
	\begin{itemize}
		\item ACE returns long numbers --- truncate them by e.g. \texttt{round(x=\ldots, digits=3)} (\texttt{x} is vector with ACE values)
	\end{itemize}
	\begin{center}
		\includegraphics[height=5cm]{ace.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Another possibilities (package phytools)}
	\begin{multicols}{2}
		\begin{spluscode}
    library(phytools)
    # More possibilities
    plot.phylo(x=primates.tree,
      edge.width=2, cex=2)
    # ML estimation of a continuous trait,
    # can compute confidence interval
    nodelabels(fastAnc(tree=
      primates.tree, x=primates.body))
    # ACE for Brownian evolution with
    # directional trend
    plot.phylo(x=primates.tree,
      edge.width=2, cex=2)
    nodelabels(anc.trend(tree=
      primates.tree, x=primates.body,
      maxit=100000)$ace)
    # ACE for Brownian evolution using
    # likelihood
		\end{spluscode}
		\columnbreak
		\begin{spluscode}
    plot.phylo(x=primates.tree,
      edge.width=2, cex=2)
    nodelabels(round(anc.ML(tree=
      primates.tree, x=primates.body,
      maxit=100000, model="BM")$ace,
      digits=2), cex=1.5)
		\end{spluscode}
		\begin{center}
			\includegraphics[height=2cm]{ancml.png}
		\end{center}
		\vfill
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Bayesian ancestral character estimation I}
	\begin{spluscode}
    primates.body.ace.bayes <- anc.Bayes(tree=primates.tree, x=primates.body,
      ngen=100000) # Use more MCMC generations
    primates.body.ace.bayes
    # Get end of ancestral states from Bayesian posterior distribution (it
    # should converge to certain values)
    tail(primates.body.ace.bayes[["mcmc"]])
    primates.body.ace.bayes[["mcmc"]][1001,3:6]
    # Get means of ancestral states from Bayesian posterior distribution
    colMeans(primates.body.ace.bayes[["mcmc"]][201:nrow
      (primates.body.ace.bayes[["mcmc"]]),as.character(1:primates.tree
      $Nnode+length(primates.tree$tip.label))])
    # Plot the likelihood from posterior distribution (it should converge)
    plot(primates.body.ace.bayes)
    plot.phylo(x=primates.tree, edge.width=2, cex=2) # Plot the tree and states
    nodelabels(round(x=primates.body.ace.bayes[["mcmc"]][1001,3:6], digits=3),
      cex=1.5)
    ?phangorn::ancestral.pml # Another possibility
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Bayesian ancestral character estimation II}
	\begin{spluscode}
    primates.body.ace.bayes # See the values
           6        7        8        9
    2.418557 2.569484 2.844268 3.584153
    tail(primates.body.ace.bayes[["mcmc"]]) # See end of the table
            gen     sig2        6        7        8        9     logLik
     ...    ...      ...      ...      ...      ...      ...        ...
     999  99800 1.960194 4.129754 3.196746 3.310278 3.425686  -9.780220
    1000  99900 1.636984 3.556224 2.701105 2.720756 2.965226  -9.770242
    1001 100000 1.588710'2.641937 3.279439 3.093420 3.670807' -7.538937
    primates.body.ace.bayes[["mcmc"]][1001,3:6] # See end of the table
                6        7       8        9
    1001 2.641937 3.279439 3.09342 3.670807
    colMeans(primates.body.ace.bayes[["mcmc"]][201:nrow(primates.body.ace.
      bayes[["mcmc"]]),as.character(1:primates.tree$Nnode+length
      (primates.tree$tip.label))]) # Get means of ancestral states
           6        7        8        9
    2.418557 2.569484 2.844268 3.584153
	\end{spluscode}
\end{frame}

\begin{frame}{Bayesian ancestral character estimation III}{Likelihood of Bayesian posterior probability and the tree with reconstructions}
	\begin{center}
		\includegraphics[width=\textwidth-3cm]{ancbayes.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Continuous map}
	\begin{multicols}{2}
		\vfill
		\begin{center}
			\includegraphics[height=6cm]{contmap.png}
		\end{center}
		\vfill
		\begin{spluscode}
    library(phytools)
    contMap(tree=primates.tree,
      x=primates.body)
    # Change colors with setMap()
    primates.contmap <- setMap(x=
      contMap(primates.tree,
      primates.body),
      colors=c("white", "black"))
    plot(primates.contmap)
    # See ?par for more settings
		\end{spluscode}
		\vfill
		\begin{center}
			\includegraphics[height=1.5cm]{contmapbw.png}
		\end{center}
		\vfill
	\end{multicols}
\end{frame}

\subsection{Phenogram}

\begin{frame}[fragile]{Display more characters on a~tree in a~table}
	\begin{spluscode}
    library(adephylo)
    table.phylo4d(x=phylo4d(x=primates.tree, tip.data=as.data.frame
      (cbind(primates.body, primates.longevity))), treetype="cladogram",
      symbol="circles", scale=FALSE, ratio.tree=0.5)
    table.phylo4d(x=phylo4d(x=shorebird.tree, tip.data=shorebird.data),
      treetype="cladogram", symbol="circles", scale=TRUE, ratio.tree=0.5)
	\end{spluscode}
	\begin{center}
		\includegraphics[height=3cm]{phylotable.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Phenogram}{Vertical axis shows character values}
	\begin{spluscode}
    phenogram(tree=primates.tree, x=primates.longevity, fsize=1.2,
      ftype="i", colors="red", main="Longevity")
    fancyTree(tree=primates.tree, type="phenogram95", x=primates.longevity,
      fsize=1.2, ftype="i", main="95-percentile of longevity")
	\end{spluscode}
	\begin{center}
		\includegraphics[height=3cm]{phenogram.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{Display 2~continuous characters in space and 3D tree connecting them}
	\begin{multicols}{2}
		\begin{spluscode}
    # 2 characters on 2 axis
    phylomorphospace(tree=
      primates.tree, X=cbind
      (primates.body,
      primates.longevity),
      label="horizontal",
      lwd=2, fsize=1.5)
    # 3D (3rd character is fake here)
    # 3 characters it a rotating cube
    phylomorphospace3d(tree=
      primates.tree, X=cbind
      (primates.body,
      primates.longevity,
      abs(primates.body-
      primates.longevity)),
      label=TRUE)
		\end{spluscode}
		\begin{center}
			\includegraphics[height=5.5cm]{phylomorphospace.png}
		\end{center}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Combine phenograms and ancestral state reconstructions}
	\begin{multicols}{2}
		\begin{spluscode}
    # 2 characters on 2 axis
    fancyTree(tree=primates.tree,
      type="scattergram",
      X=cbind(primates.body,
      primates.longevity),
      res=500, ftype="i")
    # See manuals for more settings
    ?fancyTree
    ?phenogram
    ?phylomorphospace
    ?phylomorphospace3d
    ?contMap
    ?setMap
    ?par
		\end{spluscode}
		\begin{center}
			\includegraphics[height=5.5cm]{phenogram-ace.png}
		\end{center}
	\end{multicols}
\end{frame}

\begin{frame}[fragile]{Plotting traits on trees --- code}
	\begin{spluscode}
    # Load training data to display
    data(shorebird, package="caper")
    ?caper::shorebird # See information about the data
    library(phytools) # Load library
    # Prepare named vector of values to plot
    shorebird.toplot <- shorebird.data[["Egg.Mass"]]
    names(shorebird.toplot) <- rownames(shorebird.data)
    shorebird.toplot # See it
    # See options for plotting functions
    ?plotTree.wBars
    ?dotTree
    ?plotSimmap
    # Plot the trees
    plotTree.wBars(tree=shorebird.tree, x=shorebird.toplot,
      tip.labels=TRUE)
    dotTree(tree=shorebird.tree, x=shorebird.toplot, tip.labels=TRUE,
      type="cladogram")
	\end{spluscode}
\end{frame}

\begin{frame}{Plotting traits on trees --- plots}
	\begin{center}
		\includegraphics[width=\textwidth-2cm]{treeval.png}
	\end{center}
\end{frame}

% \subsection{Disparity} % TODO Disparity
%
% \begin{frame}[fragile]{Disparity through time}
% 	\begin{spluscode}
%
% 	\end{spluscode}
% \end{frame}

\section{}

\begin{frame}{Process more data}{Not all combinations and possibilities were shown\ldots}
	\begin{exampleblock}{Tasks}
		\begin{enumerate}
			\item Try to do some analysis with another introduced toy data
			\item Try some of the introduced analysis with your own custom imported data
			\item Try at least 2--3 analysis preferably with your own data according to your interest
		\end{enumerate}
	\end{exampleblock}
	\begin{itemize}
		\item Working code can be easily recycled to process another data in similar way
		\item R is always moving forward --- new and new options are arising --- be opened for news and search them on the Internet
		\item Previous examples are not covering all possibilities\ldots
		\item It is crucial to be able to edit the introduced commands to be able to handle your data
		\item Check help pages of the functions for more options what to do with your data
	\end{itemize}
\end{frame}

\section{The end}

\begin{frame}{Final topics}{General remarks about graphics, introduction to scripting, documentation and help resources, overview of packages}
	\tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
\end{frame}

\subsection{Graphics}

\begin{frame}[fragile]{Direct saving of plots to disk}{Useful e.g. if plot should be bigger than screen, requires special settings, if done in batch, script, etc.}
	\begin{spluscode}
    # Output figure will be saved to the disk as OutputFile.png
    png(filename="OutputFile.png", width=720, height=720, bg="white")
    # Here can go any number of functions making plots...
    plot(...) # Whatever...
    # When using plotting commands, nothing is shown on the screen
    # The final plot(s) will be saved by:
    dev.off() # Closes graphical device - needed after use of plotting
              # functions png(), svg(), pdf(), ... followed by any
              # function like plot() to write the file(s) to the disk
    filename="OutFiles_%03d.png" # Returns list of files named
                                 # OutFiles_001.png, OutFiles_002.png, ...
                                 # Useful for functions returning more
                                 # graphs.
    ?png # These functions have various possibilities to set size, whatever.
    ?svg # Exact possibilities of all 3 functions vary from system to system
    ?pdf # according to graphical libraries available in the computer.
	\end{spluscode}
\end{frame}

\begin{frame}{Graphical packages}
	\begin{itemize}
		\item Basic plotting functions in R are very limited\ldots
		\begin{itemize}
			\item The usage is simple, but anything more complicated requires extensive coding (plenty of examples were shown in the course)\ldots
			\item It can be tricky to get desired figure --- some magic use to be needed\ldots
		\end{itemize}
		\item There are \href{https://CRAN.R-project.org/web/views/Graphics.html}{plenty of graphical packages}
		\item Advanced functions we used internally by used packages are \href{https://CRAN.R-project.org/package=lattice}{lattice} (\href{http://lattice.r-forge.r-project.org/}{web}), \href{https://CRAN.R-project.org/package=gplots}{gplot} and \href{https://CRAN.R-project.org/package=ggplot2}{ggplot2} (\href{https://ggplot2.tidyverse.org/}{web})
		\begin{itemize}
			\item They have enormous possibilities, it is large topic for another long course\ldots
		\end{itemize}
		\item \texttt{par()} sets graphical parameters for following plots (splitting into panes, style of lines, points, text --- see \texttt{pch}, \texttt{lwd}, \texttt{lty}, \texttt{cex}, \texttt{mai}, \texttt{mar}, \texttt{mfcol}, \texttt{mfrow},~\ldots) --- see help pages\ldots
		\item Most important low-level functions are \texttt{points}, \texttt{lines}, \texttt{text}, \texttt{abline}, \texttt{legend}, \texttt{axis}, \texttt{axes}, \texttt{arrows}, \texttt{box} --- see help pages\ldots
	\end{itemize}
\end{frame}

\subsection{GitHub}

\begin{frame}[fragile]{Install package from GitHub}
	\begin{itemize}
		\item \href{https://github.com/}{GitHub} is currently probably the most popular platform to host development of open-source projects --- plenty of R packages are there
		\item \href{https://git-scm.com/}{Git} is version controlling system --- it traces changes among all versions --- absolutely crucial for any software development
		\item Normal stable version of package is installed from repository as usual, but sometimes it can be useful to get latest developmental version (e.g. when it fixes some bug and new release is not available yet)
	\end{itemize}
	\begin{spluscode}
    # Needed library
    install.packages("devtools")
    library(devtools)
    dev_mode(on=TRUE)
    # Install selected package from GitHub (user/project)
    install_github("thibautjombart/adegenet")
    # when finished go back to normal version
    dev_mode(on=FALSE)
	\end{spluscode}
\end{frame}

\subsection{Scripts}

\begin{frame}[allowframebreaks]{R script and its running from command line}
	\begin{itemize}
		\item R script is just plain \texttt{TXT} file with \texttt{.r} (e.g. \texttt{myscript.r}) extension containing list of R commands
		\item Mark all user comments with \texttt{\#} on the beginning
		\item In command line (Linux/macOS/Windows/\ldots) use
		\begin{itemize}
			\item \texttt{Rscript myscript.r} to work \textbf{interactively} --- all output is written to the terminal (screen; as usual), user can be asked for some values,~\ldots
			\item \texttt{R CMD BATCH myscript.r} to let it run \textbf{non-interactively} --- all output is written into file \texttt{myscript.Rout}, terminal (screen) is clean and user can not influence the script anyhow --- e.g. on \href{https://www.metacentrum.cz/en/}{MetaCentrum} --- be sure the script doesn't require user input and works correctly
		\end{itemize}
		\item Script ends when there is any error or on the end of the file
		\item When working on both Windows and macOS/Linux, take care about end of lines, and in case of usage of accented characters (e.g. for labels) also about encoding
		\begin{itemize}
			\item Windows and UNIX (Linux, macOS,~\ldots) have different internal symbol for \href{https://en.wikipedia.org/wiki/Newline}{new line}
			\item Use UNIX command line utilities \texttt{dos2unix myscript.r} or \texttt{unix2dos myscript.r} to get correct ends of lines for target system
			\item Linux and macOS use to use UTF-8, Windows use regional encoding, e.g. Czech CP-1250 --- use advanced text editor (slide~\ref{editors}) to convert the encoding, or use some command line tool, like \texttt{iconv}
		\end{itemize}
	\end{itemize}
\end{frame}

\subsection{Functions}

\begin{frame}[fragile]{Simple function}
	\begin{itemize}
		\item Functions pack sets of commands for more comfortable repeated usage
		\item People more interested in R programming need to check special courses and/or \href{https://CRAN.R-project.org/manuals.html}{documentation}
	\end{itemize}
	\begin{spluscode}
    # General syntax:
    MyFunction <- function (x, y) {
      # Any commands can be here...
      x + y
      }
    # Use as usually:
    MyFunction(5, 8)
    MyFunction(1, 4)
    MyFunction(x=4, y=7)
    MF <- MyFunction(9, 15)
    MF # See it works
	\end{spluscode}
\end{frame}

\subsection{Loops}

\begin{frame}[fragile]{Simple loop --- for cycles}
	\begin{itemize}
		\item Loops repeat one task given number of times
		\item Variable \texttt{i} has changing value for every repetition --- useful for working with indexes (within lists, matrices,~\ldots)
		\item It is possible to use variables or numeric output of functions in \texttt{from:to} expression --- this is very variable
		\item In \texttt{for} loop we know in advance the number of repetitions (cycles), in \texttt{while} loop (next slide) we don't
	\end{itemize}
	\begin{spluscode}
    # Simplest loop - print value of "i" in each step
    # "i" is commonly used for various indexing
    for (i in 1:5) { print(i) }
    [1] 1 # This is the value of "i"...
    [1] 2
    [1] 3
    [1] 4
    [1] 5
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{For and while loops}
	\begin{spluscode}
    # In every step modify value of variable "X" (add 1 to previous value)
    X <- 0 # Set initial value
    for (i in 1:10) {
      # Any commands can be here...
      print("Loop turn") # Some message for user
      print(i) # Print number of turn - note how it is increasing
      X <- X+i # Rise value of "X" by current value of "i" (previous line)
      print(paste("Variable value:", X)) } # Print current value of "X"
    for (i in 10:5) { print(i) } # Can be descending...
    # Work on each item of a list object
    # Print length of each sequence in nothofagus.sequences
    for (L in 1:length(nothofagus.sequences)) {
      print(length(nothofagus.sequences[[L]])) }
    # While loop - it is done while the condition is valid
    # While value of "Q" is < 5 (starting from 0), print it and add 1
    Q <- 0
    while (Q < 5) { print(Q <- Q+1) }
	\end{spluscode}
\end{frame}

\subsection{If-else branching}

\begin{frame}[fragile]{If-else branching I}
	\begin{itemize}
		\item Basic method of branching the code --- \textbf{if} the condition is met, \textbf{then} one branch is followed, \textbf{else} --- in any other case --- the other branch of the code is executed
		\item \texttt{else} part can be missing --- the code is executed \textbf{only if} the condition is met
	\end{itemize}
	\begin{spluscode}
    XX <- seq(from=-3, to=6.5, by=0.1)
    XX
    YY <- c()
    for (II in 1:length(XX)) {
      if(XX[II] <= 2) { # Executed for XX <= 2
        YY[II] <- XX[II]^2
        } else { # if(XX[II] > 2) # Executed for XX > 2
          YY[II] <- 6-XX[II]
          }
      }
    YY # See next two slides for the end of the example
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{If-else branching II}
	\begin{spluscode}
    # Plot from example from previous slide
    plot(XX, YY) # See the result
    # Or (different possibility to get very same result)
    # Note "XX" is reused from the previous slide
    CC <- function(AA) {
      if(AA <= 2) { # Executed for XX <= 2
      BB <- AA^2
      } else { # Executed for XX > 2
        BB <- 6-AA
        }
      return(BB) # The output value
      }
     CC # Previously, "YY" contained values to plot made by the for loop,
        # here "CC" contains function to by used by sapply() when plotting
     plot(sapply(XX, CC)) # See the result
    # The plot (same for both ways how to do it) is on next slide
	\end{spluscode}
\end{frame}

\begin{frame}{Output of the if-else branching example}
	\begin{center}
		\includegraphics[height=6.5cm]{if-else.png}
	\end{center}
\end{frame}

\subsection{Solving problems}

\begin{frame}[allowframebreaks]{Most common problems and their solutions}
	\label{problems}
	\begin{itemize}
		\item Something was not found (object, function file,~\ldots)
		\begin{itemize}
			\item Check spelling of all methods, parameters, etc.
			\item Check all paths (slide~\ref{path})
			\item Check if all required objects were correctly created in previous steps
			\item Check if all required libraries are loaded
		\end{itemize}
		\item Unknown parameter, method, etc.
		\begin{itemize}
			\item Check spelling of all parameters, consult manual pages
			\item Check if all required libraries are loaded
		\end{itemize}
		\item Graphics is not plotted correctly
		\begin{itemize}
			\item Graphical window is too small (common problem with RStudio on screen with low resolution) --- try to enlarge plotting window/pane
			\item Reset graphical settings from some previous plot(s) by (repeated) calling of \texttt{dev.off()}
		\end{itemize}
		\item R does nothing (but CPU is not extensively used)
		\begin{itemize}
			\item R is waiting for some user input
			\item If command line starts with \texttt{+}, previous line was not completed correctly (e.g. missing closing bracket \texttt{)}) --- check syntax, add it and hit \texttt{Enter}
			\item Some functions show plots and ask user for decision what to do (e.g DAPC, slide~\ref{DAPC}) --- write the answer into command line or special window and hit \texttt{Enter}
		\end{itemize}
		\item Some functions are not (without extra work) usable on all operating systems, some don't work correctly in GUI
		\begin{itemize}
			\item Check manual and/or some on-line forum (slide~\ref{help} and onward)
		\end{itemize}
		\item R and packages are more or less changing from version to version
		\begin{itemize}
			\item Old methods can became outdated and not working anymore
			\item Check release notes and change logs for new versions, manual pages and on-line forums (slide~\ref{help} and onward)
			\item Generally, follow news for your topic (appropriate mailing list,~\ldots)
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{How to ask for help}
	\label{howtoask}
	\begin{itemize}
		\item \alert{Never ever} ask simple silly lazy questions you can quickly find in manual or web
		\item People on mailing lists and forums respond volunteerly in their spare free time --- do not waste it --- be polite, brief and informative
		\item Be as specific and exact as possible
		\begin{itemize}
			\item Write \alert{exactly} what you did (\enquote{It doesn't work!} is useless\ldots)
			\item Copy/paste your commands and their output, especially error messages --- they are keys to solve the problem
			\item Try to search web for the error messages (or their parts)
			\item Try to provide minimal working example --- add at least part of your data (if applicable) so that the problem is reproducible
			\item Specify version(s) of R/packages, operating system and/or another important details --- authors will commonly insist on newest versions: add outputs of \texttt{sessionInfo()} and \texttt{packageVersion("PackageName")}
		\end{itemize}
		\item \textbf{R is free as freedom of speech --- not as free beer!}
		\begin{itemize}
			\item As soon as you don't pay for support, you can't blame anyone for lack of responses
			\item There are plenty of reasons some package/function doesn't work --- usage/data author didn't expect, unsupported operating system, author's mistake, user's mistake,~\ldots
			\item Authors wish their software to be useful --- constructive feedback, reporting bugs and wishes is welcomed, but it must be provided in the way useful for the developer
		\end{itemize}
		\item R functions commonly lack control of input data --- error messages are returned by internal functions
		\begin{itemize}
			\item They are not straightforward
			\item It requires some training and experience to be quickly able to find what is going on
			\item Always carefully read error messages and think about them
		\end{itemize}
		\item Imagine you should answer --- which information do you need?
	\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Where to look for the help}
	\label{help}
	\begin{alertblock}{Question must have certain form!}
			Before asking, \alert{ensure your question is in answerable form} --- slide~\ref{howtoask}.
		\begin{itemize}
			\item Sloppily asked question can't be answered at all\ldots
			\item Check documentation, manuals and search the Internet before asking
		\end{itemize}
	\end{alertblock}
	\begin{itemize}
		\item R homepage \url{https://www.r-project.org/} and packages \url{https://CRAN.R-project.org/web/packages/} (with documentation and links)
		\item R phylogeny mailing list \url{https://stat.ethz.ch/mailman/listinfo/r-sig-phylo}
		\item R genetics mailing list \url{https://stat.ethz.ch/mailman/listinfo/r-sig-genetics}
		\item Bioconductor home page \url{https://bioconductor.org/} and support forum \url{https://support.bioconductor.org/}
		\item Adegenet help mailing list \url{http://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/adegenet-forum} and GitHub page \url{https://github.com/thibautjombart/adegenet/wiki}
		\item Poppr forum \url{https://groups.google.com/forum/\#!forum/poppr}
		\item R help mailing list \url{https://stat.ethz.ch/mailman/listinfo/r-help} (web interface \url{http://r.789695.n4.nabble.com/})
		\item R announce mailing list \url{https://stat.ethz.ch/mailman/listinfo/r-announce}
		\item R ecology mailing list \url{https://stat.ethz.ch/mailman/listinfo/r-sig-ecology}
		\item R at StackOverflow StackExchange (for programmers) \url{https://stackoverflow.com/questions/tagged/r}
		\item R at CrossValidated StackExchange (for stasticians, mathematicians, etc.) \url{https://stats.stackexchange.com/questions/tagged/r}
		\item Biostars --- general bioinformatics forum \url{https://www.biostars.org/}
		\item Biology --- general forum about biology at StackExchange \url{https://biology.stackexchange.com/}
		\item Do not hesitate to ask on the forum or contact author of package with which you have problem, preferably through some public forum or mailing list, they usually respond quickly and helpfully\ldots{ }--- they wish their packages to be working and useful
		\item \href{http://rseek.org/}{Uncle Google} is your friend here (\textit{\enquote{how to XXX in R}})\ldots
	\end{itemize}
\end{frame}

\subsection{Resources}

\begin{frame}{Citations}
	\begin{itemize}
		\item To correctly cite R launch \texttt{citation()} and see information there --- it is slightly different for every version of R
		\item Cite used packages --- launch \texttt{citation("PackageName")} --- if this information is missing, go to its manual page and/or homepage and find the information there
		\item Packages/functions commonly provide various methods to calculate desired task --- check function's help page (\texttt{\textbf{?}FunctionName}) and find references there and cite them accordingly
		\item Check original papers to fully understand respective method
	\end{itemize}
\end{frame}

\begin{frame}{Further reading}{The most important books for our topics}
	\begin{multicols}{2}
		\begin{thebibliography}{1}
			\bibitem[Paradis 2012]{Paradis2012}
				Emmanuel Paradis
				\newblock Analysis of Phylogenetics and Evolution with R, second edition
				\newblock Springer, 2012
				\newblock \url{http://ape-package.ird.fr/APER.html}
			\bibitem[Crawley 2012]{Crawley2012}
				Michael J. Crawley
				\newblock The R Book, second edition
				\newblock Wiley, 2012
			\bibitem[Sinha 2014]{Sinha2014}
				Paurush Praveen Sinha
				\newblock Bioinformatics with R Cookbook
				\newblock Packt Publishing, 2014
			\bibitem[Ives 2018]{Ives2018}
				Anthony R. Ives
				\newblock Mixed and Phylogenetic Models: A Conceptual Introduction to Correlated Data
				\newblock Leanpub, 2018
				\newblock \url{https://leanpub.com/correlateddata} (free to read on-line)
		\end{thebibliography}
	\end{multicols}
\end{frame}

\begin{frame}[allowframebreaks]{Learning resources}
	\begin{itemize}
		\item R homepage \url{https://www.r-project.org/} and packages \url{https://CRAN.R-project.org/web/packages/} (with documentation and links)
		\item Books about R \url{https://www.r-project.org/doc/bib/R-books.html}
		\item List of R documentation \url{https://CRAN.R-project.org/manuals.html}
		\item Bioconductor help pages \url{https://master.bioconductor.org/help/}
		\item R phylo wiki \url{https://www.r-phylo.org/wiki/Main_Page}
		\item R phylogenetics at CRAN \url{https://CRAN.R-project.org/web/views/Phylogenetics.html}
		\item Integrated documentation search \url{https://www.rdocumentation.org/}
		\item RForge package repository \url{https://r-forge.r-project.org/} (with documentation)
		\item Little Book of R for Bioinformatics \url{https://a-little-book-of-r-for-bioinformatics.readthedocs.org/en/latest/}
		\item Little Book of R for Multivariate Analysis \url{https://little-book-of-r-for-multivariate-analysis.readthedocs.org/en/latest/}
		\item Little Book of R for Biomedical Statistics \url{https://a-little-book-of-r-for-biomedical-statistics.readthedocs.org/en/latest/}
		\item Little Book of R for Time Series \url{https://a-little-book-of-r-for-time-series.readthedocs.org/en/latest/}
		\item Adegenet web \url{http://adegenet.r-forge.r-project.org/} and GitHub page \url{https://github.com/thibautjombart/adegenet/wiki}
		\item APE home page \url{http://ape-package.ird.fr/}
		\item Information and manual about pegas \url{http://ape-package.ird.fr/pegas.html}
		\item Phytools \url{http://phytools.org/}, its blog \url{http://blog.phytools.org/} and GitHub page \url{https://github.com/liamrevell/phytools}
		\item Poppr documentation \url{https://grunwaldlab.github.io/poppr/reference/poppr-package.html}
		\item Population Genetics in R \url{https://popgen.nescent.org/} by \href{https://onlinelibrary.wiley.com/doi/full/10.1111/1755-0998.12558}{Kamvar et al}
		\item ade4 home page \url{http://pbil.univ-lyon1.fr/ADE-4/ade4-html/00Index.html?lang=eng} and documentation \url{http://pbil.univ-lyon1.fr/ade4/home.php?lang=eng}
		\item Phangorn resources \url{https://CRAN.R-project.org/package=phangorn}
		\item The R journal \url{https://journal.r-project.org/}
		\item R Programming \url{https://en.wikibooks.org/wiki/R_Programming}
		\item RStudio Cheat Sheets \url{https://rstudio.com/resources/cheatsheets/} and Online learning resources \url{https://education.rstudio.com/learn/}
		\item R-bloggers --- aggregation of R blogs \url{https://www.r-bloggers.com/}
		\item R on The Molecular Ecologist \url{https://www.molecularecologist.com/category/software/r/}
		\item R tutorial \url{https://www.r-tutor.com/}
		\item Cookbook for R  \url{http://www.cookbook-r.com/}
		\item Spatial R \url{https://sites.google.com/site/spatialr/}
		\item R for open big data \url{https://ropensci.org/}
		\item Statistics with R \url{http://zoonek2.free.fr/UNIX/48_R/all.html}
		\item The R Inferno book \url{https://www.burns-stat.com/documents/books/the-r-inferno/} (Feeling like being in hell when using R?)
		\item Springer R series \url{https://www.springer.com/series/6991?detailsPage=titles}
		\item ggplot2 (the most powerful graphical library used by many packages) information \url{https://ggplot2.tidyverse.org/}
		\item plyr documentation \url{https://plyr.had.co.nz/} --- manipulation with data (split-apply-combine)
		\item Leaflet for R \url{https://rstudio.github.io/leaflet/}
		\item Learning R blog \url{https://learnr.wordpress.com/}
		\item R for Community Ecologists \url{http://ecology.msu.montana.edu/labdsv/R/}
		\item Quick-R learning resource \url{https://www.statmethods.net/}
		\item Visualizing and annotating phylogenetic trees with ggtree \url{https://4va.github.io/biodatasci/r-ggtree.html}
		\item R manual and help search \url{http://finzi.psych.upenn.edu/}
		\item \href{http://rseek.org/}{Uncle Google} is your friend (\textit{\enquote{how to XXX in R}})\ldots
		\item R packages commonly contain vignettes (tutorials) --- list them by \texttt{vignette()} and load selected by \texttt{vignette("VignetteName")}
		\item And finally: \alert{Reading documentation is not wasting of time!} ;-)
	\end{itemize}
\end{frame}

\subsection{Summary}

\begin{frame}[allowframebreaks]{Packages we used\ldots}{We used following packages --- but not all functions --- explore them for more possibilities}
	\begin{itemize}
		\item \href{https://CRAN.R-project.org/package=ade4}{ade4}: multivariate data analysis and graphical display (enhancements: \href{https://CRAN.R-project.org/package=ade4TkGUI}{ade4TkGUI} --- GUI, \href{https://CRAN.R-project.org/package=adegraphics}{adegraphics} --- extra graphical functions, commonly used internally)
		\item \href{https://CRAN.R-project.org/package=adegenet}{adegenet}: exploration of genetic and genomic data
		\item \href{https://CRAN.R-project.org/package=adephylo}{adephylo}: multivariate tools to analyze comparative data
		\item \href{https://CRAN.R-project.org/package=akima}{akima}: cubic spline interpolation methods for irregular and regular grids data
		\item \href{https://CRAN.R-project.org/package=ape}{ape}: analysis of phylogenetics and evolution
		\item \href{https://CRAN.R-project.org/package=BiocManager}{BiocManager}: access the Bioconductor project package repository
		\item \href{https://CRAN.R-project.org/package=caper}{caper}: phylogenetic comparative analysis
		\item \href{https://CRAN.R-project.org/package=corrplot}{corrplot}: graphical display of a~correlation or general matrix
		\item \href{https://CRAN.R-project.org/package=devtools}{devtools}: package development tools, access to GitHub
		\item \href{https://CRAN.R-project.org/package=gee}{gee}: generalized estimation equation solver
		\item \href{https://CRAN.R-project.org/package=geiger}{geiger}: fitting macroevolutionary models to phylogenetic trees
		\item \href{https://i-pri.org/special/Biostatistics/Software/Geneland/}{Geneland}: stochastic simulation and MCMC inference of structure from genetic data
		\item \href{https://CRAN.R-project.org/package=ggplot2}{ggplot2}: data visualizations using the Grammar of Graphics
		\item \href{https://CRAN.R-project.org/package=gplots}{gplots}: plotting data
		\item \href{https://CRAN.R-project.org/package=hierfstat}{hierfstat}: estimation and tests of hierarchical F-statistics
		\item \href{https://CRAN.R-project.org/package=ips}{ips}: interfaces to phylogenetic software
		\item \href{https://CRAN.R-project.org/package=kdetrees}{kdetrees}: non-parametric method for identifying potential outlying observations in a~collection of phylogenetic trees
		\item \href{https://CRAN.R-project.org/package=lattice}{lattice}: Trellis graphics, with an emphasis on multivariate data
		\item \href{https://CRAN.R-project.org/package=mapdata}{mapdata}: supplement to maps, larger and/or higher-resolution databases
		\item \href{https://CRAN.R-project.org/package=mapplots}{mapplots}: extra map plotting, pie charts and more
		\item \href{https://CRAN.R-project.org/package=mapproj}{mapproj}: converts latitude/longitude into projected coordinates
		\item \href{https://CRAN.R-project.org/package=maps}{maps}: draws geographical maps
		\item \href{https://CRAN.R-project.org/package=maptools}{maptools}: manipulating and reading geographic data
		\item \href{https://bioconductor.org/packages/release/bioc/html/muscle.html}{muscle}: multiple sequence alignment with MUSCLE
		\item \href{https://CRAN.R-project.org/package=nlme}{nlme}: fits and compares Gaussian linear and nonlinear mixed-effects models
		\item \href{https://r-forge.r-project.org/projects/parallstructure/}{ParallelStructure}: running analysis in the population genetics software STRUCTURE
		\item \href{https://CRAN.R-project.org/package=PBSmapping}{PBSmapping}: spatial analysis tools
		\item \href{https://CRAN.R-project.org/package=pegas}{pegas}: population and evolutionary genetics analysis
		\item \href{https://CRAN.R-project.org/package=phangorn}{phangorn}: phylogenetic analysis
		\item \href{https://CRAN.R-project.org/package=philentropy}{philentropy}: over 40 optimized distance and similarity measures for comparing probability functions
		\item \href{https://CRAN.R-project.org/package=phylobase}{phylobase}: phylogenetic structures and comparative data
		\item \href{http://www.christophheibl.de/Rpackages.html}{phyloch}: interfaces and graphic tools for phylogenetic data
		\item \href{https://CRAN.R-project.org/package=phytools}{phytools}: phylogenetic analysis, comparative biology, graphics
		\item \href{https://CRAN.R-project.org/package=picante}{picante}: integrates phylogeny and ecology
		\item \href{https://CRAN.R-project.org/package=plotrix}{plotrix}: various labeling, axis and color scaling functions
		\item \href{https://CRAN.R-project.org/package=poppr}{poppr}: genetic analysis of populations with mixed reproduction
		\item \href{https://CRAN.R-project.org/package=raster}{raster}: reading, writing, manipulating, analyzing and modeling of gridded spatial data
		\item \href{https://CRAN.R-project.org/package=rgdal}{rgdal}: bindings to the Geospatial Data Abstraction Library and access to projection/transformation operations library
		\item \href{https://CRAN.R-project.org/package=RgoogleMaps}{RgoogleMaps}: interface to query the Google server for static maps and uses the map as a~background image to overlay plots
		\item \href{https://CRAN.R-project.org/package=Rmpi}{Rmpi}: interface (wrapper) to MPI (used for parallel processing)
		\item \href{https://CRAN.R-project.org/package=rworldmap}{rworldmap}: mapping global data (and extra data in \href{https://CRAN.R-project.org/package=rworldxtra}{rworldxtra})
		\item \href{https://CRAN.R-project.org/package=seqinr}{seqinr}: exploratory data analysis and data visualization for biological sequence
		\item \href{https://CRAN.R-project.org/package=shapefiles}{shapefiles}: read and write ESRI shapefiles
		\item \href{https://CRAN.R-project.org/package=snow}{snow}: simple parallel computing
		\item \href{https://CRAN.R-project.org/package=sos}{sos}: searches contributed R packages
		\item \href{https://CRAN.R-project.org/package=sp}{sp}: classes and methods for spatial data
		\item \href{https://CRAN.R-project.org/package=spdep}{spdep}: spatial dependence: weighting schemes, statistics and models
		\item \href{https://CRAN.R-project.org/package=splancs}{splancs}: display and analysis of spatial point pattern data
		\item \href{https://CRAN.R-project.org/package=StAMPP}{StAMPP}: statistical analysis of mixed ploidy populations
		\item \href{https://CRAN.R-project.org/package=TeachingDemos}{TeachingDemos}: demonstrations for teaching and learning, enhanced plotting of text
		\item \href{https://CRAN.R-project.org/package=tripack}{tripack}: constrained two-dimensional Delaunay triangulation
		\item \href{https://CRAN.R-project.org/package=vcfR}{vcfR}: import/export, basic checking and manipulations of VCF
		\item \href{https://CRAN.R-project.org/package=vegan}{vegan}: community ecology
	\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Another interesting packages (we did not use)\ldots}{For your own explorations\ldots}
	\begin{itemize}
		\item \href{https://CRAN.R-project.org/package=adespatial}{adespatial}: multiscale spatial analysis of multivariate data
		\item \href{https://CRAN.R-project.org/package=adhoc}{adhoc}: ad hoc distance thresholds for DNA barcoding identification
		\item \href{https://github.com/eliotmiller/addTaxa}{addTaxa}: adding missing taxa to phylogenies
		\item \href{https://CRAN.R-project.org/package=apex}{apex}: analysis of multiple gene data
		\item \href{https://CRAN.R-project.org/package=apTreeshape}{apTreeshape}: analysis of phylogenetic tree topologies
		\item \href{https://CRAN.R-project.org/package=BAMMtools}{BAMMtools}: analyzing and visualizing complex macroevolutionary dynamics on phylogenetic trees
		\item \href{https://CRAN.R-project.org/package=bayou}{bayou}: Bayesian fitting of Ornstein-Uhlenbeck models to phylogeny
		\item \href{https://CRAN.R-project.org/package=betapart}{betapart}: partitioning beta diversity into turnover and nestedness components
		\item \href{https://CRAN.R-project.org/package=Biodem}{Biodem}: biodemography
		\item \href{https://www.bioconductor.org/packages/release/bioc/html/Biostrings.html}{Biostrings}: string matching algorithms, and other utilities, for fast manipulation of large biological sequences or sets of sequences
		\item \href{https://CRAN.R-project.org/package=convevol}{convevol}: quantifies and assesses the significance of convergent evolution
		\item \href{https://CRAN.R-project.org/package=corHMM}{corHMM}: analysis of binary character evolution
		\item \href{https://CRAN.R-project.org/package=DAMOCLES}{DAMOCLES}: maximum likelihood of a~dynamical model of community assembly
		\item \href{https://CRAN.R-project.org/package=dbscan}{dbscan}: implementation of several density-based algorithms (\href{https://en.wikipedia.org/wiki/DBSCAN}{DBSCAN}, \href{https://en.wikipedia.org/wiki/OPTICS_algorithm}{OPTICS}, etc.)
		\item \href{https://CRAN.R-project.org/package=DDD}{DDD}: diversity-dependent diversification
		\item \href{https://CRAN.R-project.org/package=dendextend}{dendextend}: extending dendrogram objects, comparing trees
		\item \href{https://CRAN.R-project.org/package=distory}{distory}: geodesic distance between phylogenetic trees
		\item \href{https://CRAN.R-project.org/package=diversitree}{diversitree}: comparative phylogenetic analysis of diversification
		\item \href{https://CRAN.R-project.org/package=diveRsity}{diveRsity}: calculation of both genetic diversity partition statistics, genetic differentiation statistics, and locus informativeness for ancestry assignment
		\item \href{https://CRAN.R-project.org/package=dplyr}{dplyr}: various manipulations with data frames
		\item \href{https://CRAN.R-project.org/package=ecodist}{ecodist}: dissimilarity-based functions for ecological analysis, spatial and community data
		\item \href{https://CRAN.R-project.org/package=evobiR}{evobiR}: comparative and population genetic analysis
		\item \href{https://CRAN.R-project.org/package=expands}{expands}: expanding ploidy and allele-frequency on nested subpopulations
		\item \href{https://CRAN.R-project.org/package=fields}{fields}: tools for spatial data
		\item \href{https://CRAN.R-project.org/package=genetics}{genetics}: population genetics
		\item \href{https://CRAN.R-project.org/package=genotypeR}{genotypeR}: design of genotyping markers from VCF files, output of markers for multiplexing on various platforms, various QA/QC and analysis
		\item \href{https://CRAN.R-project.org/package=geomorph}{geomorph}: geometric morphometric analysis of 2D/3D landmark data
		\item \href{https://bioconductor.org/packages/release/bioc/html/ggtree.html}{ggtree}: visualization and annotation of phylogenetic trees (\href{https://guangchuangyu.github.io/software/ggtree/documentation/}{documentation})
		\item \href{https://CRAN.R-project.org/package=HardyWeinberg}{HardyWeinberg}: statistical tests and graphics for HWE
		\item \href{https://CRAN.R-project.org/package=heatmap.plus}{heatmap.plus}: advanced options to plot heatmaps
		\item \href{https://CRAN.R-project.org/package=heatmaply}{heatmaply}: interactive cluster heat maps
		\item \href{https://CRAN.R-project.org/package=HMPTrees}{HMPTrees}: models, compares, and visualizes populations of taxonomic tree objects
		\item \href{https://CRAN.R-project.org/package=hwde}{hwde}: models and tests for departure from HWE and independence between loci
		\item \href{https://CRAN.R-project.org/package=HyPhy}{HyPhy}: macroevolutionary phylogentic analysis of species trees and gene trees
		\item \href{https://bioconductor.org/packages/release/bioc/html/IRanges.html}{IRanges}: infrastructure for manipulating intervals on sequences
		\item \href{https://CRAN.R-project.org/package=iteRates}{iteRates}: iterates through a~phylogenetic tree to identify regions of rate variation
		\item \href{https://CRAN.R-project.org/package=jaatha}{jaatha}: simulation-based maximum likelihood parameter estimation
		\item \href{https://CRAN.R-project.org/package=knitr}{knitr}: general-purpose tool for dynamic report generation
		\item \href{https://CRAN.R-project.org/package=LDheatmap}{LDheatmap}: graphical display, as a~heat map, of measures of pairwise linkage disequilibrium between SNPs
		\item \href{https://www.bioconductor.org/packages/release/bioc/html/LEA.html}{LEA}: landscape and ecological association studies
		\item \href{https://CRAN.R-project.org/package=leaflet}{leaflet}: interactive web maps with the JavaScript Leaflet library
		\item \href{https://github.com/giby/Linarius}{Linarius}: dominant marker analysis with mixed ploidy levels
		\item \href{https://CRAN.R-project.org/package=markophylo}{markophylo}: markov chain models for phylogenetic trees
		\item \href{https://CRAN.R-project.org/package=MASS}{MASS}: functions and data sets for venables and ripley's MASS
		\item \href{https://CRAN.R-project.org/package=MCMCglmm}{MCMCglmm}: MCMC generalized linear mixed models
		\item \href{https://github.com/NESCent/MINOTAUR}{MINOTAUR}: multivariate visualization and outlier analysis
		\item \href{https://CRAN.R-project.org/package=MonoPhy}{MonoPhy}: visualization and exploration of monophyletic clades on a~tree
		\item \href{https://CRAN.R-project.org/package=MPSEM}{MPSEM}: modeling phylogenetic signals using eigenvector maps
		\item \href{https://CRAN.R-project.org/package=mvMORPH}{mvMORPH}: multivariate comparative tools for fitting evolutionary models to morphometric data
		\item \href{https://CRAN.R-project.org/package=mvtnorm}{mvtnorm}: multivariate normal and t probabilities
		\item \href{https://CRAN.R-project.org/package=onemap}{onemap}: molecular marker data from model (backcrosses, F2 and recombinant inbred lines) and non-model systems (outcrossing species), constructions of genetic maps
		\item \href{https://CRAN.R-project.org/package=OpenStreetMap}{OpenStreetMap}: plotting OpenStreetMap maps (various layers)
		\item \href{https://CRAN.R-project.org/package=ouch}{ouch}: Ornstein-Uhlenbeck models for evolution along a~phylogenetic tree
		\item \href{https://CRAN.R-project.org/package=OUwie}{OUwie}: analysis of evolutionary rates in an OU framework
		\item \href{https://r-forge.r-project.org/projects/paleophylo/}{paleoPhylo}: assess how speciation, extinction and character change contribute to biodiversity
		\item \href{https://CRAN.R-project.org/package=paleotree}{paleotree}: paleontological and phylogenetic analysis of evolution
		\item \href{https://CRAN.R-project.org/package=paleoTS}{paleoTS}: analyze paleontological time-series
		\item \href{https://CRAN.R-project.org/package=pastis}{pastis}: phylogenetic assembly with soft taxonomic inferences
		\item \href{https://CRAN.R-project.org/package=PBD}{PBD}: protracted birth-death model of diversification
		\item \href{https://CRAN.R-project.org/package=pcadapt}{pcadapt}: PCA and search for loci responsible for the grouping (no support for mixing ploidy levels), uses VCF
		\item \href{https://CRAN.R-project.org/package=PCPS}{PCPS}: principal coordinates of phylogenetic structure
		\item \href{https://CRAN.R-project.org/package=permute}{permute}: restricted permutation designs
		\item \href{https://github.com/lliu1871/phybase}{Phybase}: read, write, manipulate, simulate, estimate, and summarize phylogenetic trees (gene trees and species trees)
		\item \href{https://CRAN.R-project.org/package=phyclust}{phyclust}: phylogenetic clustering
		\item \href{https://CRAN.R-project.org/package=phyloclim}{phyloclim}: integrating phylogenetics and climatic niche modeling
		\item \href{https://CRAN.R-project.org/package=PHYLOGR}{PHYLOGR}: manipulation and analysis of phylogenetically simulated data sets and phylogenetically based analysis using GLS
		\item \href{https://CRAN.R-project.org/package=phyloland}{phyloland}: models a~space colonization process mapped onto a~phylogeny
		\item \href{https://CRAN.R-project.org/package=phylolm}{phylolm}: phylogenetic linear models and phylogenetic generalized linear models
		\item \href{https://CRAN.R-project.org/package=phyloTop}{phyloTop}: calculating and viewing topological properties of phylogenetic trees
		\item \href{https://CRAN.R-project.org/package=phylotools}{phylotools}: supermatrix for DNA barcodes using different genes
		\item \href{https://CRAN.R-project.org/package=plotly}{plotly}: creates interactive web graphics
		\item \href{https://CRAN.R-project.org/package=plyr}{plyr}: splitting, applying and combining data
		\item \href{https://CRAN.R-project.org/package=pmc}{pmc}: phylogenetic Monte Carlo
		\item \href{https://CRAN.R-project.org/package=polyfreqs}{polyfreqs}: Gibbs sampling algorithm to perform Bayesian inference on biallelic SNP frequencies, genotypes and heterozygosity in a~population of autopolyploids
		\item \href{https://CRAN.R-project.org/package=polysat}{polysat}: polyploid microsatellite analysis
		\item \href{https://CRAN.R-project.org/package=RandomFields}{RandomFields}: simulation of Gaussian fields (+ \href{https://CRAN.R-project.org/package=RandomFieldsUtils}{RandomFieldsUtils})
		\item \href{https://github.com/thierrygosselin/radiator}{radiator}: RADseq data exploration, manipulation and visualization
		\item \href{https://github.com/ramnathv/rCharts}{rCharts}: interactive JS charts
		\item \href{https://CRAN.R-project.org/package=RColorBrewer}{RColorBrewer}: ColorBrewer palettes
		\item \href{https://CRAN.R-project.org/package=rdryad}{rdryad}: access for Dryad web services
		\item \href{https://CRAN.R-project.org/package=reshape2}{reshape2}: restructure and aggregate data
		\item \href{https://github.com/ramnathv/rMaps}{rMaps}: interactive maps
		\item \href{https://CRAN.R-project.org/package=rphast}{rphast}: interface to PHAST software for comparative genomics
		\item \href{https://r-forge.r-project.org/projects/rmesquite/}{RMesquite}: interoperability with Mesquite
		\item \href{https://CRAN.R-project.org/package=Rphylip}{Rphylip}: interface for PHYLIP
		\item \href{https://bioconductor.org/packages/release/bioc/html/Rsamtools.html}{Rsamtools}: BAM, FASTA, BCF and tabix file import and manipulations
		\item \href{https://CRAN.R-project.org/package=rwty}{rwty}: tests, visualizations, and metrics for diagnosing convergence of MCMC chains in phylogenetics
		\item \href{https://CRAN.R-project.org/package=sensiPhy}{sensiPhy}: sensitivity analysis for phylogenetic comparative methods,  statistical and graphical methods that estimate and report different types of uncertainty
		\item \href{https://www.bioconductor.org/packages/release/bioc/html/seqLogo.html}{seqLogo}: sequence logos for DNA sequence alignments
		\item \href{https://CRAN.R-project.org/package=SigTree}{SigTree}: identify and visualize significantly responsive branches in a~phylogenetic tree
		\item \href{https://CRAN.R-project.org/package=SimRAD}{SimRAD}: simulate restriction enzyme digestion, library construction and fragments size selection to predict the number of loci expected from most of the RAD and GPS approaches
		\item \href{https://www.bioconductor.org/packages/release/bioc/html/SNPRelate.html}{SNPRelate}: parallel computing toolset for relatedness and principal component analysis of SNP data
		\item \href{https://bioconductor.org/packages/release/bioc/html/snpStats.html}{snpStats}: classes and statistical methods for large SNP association studies
		\item \href{https://CRAN.R-project.org/package=spatstat}{spatstat}: spatial point pattern analysis
		\item \href{https://r-forge.r-project.org/projects/splits/}{splits}: delimiting species and automated taxonomy at many levels of biological organization
		\item \href{https://CRAN.R-project.org/package=strap}{strap}: stratigraphic analysis of phylogenetic trees, palaeontology
		\item \href{https://CRAN.R-project.org/package=strataG}{strataG}: analyzing stratified population genetic data by vast range of methods, very powerful
		\item \href{https://CRAN.R-project.org/package=stringi}{stringi} and \href{https://CRAN.R-project.org/package=stringr}{stringr}: character string processing, internally used by many packages
		\item \href{https://CRAN.R-project.org/package=surface}{surface}: fitting Hansen models to investigate convergent evolution
		\item \href{https://CRAN.R-project.org/package=SYNCSA}{SYNCSA}: analysis of metacommunities based on functional traits and phylogeny of the community components
		\item \href{https://CRAN.R-project.org/package=taxize}{taxize}: taxonomic information from around the web
		\item \href{https://CRAN.R-project.org/package=TESS}{TESS}: simulation of reconstructed phylogenetic trees under tree-wide time-heterogeneous birth-death processes and estimation of diversification parameters under the same model
		\item \href{https://CRAN.R-project.org/package=tmap}{tmap}: various thematic maps
		\item \href{https://CRAN.R-project.org/package=treebase}{treebase}:  discovery, access and manipulation of TreeBASE phylogeny
		\item \href{https://CRAN.R-project.org/package=TreePar}{TreePar}: estimating birth and death rates based on phylogeny
		\item \href{https://CRAN.R-project.org/package=TreeSearch}{TreeSearch}: search for phylogenetic trees that are optimal using a~user-defined criterion
		\item \href{https://CRAN.R-project.org/package=TreeSim}{TreeSim}: simulating phylogenetic trees
		\item \href{https://CRAN.R-project.org/package=treespace}{treespace}: exploration of distributions of phylogenetic trees
		\item \href{https://CRAN.R-project.org/package=UpSetR}{UpSetR}: visualizations of intersecting sets using a novel matrix design, along with visualizations of several common set, element and attribute related tasks
		\item \href{https://bioconductor.org/packages/VariantAnnotation/}{VariantAnnotation}: annotation of genetic variants (useful to filter VCF)
		\item \href{https://bioconductor.org/packages/release/bioc/html/XVector.html}{XVector}: representation and manipulation of external sequences
	\end{itemize}
	And more\ldots~R is continuously evolving and new packages are arising\ldots
\end{frame}

\begin{frame}{Orientation in so many packages\ldots}
	\begin{itemize}
		\item \ldots is not easy\ldots
		\item Many methods are implemented in more packages
		\begin{itemize}
			\item Quality and richness of implementations may vary a~lot\ldots
			\item Same methods in different packages may require data in different formats/R classes (conversion use to be simple --- but always see respective documentation)
		\end{itemize}
		\item Anyone can create and submit R package\ldots
		\begin{itemize}
			\item Plenty of packages to choose from\ldots
			\item No restrictions (apart basic technical requirements in repositories) --- quality may be variable\ldots
		\end{itemize}
		\item Follow news on R sites, mailing lists, journal articles introducing new packages, etc.
		\item Be open for new tools, explore, try, share your experience
	\end{itemize}
\end{frame}

\subsection{The end}

\begin{frame}{The methods are over}
	\begin{itemize}
		\item We went in more or less details through plenty of methods to work with molecular data to analyze phylogeny, population genetics, evolution and so on in R
		\item There are many more methods to try\ldots
		\item It is nearly impossible to go in reasonable time through all relevant R tools --- a~lot of space for you
	\end{itemize}
\end{frame}

\begin{frame}{The end}{Our course is over\ldots}
	\begin{center}
		\ldots I~hope it was helpful for You\ldots\\
		\vfill
		\ldots any feedback is welcomed\ldots
		\vfill
		\ldots happy \textbf{\textit{R}} hacking\ldots
		\vfill
	\end{center}
	\begin{flushright}
		\ldots~any final questions?
		\vfill
		\begin{tiny}
		\href{https://en.wikipedia.org/wiki/XeTeX}{Typesetting} using \XeLaTeX~on \href{https://www.opensuse.org/}{openSUSE} \href{https://en.wikipedia.org/wiki/GNU}{GNU}/\href{https://en.wikipedia.org/wiki/Linux}{Linux}, \today.
		\end{tiny}
	\end{flushright}
\end{frame}

\end{document}

% TODO Missing topics
%
% Vypsat balíčky před každou kapitolu
% Přeskládat alignmenty tak, aby kontroly a úpravy byly jen jednou
% Setřídit kapitolu o stromech v prezentaci i ve skriptech
% Filtrování VCF
% Filtrování genlight na chybějící data
%
% More theory for methods - before each method some theoretical slide(s)
% Tree graphics
% external tree builders
% ML
% Bayes trees
% DW index - rare alleles
% https://cran.r-project.org/web/packages/phangorn/vignettes/
% https://github.com/JClavel/Examples
% https://popgen.nescent.org/
% https://wurmlab.github.io/genomicscourse/2016-SIB/practicals/population_genetics/popgen
% https://botany.natur.cuni.cz/cevnate/navody/
% http://www.phytools.org/eqg/
% http://www.phytools.org/eqg2015/
% http://www.phytools.org/Cordoba2017/
% https://www.molecularecologist.com/2017/02/phylogenetic-trees-in-r-using-ggtree/
% https://www.molecularecologist.com/2016/07/making-maps-in-r-volume-2-ggplots/
% https://www.molecularecologist.com/2016/03/geographical-heat-maps-in-r/
% https://www.molecularecologist.com/2016/02/quick-and-dirty-tree-building-in-r/
% https://www.molecularecologist.com/2016/01/genomics-of-hybridization-part-ii-top-three-of-2015/
% https://www.molecularecologist.com/2015/07/pca-of-multilocus-genotypes-in-r/
% https://www.molecularecologist.com/2015/03/f-statistics-manhattan-plots-in-r/
% https://www.molecularecologist.com/2015/01/a-population-genetic-r-evolution/
% https://www.molecularecologist.com/2014/11/admixture-maps-in-r-for-dummies/
% https://www.molecularecologist.com/2013/10/random-drift-and-phenotypic-evolution/
% https://onlinelibrary.wiley.com/doi/abs/10.1111/evo.13492 - https://datadryad.org/resource/doi:10.5061/dryad.2s8d0f9
% https://www.r-bloggers.com/phylotar-retrieve-orthologous-sequences-from-genbank/
% https://github.com/emmanuelparadis/psmcr
% - Nahradit SPCA jinou verzí (z adephylo?).
% - Možná přeskládat nějaké věci ohledně manipulace se stromy (věci s `multiPhylo` až po práci s jednotlivými stromy, zkontrolovat na co už není potřeba `lapply`, pořádek v `interactive` variantách, apod.).
% - Víc příkladů na indexování.
% - Obecně o `lapply` a spol.
% - Kompletní sada příkladů na více genů - od načtení FASTA přes alignment po třeba stromy
% - Přidat načítání a export nexu
% - Přidat/zmínit práci s proteiny (AA třídy)
% - Profiltrovat VCF alespoň na chybějící data, zkontrolovat konverzi do DNAbin
% - Obecně povyházet varianty řešení různých úloh jen do poznámek a ostatní nechat v jedné nejvýhodnější variantě
% - přidat typické workflow (data, typické objevy a cesty)
% - Ukládání tabulkových výstupů, více o načítání tabulek
% - Možná zredukovat počet příkladů a méně je kombinovat
% The minimum spanning network is constructed from the distance matrix between all individuals using Prim's algorithm, so what you get is a representation of minimum set of edges needed to connect all the nodes in your network. My guess (and only a guess) is that while you have apparent population structure, there is still a lot of variation within groups that's strong enough to overpower the MSN. One thing you could try if you haven't already is to add the parameter include.ties = TRUE to see if you have equivalent paths. You might also consider using a Euclidean distance (use the option euclidean = TRUE and scale_missing = TRUE in bitwise.dist), which will differentiate between homozygous and heterozygous sites. You might also consider taking a look at what the tree from bitwise.dist looks like. I would suspect it has a lot of long terminal branches without strong boostrap support.
